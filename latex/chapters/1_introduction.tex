% ============================================
% CHAPTER 1: GIỚI THIỆU
% ============================================

\chapter{Giới thiệu}
\label{chap:introduction}

\section{Bối cảnh và động lực}
\label{sec:background}

Trong bối cảnh toàn cầu hóa ngày càng gia tăng, nhu cầu dịch thuật tự động giữa các ngôn ngữ trở thành một vấn đề cấp thiết. Dịch máy (Machine Translation - MT) là một trong những bài toán quan trọng và thách thức nhất trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (Natural Language Processing - NLP).

Truyền thống, các hệ thống dịch máy thống kê (Statistical Machine Translation - SMT) dựa trên các mô hình xác suất và song ngữ liệu song song đã đạt được những kết quả nhất định \cite{koehn2010statistical}. Tuy nhiên, phương pháp này gặp nhiều hạn chế trong việc nắm bắt ngữ cảnh và cấu trúc ngữ pháp phức tạp.

Sự bùng nổ của Deep Learning trong những năm gần đây đã mở ra một hướng tiếp cận mới: \textbf{Dịch máy neural} (Neural Machine Translation - NMT). Khác với SMT, NMT sử dụng mạng neural để học trực tiếp ánh xạ từ câu nguồn sang câu đích, cho phép mô hình nắm bắt được các đặc trưng ngữ nghĩa ở mức độ sâu hơn.

Đặc biệt, kiến trúc \textbf{Encoder-Decoder} với LSTM (Long Short-Term Memory) được giới thiệu bởi Sutskever et al. \cite{sutskever2014sequence} đã chứng minh hiệu quả vượt trội trong việc xử lý chuỗi dài và giải quyết vấn đề vanishing gradient của RNN truyền thống.

\section{Mục tiêu đồ án}
\label{sec:objectives}

Đồ án này tập trung vào việc xây dựng một hệ thống dịch máy Anh-Pháp sử dụng kiến trúc LSTM Encoder-Decoder, bao gồm cả phần cơ bản (baseline) và phần mở rộng (extensions). Cụ thể, các mục tiêu bao gồm:

\subsection{Phần bắt buộc (Baseline Model)}

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Cài đặt mô hình Encoder-Decoder}: Xây dựng kiến trúc LSTM 2 lớp với embedding dimension 256 và hidden dimension 512, context vector cố định.
    
    \item \textbf{Xử lý dữ liệu}: Xây dựng pipeline tiền xử lý dữ liệu bao gồm tokenization, vocabulary building (10K từ), padding và packing.
    
    \item \textbf{Huấn luyện mô hình}: Implement training loop với early stopping (patience=3), gradient clipping và teacher forcing (ratio=0.5 cố định).
    
    \item \textbf{Đánh giá hiệu năng}: Đạt BLEU score $\geq 20\%$ trên tập test Multi30K.
    
    \item \textbf{Phân tích lỗi}: Phân loại và phân tích các lỗi dịch phổ biến (câu dài, OOV, ngữ pháp, thứ tự từ) với ví dụ cụ thể.
\end{enumerate}

\subsection{Phần mở rộng (để đạt điểm cao hơn)}

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Attention Mechanism}: Implement Luong Attention để khắc phục hạn chế của context vector cố định, cho phép decoder "chú ý" đến các vị trí khác nhau của câu nguồn.
    
    \item \textbf{Tăng model capacity}: Nâng cấp từ 2 layers → 3 layers, hidden 512 → 1024, embedding 256 → 512, vocab 10K → 15K.
    
    \item \textbf{Scheduled Sampling}: Thay teacher forcing cố định (0.5) bằng scheduled sampling (0.7 → 0.5) để giảm exposure bias.
    
    \item \textbf{Beam Search Decoding}: Thay greedy decoding bằng beam search (K=5) để khám phá nhiều hypotheses.
    
    \item \textbf{So sánh hiệu năng}: Đánh giá chi tiết sự cải thiện của Attention so với Vanilla, đặc biệt với câu dài.
\end{enumerate}

\section{Phạm vi và giới hạn}
\label{sec:scope}

\subsection{Phạm vi}

\begin{itemize}
    \item \textbf{Dataset}: Multi30K English-French parallel corpus \cite{elliott2016multi30k}
    \begin{itemize}
        \item Training set: 29,000 câu
        \item Validation set: 1,014 câu
        \item Test set: 1,000 câu
    \end{itemize}
    
    \item \textbf{Cặp ngôn ngữ}: Anh $\rightarrow$ Pháp (đơn hướng)
    
    \item \textbf{Kiến trúc}: 
    \begin{itemize}
        \item \textit{Baseline}: LSTM Encoder-Decoder với context vector cố định (không có Attention)
        \item \textit{Extension}: LSTM Encoder-Decoder với Luong Attention mechanism
    \end{itemize}
    
    \item \textbf{Môi trường}: Google Colab với GPU Tesla T4
    
    \item \textbf{Framework}: PyTorch 2.0+
\end{itemize}

\subsection{Giới hạn}

\textbf{Baseline Model:}
\begin{itemize}
    \item Context vector cố định (theo yêu cầu đề bài baseline)
    
    \item Vocabulary giới hạn ở 10,000 từ phổ biến nhất cho mỗi ngôn ngữ
    \item Chỉ xử lý văn bản thuần, không xử lý context hình ảnh (mặc dù Multi30K có ảnh kèm theo)
\end{itemize}

\textbf{Cả hai models (Baseline \& Extension):}
\begin{itemize}
    \item Không sử dụng pretrained embeddings (word2vec, GloVe, FastText)
    
    \item Độ dài câu tối đa: 50 tokens
    
    \item Chỉ dịch một chiều (Anh → Pháp), không dịch ngược lại
\end{itemize}

\section{Đóng góp của đồ án}
\label{sec:contributions}

Đồ án này mang lại các đóng góp sau:

\begin{enumerate}
    \item \textbf{Implementation đầy đủ cả 2 models}: 
    \begin{itemize}
        \item Cài đặt hoàn chỉnh Baseline model (theo yêu cầu bắt buộc)
        \item Cài đặt Extension model với Attention \& Beam Search (phần mở rộng)
        \item Code từ đầu (from scratch), bao gồm data processing, model architecture, training loop, và inference
    \end{itemize}
    
    \item \textbf{Kết quả vượt yêu cầu}: 
    \begin{itemize}
        \item Baseline: BLEU 29.12\% (vượt yêu cầu 20\%)
        \item Extension: BLEU 36.57\% (vượt xa yêu cầu, đạt mức tốt)
        \item Đủ điều kiện đạt 11/10 điểm (10 cơ bản + 1 mở rộng)
    \end{itemize}
    
    \item \textbf{Reproducibility}: Code được tổ chức rõ ràng, có comment đầy đủ, và checkpoint model được lưu trữ để tái hiện kết quả.
\end{enumerate}

\section{Cấu trúc báo cáo}
\label{sec:structure}

Báo cáo được tổ chức thành 6 chương chính (khớp với mô tả ở trên):

\begin{itemize}
    \item \textbf{Chương 1 - Giới thiệu}: Bối cảnh, mục tiêu, phạm vi và đóng góp của đồ án.
    
    \item \textbf{Chương 2 - Các công trình liên quan}: Tổng quan về lịch sử dịch máy và các công trình nghiên cứu liên quan đến Encoder-Decoder.
    
    \item \textbf{Chương 3 - Baseline Model}: Mô tả chi tiết kiến trúc Vanilla model, xử lý dữ liệu, và cấu hình huấn luyện.
    
    \item \textbf{Chương 4 - Kết quả Baseline}: Thiết lập thực nghiệm, kết quả training, BLEU 29.12\%, 5 ví dụ dịch, và phân tích lỗi.
    
    \item \textbf{Chương 5 - Extension: Attention \& Beam Search}: Kiến trúc Attention model, kết quả BLEU 36.57\%, so sánh với Baseline.
    
    \item \textbf{Chương 6 - Kết luận}: Tổng kết cả 2 models, hạn chế, và hướng phát triển tương lai.
\end{itemize}

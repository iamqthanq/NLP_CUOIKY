{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaGwFNVQvtZm"
      },
      "source": [
        "## B∆Ø·ªöC 1: Thao t√°c ban ƒë·∫ßu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNVUOwZujrH"
      },
      "source": [
        "### Ch·ªçn g√≥c ph·∫£i m√†n h√¨nh, ch·ªçn change runtime type, chon t4 gpu, save, ra ch·∫°y cell n√†y ƒë·∫ßu ti·ªÅn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvLyJUzetq_4",
        "outputId": "fb8bdf9d-e236-4961-fe22-ba1fc37eaf67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU name: Tesla T4\n",
            "GPU memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\" if torch.cuda.is_available() else \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5UFXZ7tuxoD"
      },
      "source": [
        "### Sau ƒë√≥ t·∫°o th∆∞ m·ª•c trong drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4FlzjZnvFt5"
      },
      "source": [
        "### K·∫øt n·ªëi drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHEeCXdJuh5t",
        "outputId": "dfdabb9e-ef62-48ea-d73d-e0e375430256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6O8P6utvLkS"
      },
      "source": [
        "### T·∫°o th∆∞ m·ª•c project tr√™n *Drive*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNuAS9XdvMW5"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/NLP_Do_An\"\n",
        "!mkdir -p \"/content/drive/MyDrive/NLP_Do_An/data\"\n",
        "!mkdir -p \"/content/drive/MyDrive/NLP_Do_An/check_point\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mM76xS3vdVA"
      },
      "source": [
        "### Sau ƒë√≥ upload 6 files data v√†o:\n",
        "Google Drive ‚Üí MyDrive ‚Üí NLP_Do_An ‚Üí data/\n",
        "(K√©o th·∫£ t·ª´ m√°y local v√†o Drive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukT2HH-HvmpW"
      },
      "source": [
        "### **check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKJ65lFzvjYZ",
        "outputId": "7b618bde-83e7-4d5d-dee0-fde1cec977bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ln: failed to create symbolic link '/content/data/data': File exists\n",
            "ln: failed to create symbolic link '/content/check_point/check_point': File exists\n",
            "‚úÖ Data s·∫µn s√†ng!\n"
          ]
        }
      ],
      "source": [
        "!ln -s \"/content/drive/MyDrive/NLP_Do_An/data\" /content/data\n",
        "!ln -s \"/content/drive/MyDrive/NLP_Do_An/check_point\" /content/check_point\n",
        "\n",
        "print(\"‚úÖ Data s·∫µn s√†ng!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lkyixXQvqMC"
      },
      "source": [
        "##  B∆Ø·ªöC 2: C√†i ƒë·∫∑t Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqqg-nFfwC91"
      },
      "source": [
        "### C√†i ƒë·∫∑t th∆∞ vi·ªán v√† model c·∫ßn thi·∫øt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4KnlkLXwjIQ",
        "outputId": "ff69f09a-c9d2-4d75-9eb8-4739e4c48db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q spacy torch nltk matplotlib seaborn tqdm\n",
        "\n",
        "# Download spaCy models\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "print(\"‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zeWeMtxTOr"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVHUIFCLxZVs",
        "outputId": "ba96985c-7122-4482-cfba-17d03e46bada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path(\"/content/data\")\n",
        "CHECKPOINT_DIR = Path(\"/content/check_point\")\n",
        "\n",
        "# Vocabulary\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN = \"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"\n",
        "PAD_IDX, UNK_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "SPECIAL_TOKENS = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
        "MIN_FREQ = 1\n",
        "\n",
        "# Data files\n",
        "TRAIN_EN = DATA_DIR / \"train.en\"\n",
        "TRAIN_FR = DATA_DIR / \"train.fr\"\n",
        "VAL_EN = DATA_DIR / \"val.en\"\n",
        "VAL_FR = DATA_DIR / \"val.fr\"\n",
        "TEST_EN = DATA_DIR / \"test.en\"\n",
        "TEST_FR = DATA_DIR / \"test.fr\"\n",
        "\n",
        "# Training config\n",
        "BATCH_SIZE = 64\n",
        "MAX_SEQ_LENGTH = 50\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.3\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 15\n",
        "EARLY_STOPPING_PATIENCE = 3\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"üöÄ Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7eh68Iu1-UH",
        "outputId": "ac26adee-b993-4e58-b937-cd1716de4261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "C·∫§U H√åNH - D·ªãch Anh-Ph√°p\n",
            "============================================================\n",
            "Thi·∫øt b·ªã: cuda\n",
            "K√≠ch th∆∞·ªõc batch: 64\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn t·ªëi ƒëa: 10000\n",
            "Chi·ªÅu embedding: 256\n",
            "K√≠ch th∆∞·ªõc hidden: 512\n",
            "S·ªë l·ªõp: 2\n",
            "Dropout: 0.3\n",
            "T·ªâ l·ªá teacher forcing: 0.5\n",
            "Learning rate: 0.001\n",
            "S·ªë epoch: 15\n",
            "ƒê·ªô ki√™n nh·∫´n early stopping: 3\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# ============ PATH CONFIGURATION ============\n",
        "# T∆∞∆°ng th√≠ch c·∫£ local v√† Colab\n",
        "try:\n",
        "    # N·∫øu ch·∫°y t·ª´ file .py (local)\n",
        "    BASE_DIR = Path(__file__).parent.parent\n",
        "except NameError:\n",
        "    # N·∫øu ch·∫°y tr√™n Colab/Jupyter (kh√¥ng c√≥ __file__)\n",
        "    BASE_DIR = Path(\"/content\")\n",
        "\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "CHECKPOINT_DIR = BASE_DIR / \"check_point\"\n",
        "REPORT_DIR = BASE_DIR / \"report\"\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "REPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# ============ DATA FILES ============\n",
        "TRAIN_EN = DATA_DIR / \"train.en\"\n",
        "TRAIN_FR = DATA_DIR / \"train.fr\"\n",
        "VAL_EN = DATA_DIR / \"val.en\"\n",
        "VAL_FR = DATA_DIR / \"val.fr\"\n",
        "TEST_EN = DATA_DIR / \"test.en\"\n",
        "TEST_FR = DATA_DIR / \"test.fr\"\n",
        "\n",
        "# ============ VOCABULARY CONFIGURATION ============\n",
        "# Theo y√™u c·∫ßu: \"Gi·ªõi h·∫°n 10,000 t·ª´ ph·ªï bi·∫øn nh·∫•t m·ªói ng√¥n ng·ªØ\"\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "MIN_FREQ = 1  # T·∫ßn su·∫•t t·ªëi thi·ªÉu ƒë·ªÉ t·ª´ ƒë∆∞·ª£c ƒë∆∞a v√†o vocab\n",
        "\n",
        "# Special tokens\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "SOS_TOKEN = \"<sos>\"  # Start of sentence\n",
        "EOS_TOKEN = \"<eos>\"  # End of sentence\n",
        "\n",
        "SPECIAL_TOKENS = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
        "\n",
        "# Token indices\n",
        "PAD_IDX = 0\n",
        "UNK_IDX = 1\n",
        "SOS_IDX = 2\n",
        "EOS_IDX = 3\n",
        "\n",
        "# ============ DATA PROCESSING ============\n",
        "# Batch size: 32-128 theo y√™u c·∫ßu\n",
        "BATCH_SIZE = 64  # C√≥ th·ªÉ thay ƒë·ªïi trong kho·∫£ng [32, 128]\n",
        "MAX_SEQ_LENGTH = 50  # Gi·ªõi h·∫°n ƒë·ªô d√†i c√¢u ƒë·ªÉ tr√°nh qu√° d√†i\n",
        "\n",
        "# Sorting & Packing (y√™u c·∫ßu Task 2)\n",
        "SORT_WITHIN_BATCH = True  # S·∫Øp x·∫øp batch theo ƒë·ªô d√†i gi·∫£m d·∫ßn\n",
        "USE_PACKED_SEQUENCE = True  # S·ª≠ d·ª•ng pack_padded_sequence\n",
        "\n",
        "# ============ MODEL CONFIGURATION ============\n",
        "# Theo b·∫£ng \"Tham s·ªë khuy·∫øn ngh·ªã\" trong ƒë·ªÅ b√†i\n",
        "EMBEDDING_DIM = 256  # C√≥ th·ªÉ t·ª´ 256-512\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2  # S·ªë layer LSTM\n",
        "DROPOUT = 0.3  # T·ª´ 0.3-0.5 theo ƒë·ªÅ b√†i\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "\n",
        "# Encoder-Decoder v·ªõi context vector c·ªë ƒë·ªãnh (kh√¥ng d√πng attention)\n",
        "USE_ATTENTION = False  # Task c∆° b·∫£n kh√¥ng y√™u c·∫ßu attention\n",
        "\n",
        "# ============ TRAINING CONFIGURATION ============\n",
        "NUM_EPOCHS = 15  # T·ª´ 10-20 theo ƒë·ªÅ b√†i\n",
        "LEARNING_RATE = 0.001\n",
        "OPTIMIZER = \"Adam\"  # Adam(lr=0.001) theo ƒë·ªÅ b√†i\n",
        "\n",
        "# Scheduler: ReduceLROnPlateau\n",
        "SCHEDULER_PATIENCE = 2\n",
        "SCHEDULER_FACTOR = 0.5\n",
        "\n",
        "# Early stopping\n",
        "EARLY_STOPPING_PATIENCE = 3  # D·ª´ng n·∫øu val_loss kh√¥ng gi·∫£m sau 3 epochs\n",
        "\n",
        "# Checkpoint\n",
        "SAVE_BEST_MODEL = True\n",
        "CHECKPOINT_PATH = CHECKPOINT_DIR / \"best_model.pth\"\n",
        "\n",
        "# ============ DEVICE CONFIGURATION ============\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ============ EVALUATION ============\n",
        "# Greedy decoding: max length = 50 ho·∫∑c g·∫∑p <eos>\n",
        "MAX_DECODE_LENGTH = 50\n",
        "\n",
        "# BLEU score\n",
        "COMPUTE_BLEU = True\n",
        "\n",
        "# ============ LOGGING ============\n",
        "PRINT_EVERY = 100  # Print loss m·ªói 100 batches\n",
        "SAVE_PLOTS = True  # L∆∞u bi·ªÉu ƒë·ªì train/val loss\n",
        "\n",
        "# ============ DISPLAY CONFIG ============\n",
        "def display_config():\n",
        "    \"\"\"In ra c·∫•u h√¨nh hi·ªán t·∫°i\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"C·∫§U H√åNH - D·ªãch Anh-Ph√°p\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Thi·∫øt b·ªã: {DEVICE}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc batch: {BATCH_SIZE}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn t·ªëi ƒëa: {MAX_VOCAB_SIZE}\")\n",
        "    print(f\"Chi·ªÅu embedding: {EMBEDDING_DIM}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc hidden: {HIDDEN_SIZE}\")\n",
        "    print(f\"S·ªë l·ªõp: {NUM_LAYERS}\")\n",
        "    print(f\"Dropout: {DROPOUT}\")\n",
        "    print(f\"T·ªâ l·ªá teacher forcing: {TEACHER_FORCING_RATIO}\")\n",
        "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "    print(f\"S·ªë epoch: {NUM_EPOCHS}\")\n",
        "    print(f\"ƒê·ªô ki√™n nh·∫´n early stopping: {EARLY_STOPPING_PATIENCE}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display_config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-2YPMeyFuN"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az8eYsECyIQs",
        "outputId": "9fee6c12-4ce8-4a82-9600-275ace314210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K·∫øt qu·∫£ tokenize: ['hello', ',', 'how', 'are', 'you', '?']\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi 10 token\n",
            "  - Special tokens: 4\n",
            "  - Token th∆∞·ªùng: 6\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn: 10\n",
            "M√£ h√≥a 'hello': [4]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict\n",
        "import re\n",
        "\n",
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    Class qu·∫£n l√Ω vocabulary cho m·ªôt ng√¥n ng·ªØ\n",
        "    Y√™u c·∫ßu: Gi·ªõi h·∫°n 10,000 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
        "    \"\"\"\n",
        "    def __init__(self, max_size=10000, min_freq=1, special_tokens=None):\n",
        "        self.max_size = max_size\n",
        "        self.min_freq = min_freq\n",
        "        self.special_tokens = special_tokens or [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "\n",
        "        # Token to index and index to token mappings\n",
        "        self.token2idx = {}\n",
        "        self.idx2token = {}\n",
        "\n",
        "        # Initialize with special tokens\n",
        "        for idx, token in enumerate(self.special_tokens):\n",
        "            self.token2idx[token] = idx\n",
        "            self.idx2token[idx] = token\n",
        "\n",
        "        self.pad_idx = self.token2idx[\"<pad>\"]\n",
        "        self.unk_idx = self.token2idx[\"<unk>\"]\n",
        "        self.sos_idx = self.token2idx[\"<sos>\"]\n",
        "        self.eos_idx = self.token2idx[\"<eos>\"]\n",
        "\n",
        "    def build_vocab_from_iterator(self, iterator):\n",
        "        \"\"\"\n",
        "        X√¢y d·ª±ng vocabulary t·ª´ iterator of sentences\n",
        "\n",
        "        Args:\n",
        "            iterator: Iterator ch·ª©a c√°c c√¢u (m·ªói c√¢u l√† list of tokens)\n",
        "        \"\"\"\n",
        "        # ƒê·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa m·ªói token\n",
        "        counter = Counter()\n",
        "        for tokens in iterator:\n",
        "            counter.update(tokens)\n",
        "\n",
        "        # L·ªçc theo min_freq v√† l·∫•y max_size tokens ph·ªï bi·∫øn nh·∫•t\n",
        "        # Lo·∫°i b·ªè special tokens n·∫øu c√≥ trong data\n",
        "        for special in self.special_tokens:\n",
        "            if special in counter:\n",
        "                del counter[special]\n",
        "\n",
        "        # S·∫Øp x·∫øp theo t·∫ßn su·∫•t gi·∫£m d·∫ßn v√† l·∫•y top max_size - len(special_tokens)\n",
        "        most_common = counter.most_common(self.max_size - len(self.special_tokens))\n",
        "\n",
        "        # Th√™m v√†o vocabulary (b·∫Øt ƒë·∫ßu t·ª´ index len(special_tokens))\n",
        "        for idx, (token, freq) in enumerate(most_common, start=len(self.special_tokens)):\n",
        "            if freq >= self.min_freq:\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token[idx] = token\n",
        "\n",
        "        print(f\"X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi {len(self.token2idx)} token\")\n",
        "        print(f\"  - Special tokens: {len(self.special_tokens)}\")\n",
        "        print(f\"  - Token th∆∞·ªùng: {len(self.token2idx) - len(self.special_tokens)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token2idx)\n",
        "\n",
        "    def encode(self, tokens: List[str]) -> List[int]:\n",
        "        \"\"\"Convert tokens to indices\"\"\"\n",
        "        return [self.token2idx.get(token, self.unk_idx) for token in tokens]\n",
        "\n",
        "    def decode(self, indices: List[int]) -> List[str]:\n",
        "        \"\"\"Convert indices to tokens\"\"\"\n",
        "        return [self.idx2token.get(idx, \"<unk>\") for idx in indices]\n",
        "\n",
        "\n",
        "def tokenize_sentence(sentence: str, language: str = \"en\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Tokenize m·ªôt c√¢u th√†nh list of tokens\n",
        "    S·ª≠ d·ª•ng tokenization ƒë∆°n gi·∫£n (split by space + lowercase)\n",
        "\n",
        "    Args:\n",
        "        sentence: C√¢u c·∫ßn tokenize\n",
        "        language: Ng√¥n ng·ªØ ('en' ho·∫∑c 'fr')\n",
        "\n",
        "    Returns:\n",
        "        List of tokens\n",
        "    \"\"\"\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # X·ª≠ l√Ω d·∫•u c√¢u: th√™m space tr∆∞·ªõc d·∫•u c√¢u\n",
        "    sentence = re.sub(r\"([.!?;,])\", r\" \\1\", sentence)\n",
        "\n",
        "    # Split by whitespace\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def read_parallel_corpus(src_file: str, tgt_file: str, tokenize_fn=tokenize_sentence) -> Tuple[List[List[str]], List[List[str]]]:\n",
        "    \"\"\"\n",
        "    ƒê·ªçc parallel corpus (c·∫∑p file en-fr)\n",
        "\n",
        "    Args:\n",
        "        src_file: Path to source file (.en)\n",
        "        tgt_file: Path to target file (.fr)\n",
        "        tokenize_fn: Function ƒë·ªÉ tokenize\n",
        "\n",
        "    Returns:\n",
        "        (src_sentences, tgt_sentences): Tuple of lists of tokenized sentences\n",
        "    \"\"\"\n",
        "    src_sentences = []\n",
        "    tgt_sentences = []\n",
        "\n",
        "    with open(src_file, 'r', encoding='utf-8') as f_src, \\\n",
        "         open(tgt_file, 'r', encoding='utf-8') as f_tgt:\n",
        "\n",
        "        for src_line, tgt_line in zip(f_src, f_tgt):\n",
        "            src_line = src_line.strip()\n",
        "            tgt_line = tgt_line.strip()\n",
        "\n",
        "            if src_line and tgt_line:  # B·ªè qua d√≤ng tr·ªëng\n",
        "                src_tokens = tokenize_fn(src_line, language=\"en\")\n",
        "                tgt_tokens = tokenize_fn(tgt_line, language=\"fr\")\n",
        "\n",
        "                src_sentences.append(src_tokens)\n",
        "                tgt_sentences.append(tgt_tokens)\n",
        "\n",
        "    return src_sentences, tgt_sentences\n",
        "\n",
        "\n",
        "def add_special_tokens(tokens: List[str], add_sos=True, add_eos=True) -> List[str]:\n",
        "    \"\"\"\n",
        "    Th√™m <sos> v√† <eos> v√†o c√¢u\n",
        "\n",
        "    Args:\n",
        "        tokens: List of tokens\n",
        "        add_sos: Th√™m <sos> ·ªü ƒë·∫ßu\n",
        "        add_eos: Th√™m <eos> ·ªü cu·ªëi\n",
        "\n",
        "    Returns:\n",
        "        List of tokens with special tokens\n",
        "    \"\"\"\n",
        "    result = tokens.copy()\n",
        "    if add_sos:\n",
        "        result = [\"<sos>\"] + result\n",
        "    if add_eos:\n",
        "        result = result + [\"<eos>\"]\n",
        "    return result\n",
        "\n",
        "\n",
        "def collate_fn(batch, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"\n",
        "    Custom collate function cho DataLoader\n",
        "    X·ª≠ l√Ω padding v√† chuy·ªÉn sang tensor\n",
        "\n",
        "    Args:\n",
        "        batch: List of (src_tokens, tgt_tokens)\n",
        "        src_vocab: Source vocabulary\n",
        "        tgt_vocab: Target vocabulary\n",
        "        device: torch device\n",
        "        max_len: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa sequence\n",
        "\n",
        "    Returns:\n",
        "        src_batch: Tensor shape (batch_size, max_src_len)\n",
        "        src_lengths: Tensor shape (batch_size,) - ƒë·ªô d√†i th·ª±c c·ªßa m·ªói sequence\n",
        "        tgt_batch: Tensor shape (batch_size, max_tgt_len)\n",
        "        tgt_lengths: Tensor shape (batch_size,)\n",
        "    \"\"\"\n",
        "    # Th√™m special tokens\n",
        "    src_batch = []\n",
        "    tgt_batch = []\n",
        "    src_lengths = []\n",
        "    tgt_lengths = []\n",
        "\n",
        "    for src_tokens, tgt_tokens in batch:\n",
        "        # Th√™m <sos>, <eos> v√† gi·ªõi h·∫°n ƒë·ªô d√†i\n",
        "        src_tokens = add_special_tokens(src_tokens[:max_len-2], add_sos=True, add_eos=True)\n",
        "        tgt_tokens = add_special_tokens(tgt_tokens[:max_len-2], add_sos=True, add_eos=True)\n",
        "\n",
        "        # Encode\n",
        "        src_indices = src_vocab.encode(src_tokens)\n",
        "        tgt_indices = tgt_vocab.encode(tgt_tokens)\n",
        "\n",
        "        src_batch.append(src_indices)\n",
        "        tgt_batch.append(tgt_indices)\n",
        "        src_lengths.append(len(src_indices))\n",
        "        tgt_lengths.append(len(tgt_indices))\n",
        "\n",
        "    # Padding\n",
        "    max_src_len = max(src_lengths)\n",
        "    max_tgt_len = max(tgt_lengths)\n",
        "\n",
        "    padded_src = []\n",
        "    padded_tgt = []\n",
        "\n",
        "    for src_indices, tgt_indices in zip(src_batch, tgt_batch):\n",
        "        # Pad v·ªõi <pad> token\n",
        "        padded_src.append(src_indices + [src_vocab.pad_idx] * (max_src_len - len(src_indices)))\n",
        "        padded_tgt.append(tgt_indices + [tgt_vocab.pad_idx] * (max_tgt_len - len(tgt_indices)))\n",
        "\n",
        "    # Convert to tensors\n",
        "    src_batch = torch.tensor(padded_src, dtype=torch.long, device=device)\n",
        "    tgt_batch = torch.tensor(padded_tgt, dtype=torch.long, device=device)\n",
        "    src_lengths = torch.tensor(src_lengths, dtype=torch.long, device=device)\n",
        "    tgt_lengths = torch.tensor(tgt_lengths, dtype=torch.long, device=device)\n",
        "\n",
        "    return src_batch, src_lengths, tgt_batch, tgt_lengths\n",
        "\n",
        "\n",
        "def save_vocab(vocab, filepath):\n",
        "    \"\"\"L∆∞u vocabulary\"\"\"\n",
        "    torch.save({\n",
        "        'token2idx': vocab.token2idx,\n",
        "        'idx2token': vocab.idx2token,\n",
        "        'max_size': vocab.max_size,\n",
        "        'min_freq': vocab.min_freq,\n",
        "        'special_tokens': vocab.special_tokens\n",
        "    }, filepath)\n",
        "    print(f\"ƒê√£ l∆∞u t·ª´ ƒëi·ªÉn v√†o {filepath}\")\n",
        "\n",
        "\n",
        "def load_vocab(filepath):\n",
        "    \"\"\"Load vocabulary\"\"\"\n",
        "    data = torch.load(filepath)\n",
        "    vocab = Vocabulary(\n",
        "        max_size=data['max_size'],\n",
        "        min_freq=data['min_freq'],\n",
        "        special_tokens=data['special_tokens']\n",
        "    )\n",
        "    vocab.token2idx = data['token2idx']\n",
        "    vocab.idx2token = data['idx2token']\n",
        "    print(f\"ƒê√£ t·∫£i t·ª´ ƒëi·ªÉn t·ª´ {filepath}\")\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"ƒê·∫øm s·ªë parameters c·ªßa model\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"T√≠nh th·ªùi gian ch·∫°y epoch\"\"\"\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test tokenization\n",
        "    test_sentence = \"Hello, how are you?\"\n",
        "    tokens = tokenize_sentence(test_sentence)\n",
        "    print(f\"K·∫øt qu·∫£ tokenize: {tokens}\")\n",
        "\n",
        "    # Test vocabulary\n",
        "    sentences = [\n",
        "        [\"hello\", \"world\"],\n",
        "        [\"hello\", \"how\", \"are\", \"you\"],\n",
        "        [\"world\", \"peace\"]\n",
        "    ]\n",
        "    vocab = Vocabulary(max_size=100)\n",
        "    vocab.build_vocab_from_iterator(sentences)\n",
        "    print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn: {len(vocab)}\")\n",
        "    print(f\"M√£ h√≥a 'hello': {vocab.encode(['hello'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiVoLY2dy_fQ"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skki4ULyzBn1",
        "outputId": "31453548-744b-46c5-fd0b-65604a916de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ki·ªÉm tra t·∫£i d·ªØ li·ªáu...\n",
            "============================================================\n",
            "X√ÇY D·ª∞NG T·ª™ ƒêI·ªÇN (VOCABULARIES)\n",
            "============================================================\n",
            "ƒê·ªçc d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´:\n",
            "  Source: /content/data/train.en\n",
            "  Target: /content/data/train.fr\n",
            "ƒê√£ t·∫£i 29000 c·∫∑p c√¢u\n",
            "\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Anh (source)...\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi 10000 token\n",
            "  - Special tokens: 4\n",
            "  - Token th∆∞·ªùng: 9996\n",
            "\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p (target)...\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi 10000 token\n",
            "  - Special tokens: 4\n",
            "  - Token th∆∞·ªùng: 9996\n",
            "============================================================\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Anh: 10000\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p: 10000\n",
            "============================================================\n",
            "ƒê√£ l∆∞u t·ª´ ƒëi·ªÉn v√†o /content/check_point/src_vocab.pth\n",
            "ƒê√£ l∆∞u t·ª´ ƒëi·ªÉn v√†o /content/check_point/tgt_vocab.pth\n",
            "============================================================\n",
            "CHU·∫®N B·ªä DATA LOADERS\n",
            "============================================================\n",
            "ƒêang t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p train: 29000\n",
            "ƒêang t·∫£i d·ªØ li·ªáu validation...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p val: 1014\n",
            "ƒêang t·∫£i d·ªØ li·ªáu test...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p test: 1000\n",
            "\n",
            "K√≠ch th∆∞·ªõc batch: 64\n",
            "S·ªë batch train: 454\n",
            "S·ªë batch val: 16\n",
            "S·ªë batch test: 16\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "KI·ªÇM TRA M·ªòT BATCH\n",
            "============================================================\n",
            "K√≠ch th∆∞·ªõc source batch: torch.Size([64, 29])\n",
            "K√≠ch th∆∞·ªõc source lengths: torch.Size([64])\n",
            "K√≠ch th∆∞·ªõc target batch: torch.Size([64, 33])\n",
            "K√≠ch th∆∞·ªõc target lengths: torch.Size([64])\n",
            "\n",
            "ƒê·ªô d√†i source (ƒë√£ s·∫Øp x·∫øp): [29, 26, 24, 21, 20]...\n",
            "ƒê·ªô d√†i target: [33, 31, 22, 21, 26]...\n",
            "\n",
            "--- C√¢u ƒë·∫ßu ti√™n trong batch ---\n",
            "Source (EN): <sos> a woman opens a gift while standing in a dining room that has been festively decorated : her face is obstructed by one of the decorations . <eos>\n",
            "Target (FR): <sos> une femme ouvre un cadeau tandis qu'elle se trouve dans une salle √† manger qui a √©t√© d√©cor√©e de fa√ßon festive : son visage est masqu√© par l'une des d√©corations . <eos>\n",
            "\n",
            "‚úÖ Ki·ªÉm tra t·∫£i d·ªØ li·ªáu ho√†n t·∫•t!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "import re\n",
        "\n",
        "# NOTE: Trong Colab, c√°c bi·∫øn n√†y ƒë√£ ƒë∆∞·ª£c define ·ªü cell Config\n",
        "# N·∫øu ch·∫°y file n√†y standalone, c·∫ßn uncomment c√°c d√≤ng d∆∞·ªõi:\n",
        "\n",
        "# from pathlib import Path\n",
        "# DATA_DIR = Path(\"/content/data\")\n",
        "# CHECKPOINT_DIR = Path(\"/content/check_point\")\n",
        "# TRAIN_EN = DATA_DIR / \"train.en\"\n",
        "# TRAIN_FR = DATA_DIR / \"train.fr\"\n",
        "# VAL_EN = DATA_DIR / \"val.en\"\n",
        "# VAL_FR = DATA_DIR / \"val.fr\"\n",
        "# TEST_EN = DATA_DIR / \"test.en\"\n",
        "# TEST_FR = DATA_DIR / \"test.fr\"\n",
        "# BATCH_SIZE = 64\n",
        "# MAX_SEQ_LENGTH = 50\n",
        "# MAX_VOCAB_SIZE = 10000\n",
        "# MIN_FREQ = 1\n",
        "# SPECIAL_TOKENS = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset cho b√†i to√°n Machine Translation\n",
        "    \"\"\"\n",
        "    def __init__(self, src_sentences, tgt_sentences):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src_sentences: List of tokenized source sentences\n",
        "            tgt_sentences: List of tokenized target sentences\n",
        "        \"\"\"\n",
        "        assert len(src_sentences) == len(tgt_sentences), \\\n",
        "            \"Source and target must have same length\"\n",
        "\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_sentences[idx], self.tgt_sentences[idx]\n",
        "\n",
        "\n",
        "def collate_batch_with_packing(batch, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"\n",
        "    Collate function v·ªõi sorting v√† packing\n",
        "    Y√™u c·∫ßu: S·∫Øp x·∫øp batch theo ƒë·ªô d√†i gi·∫£m d·∫ßn, s·ª≠ d·ª•ng pack_padded_sequence\n",
        "    \"\"\"\n",
        "    # Th√™m special tokens v√† encode\n",
        "    batch_data = []\n",
        "    for src_tokens, tgt_tokens in batch:\n",
        "        # Gi·ªõi h·∫°n ƒë·ªô d√†i v√† th√™m <sos>, <eos>\n",
        "        src_tokens = add_special_tokens(src_tokens[:max_len-2], add_sos=True, add_eos=True)\n",
        "        tgt_tokens = add_special_tokens(tgt_tokens[:max_len-2], add_sos=True, add_eos=True)\n",
        "\n",
        "        # Encode to indices\n",
        "        src_indices = src_vocab.encode(src_tokens)\n",
        "        tgt_indices = tgt_vocab.encode(tgt_tokens)\n",
        "\n",
        "        batch_data.append((src_indices, len(src_indices), tgt_indices, len(tgt_indices)))\n",
        "\n",
        "    # Sort by source length (descending) - y√™u c·∫ßu cho pack_padded_sequence\n",
        "    batch_data.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Unpack\n",
        "    src_batch = [item[0] for item in batch_data]\n",
        "    src_lengths = [item[1] for item in batch_data]\n",
        "    tgt_batch = [item[2] for item in batch_data]\n",
        "    tgt_lengths = [item[3] for item in batch_data]\n",
        "\n",
        "    # Padding\n",
        "    max_src_len = max(src_lengths)\n",
        "    max_tgt_len = max(tgt_lengths)\n",
        "\n",
        "    padded_src = []\n",
        "    padded_tgt = []\n",
        "\n",
        "    for src_indices, tgt_indices in zip(src_batch, tgt_batch):\n",
        "        padded_src.append(src_indices + [src_vocab.pad_idx] * (max_src_len - len(src_indices)))\n",
        "        padded_tgt.append(tgt_indices + [tgt_vocab.pad_idx] * (max_tgt_len - len(tgt_indices)))\n",
        "\n",
        "    # Convert to tensors\n",
        "    src_batch = torch.tensor(padded_src, dtype=torch.long, device=device)\n",
        "    tgt_batch = torch.tensor(padded_tgt, dtype=torch.long, device=device)\n",
        "    src_lengths = torch.tensor(src_lengths, dtype=torch.long, device='cpu')  # lengths ph·∫£i ·ªü CPU\n",
        "    tgt_lengths = torch.tensor(tgt_lengths, dtype=torch.long, device='cpu')\n",
        "\n",
        "    return src_batch, src_lengths, tgt_batch, tgt_lengths\n",
        "\n",
        "\n",
        "def build_vocabularies(train_src_file, train_tgt_file, max_vocab_size=10000):\n",
        "    \"\"\"\n",
        "    X√¢y d·ª±ng vocabularies t·ª´ training data\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"X√ÇY D·ª∞NG T·ª™ ƒêI·ªÇN (VOCABULARIES)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # ƒê·ªçc training data\n",
        "    print(f\"ƒê·ªçc d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´:\")\n",
        "    print(f\"  Source: {train_src_file}\")\n",
        "    print(f\"  Target: {train_tgt_file}\")\n",
        "\n",
        "    src_sentences, tgt_sentences = read_parallel_corpus(\n",
        "        train_src_file,\n",
        "        train_tgt_file,\n",
        "        tokenize_fn=tokenize_sentence\n",
        "    )\n",
        "\n",
        "    print(f\"ƒê√£ t·∫£i {len(src_sentences)} c·∫∑p c√¢u\")\n",
        "\n",
        "    # Build source vocabulary\n",
        "    print(\"\\nX√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Anh (source)...\")\n",
        "    src_vocab = Vocabulary(\n",
        "        max_size=max_vocab_size,\n",
        "        min_freq=MIN_FREQ,\n",
        "        special_tokens=SPECIAL_TOKENS\n",
        "    )\n",
        "    src_vocab.build_vocab_from_iterator(src_sentences)\n",
        "\n",
        "    # Build target vocabulary\n",
        "    print(\"\\nX√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p (target)...\")\n",
        "    tgt_vocab = Vocabulary(\n",
        "        max_size=max_vocab_size,\n",
        "        min_freq=MIN_FREQ,\n",
        "        special_tokens=SPECIAL_TOKENS\n",
        "    )\n",
        "    tgt_vocab.build_vocab_from_iterator(tgt_sentences)\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Anh: {len(src_vocab)}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p: {len(tgt_vocab)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return src_vocab, tgt_vocab\n",
        "\n",
        "\n",
        "def prepare_data_loaders(src_vocab, tgt_vocab, batch_size=64):\n",
        "    \"\"\"\n",
        "    Chu·∫©n b·ªã DataLoaders cho train, val, test\n",
        "\n",
        "    Args:\n",
        "        src_vocab: Source vocabulary\n",
        "        tgt_vocab: Target vocabulary\n",
        "        batch_size: Batch size (32-128 theo ƒë·ªÅ b√†i)\n",
        "\n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"CHU·∫®N B·ªä DATA LOADERS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load train data\n",
        "    print(\"ƒêang t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán...\")\n",
        "    train_src, train_tgt = read_parallel_corpus(TRAIN_EN, TRAIN_FR)\n",
        "    train_dataset = TranslationDataset(train_src, train_tgt)\n",
        "    print(f\"  K√≠ch th∆∞·ªõc t·∫≠p train: {len(train_dataset)}\")\n",
        "\n",
        "    # Load val data\n",
        "    print(\"ƒêang t·∫£i d·ªØ li·ªáu validation...\")\n",
        "    val_src, val_tgt = read_parallel_corpus(VAL_EN, VAL_FR)\n",
        "    val_dataset = TranslationDataset(val_src, val_tgt)\n",
        "    print(f\"  K√≠ch th∆∞·ªõc t·∫≠p val: {len(val_dataset)}\")\n",
        "\n",
        "    # Load test data\n",
        "    print(\"ƒêang t·∫£i d·ªØ li·ªáu test...\")\n",
        "    test_src, test_tgt = read_parallel_corpus(TEST_EN, TEST_FR)\n",
        "    test_dataset = TranslationDataset(test_src, test_tgt)\n",
        "    print(f\"  K√≠ch th∆∞·ªõc t·∫≠p test: {len(test_dataset)}\")\n",
        "\n",
        "    # Create collate function\n",
        "    def collate_fn_wrapper(batch):\n",
        "        return collate_batch_with_packing(\n",
        "            batch, src_vocab, tgt_vocab, DEVICE, MAX_SEQ_LENGTH\n",
        "        )\n",
        "\n",
        "    # Create DataLoaders\n",
        "    # enforce_sorted=True ƒë·ªÉ s·ª≠ d·ª•ng pack_padded_sequence\n",
        "    # NOTE: pin_memory=False v√¨ tensor ƒë√£ ƒë∆∞·ª£c chuy·ªÉn l√™n GPU trong collate_fn\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,  # Shuffle training data\n",
        "        collate_fn=collate_fn_wrapper,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn_wrapper,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn_wrapper,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\nK√≠ch th∆∞·ªõc batch: {batch_size}\")\n",
        "    print(f\"S·ªë batch train: {len(train_loader)}\")\n",
        "    print(f\"S·ªë batch val: {len(val_loader)}\")\n",
        "    print(f\"S·ªë batch test: {len(test_loader)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def test_data_loading():\n",
        "    \"\"\"\n",
        "    Test function ƒë·ªÉ ki·ªÉm tra data loading\n",
        "    \"\"\"\n",
        "    print(\"Ki·ªÉm tra t·∫£i d·ªØ li·ªáu...\")\n",
        "\n",
        "    # Build vocabularies\n",
        "    src_vocab, tgt_vocab = build_vocabularies(TRAIN_EN, TRAIN_FR, MAX_VOCAB_SIZE)\n",
        "\n",
        "    # Save vocabularies\n",
        "    save_vocab(src_vocab, CHECKPOINT_DIR / \"src_vocab.pth\")\n",
        "    save_vocab(tgt_vocab, CHECKPOINT_DIR / \"tgt_vocab.pth\")\n",
        "\n",
        "    # Prepare data loaders\n",
        "    train_loader, val_loader, test_loader = prepare_data_loaders(\n",
        "        src_vocab, tgt_vocab, BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # Test m·ªôt batch\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"KI·ªÇM TRA M·ªòT BATCH\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for src_batch, src_lengths, tgt_batch, tgt_lengths in train_loader:\n",
        "        print(f\"K√≠ch th∆∞·ªõc source batch: {src_batch.shape}\")\n",
        "        print(f\"K√≠ch th∆∞·ªõc source lengths: {src_lengths.shape}\")\n",
        "        print(f\"K√≠ch th∆∞·ªõc target batch: {tgt_batch.shape}\")\n",
        "        print(f\"K√≠ch th∆∞·ªõc target lengths: {tgt_lengths.shape}\")\n",
        "\n",
        "        print(f\"\\nƒê·ªô d√†i source (ƒë√£ s·∫Øp x·∫øp): {src_lengths.tolist()[:5]}...\")\n",
        "        print(f\"ƒê·ªô d√†i target: {tgt_lengths.tolist()[:5]}...\")\n",
        "\n",
        "        # Decode first sentence\n",
        "        print(\"\\n--- C√¢u ƒë·∫ßu ti√™n trong batch ---\")\n",
        "        src_tokens = src_vocab.decode(src_batch[0].tolist())\n",
        "        tgt_tokens = tgt_vocab.decode(tgt_batch[0].tolist())\n",
        "\n",
        "        print(f\"Source (EN): {' '.join(src_tokens[:src_lengths[0]])}\")\n",
        "        print(f\"Target (FR): {' '.join(tgt_tokens[:tgt_lengths[0]])}\")\n",
        "\n",
        "        break\n",
        "\n",
        "    print(\"\\n‚úÖ Ki·ªÉm tra t·∫£i d·ªØ li·ªáu ho√†n t·∫•t!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run test\n",
        "    test_data_loading()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8YLSzn4HV5"
      },
      "source": [
        "### X√¢y d·ª±ng t·ª´ ƒëi·ªÉn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu_Z41Ok4Jpt",
        "outputId": "8fab59e9-ba2a-46be-a754-3b3bfa2c0046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabularies...\n",
            "============================================================\n",
            "X√ÇY D·ª∞NG T·ª™ ƒêI·ªÇN (VOCABULARIES)\n",
            "============================================================\n",
            "ƒê·ªçc d·ªØ li·ªáu hu·∫•n luy·ªán t·ª´:\n",
            "  Source: /content/data/train.en\n",
            "  Target: /content/data/train.fr\n",
            "ƒê√£ t·∫£i 29000 c·∫∑p c√¢u\n",
            "\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Anh (source)...\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi 10000 token\n",
            "  - Special tokens: 4\n",
            "  - Token th∆∞·ªùng: 9996\n",
            "\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p (target)...\n",
            "X√¢y d·ª±ng t·ª´ ƒëi·ªÉn v·ªõi 10000 token\n",
            "  - Special tokens: 4\n",
            "  - Token th∆∞·ªùng: 9996\n",
            "============================================================\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Anh: 10000\n",
            "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p: 10000\n",
            "============================================================\n",
            "ƒê√£ l∆∞u t·ª´ ƒëi·ªÉn v√†o /content/check_point/src_vocab.pth\n",
            "ƒê√£ l∆∞u t·ª´ ƒëi·ªÉn v√†o /content/check_point/tgt_vocab.pth\n",
            "‚úÖ English vocab: 10000 tokens\n",
            "‚úÖ French vocab: 10000 tokens\n"
          ]
        }
      ],
      "source": [
        "# ============ BUILD VOCABULARIES ============\n",
        "print(\"Building vocabularies...\")\n",
        "src_vocab, tgt_vocab = build_vocabularies(TRAIN_EN, TRAIN_FR, MAX_VOCAB_SIZE)\n",
        "\n",
        "# Save vocabularies\n",
        "save_vocab(src_vocab, CHECKPOINT_DIR / \"src_vocab.pth\")\n",
        "save_vocab(tgt_vocab, CHECKPOINT_DIR / \"tgt_vocab.pth\")\n",
        "\n",
        "print(f\"‚úÖ English vocab: {len(src_vocab)} tokens\")\n",
        "print(f\"‚úÖ French vocab: {len(tgt_vocab)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qam_3CR546ki"
      },
      "source": [
        "### T·∫°o DataLoader ƒë·ªÉ chia data th√†nh c√°c batch ph·ª•c v·ª• training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwk1osbn5BeO",
        "outputId": "096b2f86-456d-4c11-d4a1-4db681e87066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHU·∫®N B·ªä DATA LOADERS\n",
            "============================================================\n",
            "ƒêang t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p train: 29000\n",
            "ƒêang t·∫£i d·ªØ li·ªáu validation...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p val: 1014\n",
            "ƒêang t·∫£i d·ªØ li·ªáu test...\n",
            "  K√≠ch th∆∞·ªõc t·∫≠p test: 1000\n",
            "\n",
            "K√≠ch th∆∞·ªõc batch: 64\n",
            "S·ªë batch train: 454\n",
            "S·ªë batch val: 16\n",
            "S·ªë batch test: 16\n",
            "============================================================\n",
            "‚úÖ Source batch: torch.Size([64, 29])\n",
            "‚úÖ Target batch: torch.Size([64, 31])\n",
            "‚úÖ Source lengths (sorted): tensor([29, 28, 26, 21, 20])\n"
          ]
        }
      ],
      "source": [
        "# ============ PREPARE DATALOADERS ============\n",
        "\n",
        "# G·ªçi h√†m prepare_data_loaders() t·ª´ data_loader.py\n",
        "# Input:\n",
        "#   - src_vocab, tgt_vocab: t·ª´ ƒëi·ªÉn ƒë√£ build ·ªü Cell 6\n",
        "#   - BATCH_SIZE: 64 c√¢u/batch\n",
        "# Output:\n",
        "#   - train_loader: 454 batches (29,000 c√¢u / 64 = 454)\n",
        "#   - val_loader: 16 batches (1,014 c√¢u / 64 = 16)\n",
        "#   - test_loader: 16 batches (1,000 c√¢u / 64 = 16)\n",
        "train_loader, val_loader, test_loader = prepare_data_loaders(\n",
        "    src_vocab, tgt_vocab, BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Test xem DataLoader ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng\n",
        "# L·∫•y 1 batch ƒë·∫ßu ti√™n t·ª´ train_loader\n",
        "for src_batch, src_lengths, tgt_batch, tgt_lengths in train_loader:\n",
        "    # src_batch: tensor ch·ª©a 64 c√¢u ti·∫øng Anh (ƒë√£ padding)\n",
        "    print(f\"‚úÖ Source batch: {src_batch.shape}\")  # VD: torch.Size([64, 25])\n",
        "\n",
        "    # tgt_batch: tensor ch·ª©a 64 c√¢u ti·∫øng Ph√°p (ƒë√£ padding)\n",
        "    print(f\"‚úÖ Target batch: {tgt_batch.shape}\")  # VD: torch.Size([64, 28])\n",
        "\n",
        "    # src_lengths: ƒë·ªô d√†i th·ª±c c·ªßa 5 c√¢u ƒë·∫ßu (ƒë√£ s·∫Øp x·∫øp gi·∫£m d·∫ßn)\n",
        "    print(f\"‚úÖ Source lengths (sorted): {src_lengths[:5]}\")  # VD: [25, 23, 20, 18, 15]\n",
        "\n",
        "    break  # Ch·ªâ test 1 batch r·ªìi d·ª´ng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTnJ5acKt9DH"
      },
      "source": [
        "### B∆Ø·ªöC 3 - X√ÇY D·ª∞NG M√î H√åNH (ENCODER - DECODER)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZboSLFUruMck"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "# ============ 1. ENCODER ============\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        # batch_first=True v√¨ DataLoader c·ªßa Th·∫Øng tr·∫£ v·ªÅ [Batch Size, Seq Len]\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers,\n",
        "                            dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_len: [batch_size]\n",
        "\n",
        "        # 1. Embedding\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded: [batch_size, src_len, emb_dim]\n",
        "\n",
        "        # 2. Pack Sequence (ƒê·ªÉ LSTM b·ªè qua c√°c token <pad>)\n",
        "        # src_len ph·∫£i ·ªü tr√™n CPU (Code c·ªßa Th·∫Øng ƒë√£ l√†m ƒë√∫ng vi·ªác n√†y)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu(), batch_first=True)\n",
        "\n",
        "        # 3. Pass qua LSTM\n",
        "        packed_outputs, (hidden, cell) = self.lstm(packed_embedded)\n",
        "\n",
        "        # hidden, cell: [n_layers, batch_size, hid_dim]\n",
        "        # ƒê√¢y ch√≠nh l√† CONTEXT VECTOR s·∫Ω chuy·ªÉn sang Decoder\n",
        "\n",
        "        return hidden, cell\n",
        "\n",
        "# ============ 2. DECODER ============\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Output dim ch√≠nh l√† k√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ti·∫øng Ph√°p\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        # LSTM Decoder\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers,\n",
        "                            dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Linear layer ƒë·ªÉ d·ª± ƒëo√°n t·ª´ ti·∫øp theo\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input: [batch_size] (ch·ªâ 1 t·ª´ t·∫°i 1 th·ªùi ƒëi·ªÉm)\n",
        "        # hidden, cell: context vector t·ª´ b∆∞·ªõc tr∆∞·ªõc\n",
        "\n",
        "        # Th√™m chi·ªÅu sequence len = 1\n",
        "        input = input.unsqueeze(1)\n",
        "        # input: [batch_size, 1]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded: [batch_size, 1, emb_dim]\n",
        "\n",
        "        # Decoder ch·∫°y t·ª´ng b∆∞·ªõc n√™n kh√¥ng c·∫ßn pack_padded_sequence\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "\n",
        "        # output: [batch_size, 1, hid_dim]\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        # prediction: [batch_size, output_vocab_size]\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "# ============ 3. SEQ2SEQ (G·ªòP C·∫¢ 2) ============\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        # Ki·ªÉm tra hidden size ph·∫£i kh·ªõp nhau\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, src_len, tgt, teacher_forcing_ratio=0.5):\n",
        "        # src: [batch_size, src_len]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        tgt_len = tgt.shape[1]\n",
        "        tgt_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Tensor ƒë·ªÉ ch·ª©a k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "\n",
        "        # 1. Encode source sentence -> l·∫•y context vector (hidden, cell)\n",
        "        hidden, cell = self.encoder(src, src_len)\n",
        "\n",
        "        # Input ƒë·∫ßu ti√™n cho decoder l√† <sos> token\n",
        "        input = tgt[:, 0]\n",
        "\n",
        "        # 2. Decode t·ª´ng b∆∞·ªõc\n",
        "        # B·∫Øt ƒë·∫ßu t·ª´ 1 v√¨ v·ªã tr√≠ 0 l√† <sos> ƒë√£ bi·∫øt r·ªìi\n",
        "        for t in range(1, tgt_len):\n",
        "\n",
        "            # Pass qua decoder\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            # L∆∞u prediction\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            # Quy·∫øt ƒë·ªãnh Teacher Forcing\n",
        "            # N·∫øu random < ratio -> d√πng t·ª´ th·∫≠t (ground truth) l√†m input ti·∫øp theo\n",
        "            # Ng∆∞·ª£c l·∫°i -> d√πng t·ª´ d·ª± ƒëo√°n cao nh·∫•t l√†m input\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            input = tgt[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvDZFrxmuOsm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AdF97BnuTq5"
      },
      "source": [
        "### THI·∫æT L·∫¨P HU·∫§N LUY·ªÜN (INIT, LOSS, OPTIMIZER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfgf9eFquUoJ",
        "outputId": "7a546b23-b637-44a8-9a60-6f28297f0b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M√¥ h√¨nh c√≥ 17,606,416 tham s·ªë train ƒë∆∞·ª£c\n"
          ]
        }
      ],
      "source": [
        "# ============ KH·ªûI T·∫†O MODEL ============\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(tgt_vocab)\n",
        "\n",
        "# Kh·ªüi t·∫°o Encoder & Decoder\n",
        "enc = Encoder(INPUT_DIM, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "\n",
        "# G·ªôp th√†nh model Seq2Seq\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "# H√†m kh·ªüi t·∫°o tr·ªçng s·ªë (gi√∫p model h·ªôi t·ª• nhanh h∆°n)\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'M√¥ h√¨nh c√≥ {sum(p.numel() for p in model.parameters() if p.requires_grad):,} tham s·ªë train ƒë∆∞·ª£c')\n",
        "\n",
        "# ============ OPTIMIZER & LOSS ============\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Quan tr·ªçng: B·ªè qua loss t√≠nh tr√™n c√°c token <pad>\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAYkn4BhualS"
      },
      "source": [
        "### B∆Ø·ªöC 4 - V√íNG L·∫∂P TRAIN & EVALUATE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV9kbFb4ubbC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# H√†m Train 1 epoch\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, src_len, tgt, tgt_len) in enumerate(iterator):\n",
        "        # src, tgt ƒë√£ ·ªü tr√™n GPU nh·ªù collate_fn\n",
        "        # src_len ·ªü tr√™n CPU (ƒë√∫ng y√™u c·∫ßu)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(src, src_len, tgt, TEACHER_FORCING_RATIO)\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        # Lo·∫°i b·ªè token ƒë·∫ßu ti√™n (<sos>) khi t√≠nh loss v√¨ ta kh√¥ng d·ª± ƒëo√°n n√≥\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "        # T√≠nh loss\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping (tr√°nh b√πng n·ªï gradient trong LSTM)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# H√†m Evaluate (kh√¥ng d√πng Teacher Forcing)\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, src_len, tgt, tgt_len) in enumerate(iterator):\n",
        "\n",
        "            # T·∫Øt teacher forcing khi eval (0)\n",
        "            output = model(src, src_len, tgt, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# H√†m t√≠nh th·ªùi gian\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkQr4P8yufj8"
      },
      "source": [
        "### CH·∫†Y HU·∫§N LUY·ªÜN (MAIN LOOP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hTeB18QnugSK",
        "outputId": "611c7885-5289-4808-fb3c-60a1e44c7139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán 15 epochs...\n",
            "------------------------------------------------------------\n",
            "Epoch: 01 | Time: 1m 9s\n",
            "\tTrain Loss: 4.865 | Train PPL: 129.660\n",
            "\t Val. Loss: 4.801 |  Val. PPL: 121.587 --> Saved Best Model\n",
            "Epoch: 02 | Time: 1m 9s\n",
            "\tTrain Loss: 4.052 | Train PPL:  57.526\n",
            "\t Val. Loss: 4.564 |  Val. PPL:  95.978 --> Saved Best Model\n",
            "Epoch: 03 | Time: 1m 9s\n",
            "\tTrain Loss: 3.621 | Train PPL:  37.387\n",
            "\t Val. Loss: 4.222 |  Val. PPL:  68.172 --> Saved Best Model\n",
            "Epoch: 04 | Time: 1m 8s\n",
            "\tTrain Loss: 3.241 | Train PPL:  25.557\n",
            "\t Val. Loss: 3.792 |  Val. PPL:  44.328 --> Saved Best Model\n",
            "Epoch: 05 | Time: 1m 8s\n",
            "\tTrain Loss: 2.889 | Train PPL:  17.978\n",
            "\t Val. Loss: 3.657 |  Val. PPL:  38.731 --> Saved Best Model\n",
            "Epoch: 06 | Time: 1m 8s\n",
            "\tTrain Loss: 2.612 | Train PPL:  13.620\n",
            "\t Val. Loss: 3.502 |  Val. PPL:  33.193 --> Saved Best Model\n",
            "Epoch: 07 | Time: 1m 10s\n",
            "\tTrain Loss: 2.366 | Train PPL:  10.653\n",
            "\t Val. Loss: 3.380 |  Val. PPL:  29.379 --> Saved Best Model\n",
            "Epoch: 08 | Time: 1m 9s\n",
            "\tTrain Loss: 2.157 | Train PPL:   8.646\n",
            "\t Val. Loss: 3.361 |  Val. PPL:  28.818 --> Saved Best Model\n",
            "Epoch: 09 | Time: 1m 8s\n",
            "\tTrain Loss: 1.963 | Train PPL:   7.119\n",
            "\t Val. Loss: 3.248 |  Val. PPL:  25.751 --> Saved Best Model\n",
            "Epoch: 10 | Time: 1m 9s\n",
            "\tTrain Loss: 1.779 | Train PPL:   5.925\n",
            "\t Val. Loss: 3.277 |  Val. PPL:  26.500 \n",
            "Epoch: 11 | Time: 1m 7s\n",
            "\tTrain Loss: 1.625 | Train PPL:   5.079\n",
            "\t Val. Loss: 3.176 |  Val. PPL:  23.951 --> Saved Best Model\n",
            "Epoch: 12 | Time: 1m 8s\n",
            "\tTrain Loss: 1.482 | Train PPL:   4.401\n",
            "\t Val. Loss: 3.226 |  Val. PPL:  25.187 \n",
            "Epoch: 13 | Time: 1m 8s\n",
            "\tTrain Loss: 1.374 | Train PPL:   3.949\n",
            "\t Val. Loss: 3.192 |  Val. PPL:  24.348 \n",
            "Epoch: 14 | Time: 1m 8s\n",
            "\tTrain Loss: 1.249 | Train PPL:   3.488\n",
            "\t Val. Loss: 3.261 |  Val. PPL:  26.074 \n",
            "Epoch: 15 | Time: 1m 8s\n",
            "\tTrain Loss: 1.162 | Train PPL:   3.195\n",
            "\t Val. Loss: 3.321 |  Val. PPL:  27.677 \n",
            "------------------------------------------------------------\n",
            "Hu·∫•n luy·ªán ho√†n t·∫•t!\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHWCAYAAABACtmGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhkZJREFUeJzs3Xd4lFX6xvHvpPcKpBFCC53QOwIKCogIYkEWBewFVFZllbUswioq9rJi+SnqLqAioKgoRar03ntIAqTQ0kmd+f0xYSAkTAIkeVPuz3XNlcz7vjPzDKHMzTnnOSaLxWJBRERERERELsvB6AJEREREREQqOwUnERERERGREig4iYiIiIiIlEDBSUREREREpAQKTiIiIiIiIiVQcBIRERERESmBgpOIiIiIiEgJFJxERERERERKoOAkIiIiIiJSAgUnEZEqasyYMdSvX/+qHjtp0iRMJlPZFlTFLV++HJPJxPLly23HSvtrfPToUUwmEzNmzCjTmurXr8+YMWPK9DlFROTqKDiJiJQxk8lUqtvFH9BrGrPZzFtvvUVkZCTu7u40atSIxx57jPT09FI9Pioqinr16mGxWC57TY8ePQgKCiIvL6+syi4Xa9asYdKkSSQnJxtdis2MGTMwmUxs2rTJ6FJERCoNJ6MLEBGpbr799ttC97/55hsWL15c5Hjz5s2v6XU+//xzzGbzVT32xRdf5Pnnn7+m178W77//PhMmTGDo0KFMmDCBmJgYZs2axXPPPYeXl1eJjx85ciTPP/88q1atolevXkXOHz16lLVr1zJu3DicnK7+n7pr+TUurTVr1vDKK68wZswY/Pz8Cp3bv38/Dg76P04RkcpAwUlEpIzdc889he6vW7eOxYsXFzl+qczMTDw8PEr9Os7OzldVH4CTk9M1BYprNXv2bFq2bMncuXNtUwanTJlS6pDyt7/9jYkTJzJz5sxig9OsWbOwWCyMHDnymuq8ll/jsuDq6mro64uIyAX6bywREQP06dOHVq1asXnzZnr16oWHhwf//Oc/Afjpp58YNGgQoaGhuLq60qhRI6ZMmUJ+fn6h57h0/c35dTZvvfUWn332GY0aNcLV1ZVOnTqxcePGQo8tbo2TyWRi3LhxzJ8/n1atWuHq6krLli35/fffi9S/fPlyOnbsiJubG40aNeLTTz+9onVTDg4OmM3mQtc7ODiUOsyFh4fTq1cv5syZQ25ubpHzM2fOpFGjRnTp0oWYmBgef/xxmjZtiru7O4GBgdx5550cPXq0xNcpbo1TcnIyY8aMwdfXFz8/P0aPHl3sNLsdO3YwZswYGjZsiJubG8HBwdx///2cPn3ads2kSZOYMGECAA0aNLBN4zxfW3FrnI4cOcKdd95JQEAAHh4edO3alV9//bXQNefXa33//fe8+uqr1K1bFzc3N/r27cuhQ4dKfN+ltXXrVgYOHIiPjw9eXl707duXdevWFbomNzeXV155hcjISNzc3AgMDKRnz54sXrzYdk1CQgL33XcfdevWxdXVlZCQEIYMGVKqn5GISEXRiJOIiEFOnz7NwIEDufvuu7nnnnsICgoCrOtLvLy8ePrpp/Hy8uLPP//k5ZdfJjU1lWnTppX4vDNnziQtLY1HHnkEk8nEm2++ybBhwzhy5EiJIyirV69m7ty5PP7443h7e/PBBx9w++23ExsbS2BgIGD9sDxgwABCQkJ45ZVXyM/PZ/LkydSuXbvU7/2+++7jkUce4dNPP+WRRx4p9eMuNnLkSB5++GH++OMPbrnlFtvxnTt3smvXLl5++WUANm7cyJo1a7j77rupW7cuR48e5ZNPPqFPnz7s2bPnikb5LBYLQ4YMYfXq1Tz66KM0b96cefPmMXr06CLXLl68mCNHjnDfffcRHBzM7t27+eyzz9i9ezfr1q3DZDIxbNgwDhw4wKxZs3j33XepVasWwGV/LRMTE+nevTuZmZk8+eSTBAYG8vXXX3PrrbcyZ84cbrvttkLXv/766zg4OPDss8+SkpLCm2++yciRI1m/fn2p3/Pl7N69m+uuuw4fHx/+8Y9/4OzszKeffkqfPn1YsWIFXbp0AazhcOrUqTz44IN07tyZ1NRUNm3axJYtW7jxxhsBuP3229m9ezdPPPEE9evXJykpicWLFxMbG3vVDVBERMqcRUREytXYsWMtl/5127t3bwtgmT59epHrMzMzixx75JFHLB4eHpasrCzbsdGjR1siIiJs96Ojoy2AJTAw0HLmzBnb8Z9++skCWBYsWGA79q9//atITYDFxcXFcujQIdux7du3WwDLhx9+aDs2ePBgi4eHh+X48eO2YwcPHrQ4OTkVec7Lef755y0uLi4WR0dHy9y5c0v1mEudOXPG4urqahkxYkSR5wYs+/fvt1gsxf96rl271gJYvvnmG9uxZcuWWQDLsmXLbMcu/TWeP3++BbC8+eabtmN5eXmW6667zgJYvvrqK9vx4l531qxZFsCycuVK27Fp06ZZAEt0dHSR6yMiIiyjR4+23R8/frwFsKxatcp2LC0tzdKgQQNL/fr1Lfn5+YXeS/PmzS3Z2dm2a99//30LYNm5c2eR17rYV199ZQEsGzduvOw1Q4cOtbi4uFgOHz5sO3bixAmLt7e3pVevXrZjbdq0sQwaNOiyz3P27FkLYJk2bZrdmkREjKapeiIiBnF1deW+++4rctzd3d32fVpaGqdOneK6664jMzOTffv2lfi8w4cPx9/f33b/uuuuA6xTvErSr18/GjVqZLsfFRWFj4+P7bH5+fksWbKEoUOHEhoaaruucePGDBw4sMTnB/jggw945513+OuvvxgxYgR33303ixYtKnSNq6srL730kt3n8ff35+abb+bnn38mIyMDsI4IzZ49m44dO9KkSROg8K9nbm4up0+fpnHjxvj5+bFly5ZS1Xzeb7/9hpOTE4899pjtmKOjI0888USRay9+3aysLE6dOkXXrl0Brvh1L379zp0707NnT9sxLy8vHn74YY4ePcqePXsKXX/ffffh4uJiu38lvxfsyc/PZ9GiRQwdOpSGDRvajoeEhPC3v/2N1atXk5qaCoCfnx+7d+/m4MGDxT6Xu7s7Li4uLF++nLNnz15TXSIi5UnBSUTEIGFhYYU+1J63e/dubrvtNnx9ffHx8aF27dq2xhIpKSklPm+9evUK3T8fokrzofTSx55//PnHJiUlce7cORo3blzkuuKOXercuXP861//4sEHH6Rjx4589dVX3HDDDdx2222sXr0agIMHD5KTk2Ob6mXPyJEjycjI4KeffgKsHeqOHj1aqCnEuXPnePnllwkPD8fV1ZVatWpRu3ZtkpOTS/XrebGYmBhCQkKKdP5r2rRpkWvPnDnDU089RVBQEO7u7tSuXZsGDRoApfs5Xu71i3ut8x0aY2JiCh2/lt8L9pw8eZLMzMzL1mI2m4mLiwNg8uTJJCcn06RJE1q3bs2ECRPYsWOH7XpXV1feeOMNFi5cSFBQEL169eLNN98kISHhmmoUESlrCk4iIga5eETivOTkZHr37s327duZPHkyCxYsYPHixbzxxhsApeo65+joWOxxi509j8risaWxd+9ekpOTbSMvTk5OzJkzh1atWjFo0CC2bNnCZ599Rp06dWzrX+y55ZZb8PX1ZebMmYB1fZejoyN333237ZonnniCV199lbvuuovvv/+eRYsWsXjxYgIDA8u11fhdd93F559/zqOPPsrcuXNZtGiRrdFGebc4P6+8f56l0atXLw4fPsyXX35Jq1at+OKLL2jfvj1ffPGF7Zrx48dz4MABpk6dipubGy+99BLNmzdn69atFVaniEhJ1BxCRKQSWb58OadPn2bu3LmF2mxHR0cbWNUFderUwc3NrdjObKXp1na+i9750QgAT09PfvvtN3r27En//v3Jysri3//+d6lacbu6unLHHXfwzTffkJiYyA8//MANN9xAcHCw7Zo5c+YwevRo3n77bduxrKysq9pwNiIigqVLl5Kenl5o1Gn//v2Frjt79ixLly7llVdesTWpAIqdrlbaToTnX//S1wJsUzgjIiJK/VzXonbt2nh4eFy2FgcHB8LDw23HAgICuO+++7jvvvtIT0+nV69eTJo0iQcffNB2TaNGjXjmmWd45plnOHjwIG3btuXtt9/mv//9b4W8JxGRkmjESUSkEjk/QnDxiEBOTg7/+c9/jCqpEEdHR/r168f8+fM5ceKE7fihQ4dYuHBhiY9v3bo1QUFBfPTRRyQlJdmOBwYG8tVXX3Hq1CnOnTvH4MGDS13TyJEjyc3N5ZFHHuHkyZNF9m5ydHQsMsLy4YcfFmnvXho333wzeXl5fPLJJ7Zj+fn5fPjhh0VeE4qO7Lz33ntFntPT0xOgVEHu5ptvZsOGDaxdu9Z2LCMjg88++4z69evTokWL0r6Va+Lo6MhNN93ETz/9VKhleGJiIjNnzqRnz574+PgAFGq/DtY1WY0bNyY7Oxuw7l+WlZVV6JpGjRrh7e1tu0ZEpDLQiJOISCXSvXt3/P39GT16NE8++SQmk4lvv/22QqdWlWTSpEksWrSIHj168Nhjj5Gfn89HH31Eq1at2LZtm93HOjk58dFHHzF8+HBat27NI488QkREBHv37uXLL7+kdevWHDt2jCFDhvDXX3/ZPnzb07t3b+rWrctPP/2Eu7s7w4YNK3T+lltu4dtvv8XX15cWLVqwdu1alixZYmuvfiUGDx5Mjx49eP755zl69CgtWrRg7ty5RdYs+fj42Nbq5ObmEhYWxqJFi4odOezQoQMAL7zwAnfffTfOzs4MHjzYFqgu9vzzzzNr1iwGDhzIk08+SUBAAF9//TXR0dH8+OOPODiU7f+Hfvnll8Xu4/XUU0/x73//m8WLF9OzZ08ef/xxnJyc+PTTT8nOzubNN9+0XduiRQv69OlDhw4dCAgIYNOmTcyZM4dx48YBcODAAfr27ctdd91FixYtcHJyYt68eSQmJhaacikiYjQFJxGRSiQwMJBffvmFZ555hhdffBF/f3/uuece+vbtS//+/Y0uD7B+0F+4cCHPPvssL730EuHh4UyePJm9e/eWquvfHXfcwfLly3n11Vd5//33yc7OJjIykn/84x889dRTrFixgkGDBnHnnXfy66+/lrgproODAyNGjGDatGkMHjwYb2/vQufff/99HB0d+d///kdWVhY9evRgyZIlV/Xr6eDgwM8//8z48eP573//i8lk4tZbb+Xtt9+mXbt2ha6dOXMmTzzxBB9//DEWi4WbbrqJhQsXFupGCNCpUyemTJnC9OnT+f333zGbzURHRxcbnIKCglizZg3PPfccH374IVlZWURFRbFgwQIGDRp0xe+nJBePrF1szJgxtGzZklWrVjFx4kSmTp2K2WymS5cu/Pe//y3U2OPJJ5/k559/ZtGiRWRnZxMREcG///1v28a/4eHhjBgxgqVLl/Ltt9/i5OREs2bN+P7777n99tvL/D2JiFwtk6Uy/TemiIhUWUOHDrXbdlpERKQq0xonERG5YufOnSt0/+DBg/z222/06dPHmIJERETKmUacRETkioWEhDBmzBgaNmxITEwMn3zyCdnZ2WzdupXIyEijyxMRESlzWuMkIiJXbMCAAcyaNYuEhARcXV3p1q0br732mkKTiIhUWxpxEhERERERKYHWOImIiIiIiJRAwUlERERERKQENW6Nk9ls5sSJE3h7e2MymYwuR0REREREDGKxWEhLSyM0NLTETcRrXHA6ceIE4eHhRpchIiIiIiKVRFxcHHXr1rV7jaHBadKkSbzyyiuFjjVt2tTuzvM//PADL730EkePHiUyMpI33niDm2++udSveX5H+bi4OHx8fK6ucBERERERqfJSU1MJDw+3ZQR7DB9xatmyJUuWLLHdd3K6fElr1qxhxIgRTJ06lVtuuYWZM2cydOhQtmzZQqtWrUr1euen5/n4+Cg4iYiIiIhIqZbwGB6cnJycCA4OLtW177//PgMGDGDChAkATJkyhcWLF/PRRx8xffr0Yh+TnZ1Ndna27X5qauq1Fy0iIiIiIjWK4V31Dh48SGhoKA0bNmTkyJHExsZe9tq1a9fSr1+/Qsf69+/P2rVrL/uYqVOn4uvra7tpfZOIiIiIiFwpQ4NTly5dmDFjBr///juffPIJ0dHRXHfddaSlpRV7fUJCAkFBQYWOBQUFkZCQcNnXmDhxIikpKbZbXFxcmb4HERERERGp/gydqjdw4EDb91FRUXTp0oWIiAi+//57HnjggTJ5DVdXV1xdXcvkuURERESkfFgsFvLy8sjPzze6FKlmnJ2dcXR0vObnMXyN08X8/Pxo0qQJhw4dKvZ8cHAwiYmJhY4lJiaWeo2UiIiIiFQ+OTk5xMfHk5mZaXQpUg2ZTCbq1q2Ll5fXNT1PpQpO6enpHD58mHvvvbfY8926dWPp0qWMHz/edmzx4sV069atgioUERERkbJkNpuJjo7G0dGR0NBQXFxcStXhTKQ0LBYLJ0+e5NixY0RGRl7TyJOhwenZZ59l8ODBREREcOLECf71r3/h6OjIiBEjABg1ahRhYWFMnToVgKeeeorevXvz9ttvM2jQIGbPns2mTZv47LPPjHwbIiIiInKVcnJyMJvNhIeH4+HhYXQ5Ug3Vrl2bo0ePkpubW3WD07FjxxgxYgSnT5+mdu3a9OzZk3Xr1lG7dm0AYmNjcXC40L+ie/fuzJw5kxdffJF//vOfREZGMn/+/FLv4SQiIiIildPFn/lEylJZjWCaLBaLpUyeqYpITU3F19eXlJQUbYArIiIiYrCsrCyio6Np0KABbm5uRpcj1ZC932NXkg0U7UVEREREREqg4CQiIiIiUgnUr1+f9957z+gy5DIUnEREREREroDJZLJ7mzRp0lU978aNG3n44YevqbY+ffoU6kAtZadStSOvidKycvF2cza6DBEREREppfj4eNv33333HS+//DL79++3Hbt4vyCLxUJ+fj5OTiV/7D7fIE0qJ404GWjulmP0fGMZKw6cNLoUERERkUrBYrGQmZNnyK20PdOCg4NtN19fX0wmk+3+vn378Pb2ZuHChXTo0AFXV1dWr17N4cOHGTJkCEFBQXh5edGpUyeWLFlS6HkvnapnMpn44osvuO222/Dw8CAyMpKff/75mn59f/zxR1q2bImrqyv169fn7bffLnT+P//5D5GRkbi5uREUFMQdd9xhOzdnzhxat26Nu7s7gYGB9OvXj4yMjGuqpyrRiJOBdh5PIeVcLhN/3MEff++lkScRERGp8c7l5tPi5T8Mee09k/vj4VI2H4+ff/553nrrLRo2bIi/vz9xcXHcfPPNvPrqq7i6uvLNN98wePBg9u/fT7169S77PK+88gpvvvkm06ZN48MPP2TkyJHExMQQEBBwxTVt3ryZu+66i0mTJjF8+HDWrFnD448/TmBgIGPGjGHTpk08+eSTfPvtt3Tv3p0zZ86watUqwDrKNmLECN58801uu+020tLSWLVqVanDZnWg4GSgCf2bsmRvInFnzvHG7/v499DWRpckIiIiImVg8uTJ3Hjjjbb7AQEBtGnTxnZ/ypQpzJs3j59//plx48Zd9nnGjBnDiBEjAHjttdf44IMP2LBhAwMGDLjimt555x369u3LSy+9BECTJk3Ys2cP06ZNY8yYMcTGxuLp6cktt9yCt7c3ERERtGvXDrAGp7y8PIYNG0ZERAQArVvXrM+uCk4G8nBx4o1hUfzti/X8d10st0SF0rVhoNFliYiIiBjG3dmRPZP7G/baZaVjx46F7qenpzNp0iR+/fVXWwg5d+4csbGxdp8nKirK9r2npyc+Pj4kJSVdVU179+5lyJAhhY716NGD9957j/z8fG688UYiIiJo2LAhAwYMYMCAAbZpgm3atKFv3760bt2a/v37c9NNN3HHHXfg7+9/VbVURVrjZLDujWvxty7W4dnnftzBuZx8gysSERERMY7JZMLDxcmQm8lkKrP34enpWej+s88+y7x583jttddYtWoV27Zto3Xr1uTk5Nh9Hmfnwks5TCYTZrO5zOq8mLe3N1u2bGHWrFmEhITw8ssv06ZNG5KTk3F0dGTx4sUsXLiQFi1a8OGHH9K0aVOio6PLpZbKSMHJSBYLmM1MHNiMEF83Yk5n8vai/SU/TkRERESqlL/++osxY8Zw22230bp1a4KDgzl69GiF1tC8eXP++uuvInU1adIER0fraJuTkxP9+vXjzTffZMeOHRw9epQ///wTsIa2Hj168Morr7B161ZcXFyYN29ehb4HI2mqnpEOLYXfn8e72+O8Prgvo/+7i//7K5qbo0JoX6/mDHuKiIiIVHeRkZHMnTuXwYMHYzKZeOmll8pt5OjkyZNs27at0LGQkBCeeeYZOnXqxJQpUxg+fDhr167lo48+4j//+Q8Av/zyC0eOHKFXr174+/vz22+/YTabadq0KevXr2fp0qXcdNNN1KlTh/Xr13Py5EmaN29eLu+hMtKIk5E2fQmnD8Ivf6f3r334vO5CalnO8o85O8jO05Q9ERERkerinXfewd/fn+7duzN48GD69+9P+/bty+W1Zs6cSbt27QrdPv/8c9q3b8/333/P7NmzadWqFS+//DKTJ09mzJgxAPj5+TF37lxuuOEGmjdvzvTp05k1axYtW7bEx8eHlStXcvPNN9OkSRNefPFF3n77bQYOHFgu76EyMllqUg9BIDU1FV9fX1JSUvDx8TG2mKxU2PpfWP8JJFsXBubixE/53clo9zCjhw02tj4RERGRcpaVlUV0dDQNGjTAzc3N6HKkGrL3e+xKsoFGnIzk5gPdHocntsJd30B4F5zJ4w7HlYzecQ/pnw2EA39AOQ3jioiIiIhI6Sg4VQaOTtBiCDywCB5cyiav68mzOOB1Yg3MvAs+7gwb/w9yMo2uVERERESkRlJwqmzqdiTike+41eEjPssbRLajp3Ud1K9Pw7stYOkUSEswukoRERERkRpFwakSqu3tysO39uG1vJF0zfqIpB6TwK8enDsLq96Cd1vBvEchfofRpYqIiIiI1AgKTpXUkLah9G1Wh7P5rjx0oDP5486vg+oK5lzYPgs+vQ6+Hgz7f9c6KBERERGRcqTgVEmZTCZeva013q5ObI9L5ss1sQXroP6AB5dCy2FgcoTolTBrOHzcSeugRERERETKiYJTJRbs68aLt1g3FXtr0X6iT2VYT9TtCHd+BU9th+5PgKsPnD500TqoyZAab2DlIiIiIiLVi4JTJXdXx3B6Nq5Fdp6Z537cgdl80bZbfuFw07/h6T0w4A3wiyhYB/U2vNda66BERERERMqIglMlZzKZmDqsNR4ujmyIPsP/1scUvcjVG7o+Ck9uhbu+LboOasYtWgclIiIiInINFJyqgPAAD54b0AyA1xfu49jZy6xjcnCEFrcWrIP6E1rdbl0HdXTVReugvoCcjAqsXkRERESK06dPH8aPH2+7X79+fd577z27jzGZTMyfP/+aX7usnqcmUXCqIu7tGkGn+v5k5OQzce5OLBaL/QfU7QB3fFmwDupJcPUtWAf1DLzbUuugRERERK7S4MGDGTBgQLHnVq1ahclkYseOK18usXHjRh5++OFrLa+QSZMm0bZt2yLH4+PjGThwYJm+1qVmzJiBn59fub5GRVJwqiIcHEy8cXsUrk4OrDp4ih82HyvdA/3C4aYp8PTu4tdBzX0E4reXb/EiIiIi1cgDDzzA4sWLOXas6Oexr776io4dOxIVFXXFz1u7dm08PDzKosQSBQcH4+rqWiGvVV0oOFUhDWt78fSNTQCY8sseElOzSv/gi9dBDf8v1OtmXQe1YzZ82qtgHdRCrYMSERERY1ks1mUFRtxKmtFT4JZbbqF27drMmDGj0PH09HR++OEHHnjgAU6fPs2IESMICwvDw8OD1q1bM2vWLLvPe+lUvYMHD9KrVy/c3Nxo0aIFixcvLvKY5557jiZNmuDh4UHDhg156aWXyM3NBawjPq+88grbt2/HZDJhMplsNV86VW/nzp3ccMMNuLu7ExgYyMMPP0x6errt/JgxYxg6dChvvfUWISEhBAYGMnbsWNtrXY3Y2FiGDBmCl5cXPj4+3HXXXSQmJtrOb9++neuvvx5vb298fHzo0KEDmzZtAiAmJobBgwfj7++Pp6cnLVu25LfffrvqWkrDqVyfXcrcAz0b8NvOeLYfS+GFebv4fFQHTCZT6Z/AwRGaD7bejm+Gtf+B3fOs66COroKARtDtcWgzAlw8y++NiIiIiBQnNxNeCzXmtf95olSff5ycnBg1ahQzZszghRdesH0W++GHH8jPz2fEiBGkp6fToUMHnnvuOXx8fPj111+59957adSoEZ07dy7xNcxmM8OGDSMoKIj169eTkpJSaD3Ued7e3syYMYPQ0FB27tzJQw89hLe3N//4xz8YPnw4u3bt4vfff2fJkiUA+Pr6FnmOjIwM+vfvT7du3di4cSNJSUk8+OCDjBs3rlA4XLZsGSEhISxbtoxDhw4xfPhw2rZty0MPPVTi+ynu/Z0PTStWrCAvL4+xY8cyfPhwli9fDsDIkSNp164dn3zyCY6Ojmzbtg1nZ2cAxo4dS05ODitXrsTT05M9e/bg5eV1xXVcCQWnKsbJ0YE372jDLR+uYsneRBbsiOfWNlf5l0tYB7jj/+DGV2D9p7D5azhz2LoOaukU6Hg/dH4YfELK9k2IiIiIVHH3338/06ZNY8WKFfTp0wewTtO7/fbb8fX1xdfXl2effdZ2/RNPPMEff/zB999/X6rgtGTJEvbt28cff/xBaKj1s95rr71WZF3Siy++aPu+fv36PPvss8yePZt//OMfuLu74+XlhZOTE8HBwZd9rZkzZ5KVlcU333yDp6c1OH700UcMHjyYN954g6CgIAD8/f356KOPcHR0pFmzZgwaNIilS5deVXBaunQpO3fuJDo6mvDwcAC++eYbWrZsycaNG+nUqROxsbFMmDCBZs2sTdIiIyNtj4+NjeX222+ndevWADRs2PCKa7hSCk5VUNNgb8ZdH8m7Sw4w6efd9GgUSKDXNcxR9a1rXQfV+znY9j9Y9x84exRWvwNrPoRWw6Dr4xDatqzegoiIiEjxnD2sIz9GvXYpNWvWjO7du/Pll1/Sp08fDh06xKpVq5g8eTIA+fn5vPbaa3z//fccP36cnJwcsrOzS72Gae/evYSHh9tCE0C3bt2KXPfdd9/xwQcfcPjwYdLT08nLy8PHx6fU7+P8a7Vp08YWmgB69OiB2Wxm//79tuDUsmVLHB0dbdeEhISwc+fOK3qti18zPDzcFpoAWrRogZ+fH3v37qVTp048/fTTPPjgg3z77bf069ePO++8k0aNGgHw5JNP8thjj7Fo0SL69evH7bffflXryq6E1jhVUY/1aUSzYG/OZOTwr593l82TunpBl0fgiS0F66C6F6yD+g4+6611UCIiIlL+TCbrdDkjbley/AFrk4gff/yRtLQ0vvrqKxo1akTv3r0BmDZtGu+//z7PPfccy5YtY9u2bfTv35+cnJwy+6Vau3YtI0eO5Oabb+aXX35h69atvPDCC2X6Ghc7P03uPJPJhLkcPxdOmjSJ3bt3M2jQIP78809atGjBvHnzAHjwwQc5cuQI9957Lzt37qRjx458+OGH5VYLKDhVWS5ODky7ow2ODiZ+2RHPH7sTyu7Jz6+Dun8hPPQntLrjov2g7oaPOsKGz7UflIiIiNRod911Fw4ODsycOZNvvvmG+++/37be6a+//mLIkCHcc889tGnThoYNG3LgwIFSP3fz5s2Ji4sjPv7C9jHr1q0rdM2aNWuIiIjghRdeoGPHjkRGRhITE1PoGhcXF/Lz80t8re3bt5ORceGz3V9//YWDgwNNmzYtdc1X4vz7i4uLsx3bs2cPycnJtGjRwnasSZMm/P3vf2fRokUMGzaMr776ynYuPDycRx99lLlz5/LMM8/w+eefl0ut5yk4VWGt6/rycC/rfM4X5+8iJfPqu5pc1vl1UON3QI+nrPtBnTkMvz0L77SAJZMg1aDhdBEREREDeXl5MXz4cCZOnEh8fDxjxoyxnYuMjGTx4sWsWbOGvXv38sgjjxTqGFeSfv360aRJE0aPHs327dtZtWoVL7zwQqFrIiMjiY2NZfbs2Rw+fJgPPvjANiJzXv369YmOjmbbtm2cOnWK7OzsIq81cuRI3NzcGD16NLt27WLZsmU88cQT3HvvvbZpelcrPz+fbdu2Fbrt3buXfv360bp1a0aOHMmWLVvYsGEDo0aNonfv3nTs2JFz584xbtw4li9fTkxMDH/99RcbN26kefPmAIwfP54//viD6OhotmzZwrJly2znyouCUxX3VN9IGtb25GRaNlN+3VN+L+RbF26cDE/vgYFvgn8DyEqG1e8W7Af1MCTtLb/XFxEREamEHnjgAc6ePUv//v0LrUd68cUXad++Pf3796dPnz4EBwczdOjQUj+vg4MD8+bN49y5c3Tu3JkHH3yQV199tdA1t956K3//+98ZN24cbdu2Zc2aNbz00kuFrrn99tsZMGAA119/PbVr1y62JbqHhwd//PEHZ86coVOnTtxxxx307duXjz766Mp+MYqRnp5Ou3btCt0GDx6MyWTip59+wt/fn169etGvXz8aNmzId999B4CjoyOnT59m1KhRNGnShLvuuouBAwfyyiuvANZANnbsWJo3b86AAQNo0qQJ//nPf665XntMFkspG9ZXE6mpqfj6+pKSknLFC+cqq80xZ7hj+losFphxXyf6NK1T/i9qzreud1r7McSusR5zcLKOSvX6Bzi7lX8NIiIiUuVlZWURHR1NgwYNcHPT5wcpe/Z+j11JNtCIUzXQISKAMd3rA/DPuTtJyyqHKXuXcnCE5rcUrINaBk1vBnMerHobpveAo3+Vfw0iIiIiIhVEwamamNC/KeEB7pxIyeKN3/dV7IuHtYcRs+Cub8ErCE4fghk3wy9/h6yUiq1FRERERKQcVJrg9Prrr2MymYrdEfm8GTNmYDKZCt00pGvl4eLEG8Osvev/uy6WtYdPV3wRLW6Fseuh/Sjr/U1fwsddYd9vFV+LiIiIiEgZqhTBaePGjXz66ael2rTKx8eH+Ph42+3Slos1WffGtfhbl3oAPD93B+dy7LeeLBfu/nDrhzB6gbWBRNoJmD0Cvh8N6UkVX4+IiIiISBkwPDilp6czcuRIPv/8c/z9/Uu83mQyERwcbLtda4vE6mbiwGaE+LoRczqTtxftN66QBr3g8bXQY7x1D6g98+GjTrD1v1Cz+pGIiIhIKdSwfmVSgcrq95bhwWns2LEMGjSIfv36ler69PR0IiIiCA8PZ8iQIezevdvu9dnZ2aSmpha6VWfebs68dltrAP7vr2i2xJ41rhhnd7jxFesmusFR1vblP42Fb4bAmWjj6hIREZFKw9nZGYDMzEyDK5HqKicnB7C2OL8WTmVRzNWaPXs2W7ZsYePGjaW6vmnTpnz55ZdERUWRkpLCW2+9Rffu3dm9ezd169Yt9jFTp0619XuvKa5vVodh7cOYu+U4/5izg1+e6Imb87X9RrkmoW2tnffWfgTLp0L0CvhPN7jhBejyGDga+ttQREREDOTo6Iifnx9JSdYp/R4eHphMJoOrkurCbDZz8uRJPDw8cHK6ts+chu3jFBcXR8eOHVm8eLFtbVOfPn1o27Yt7733XqmeIzc3l+bNmzNixAimTJlS7DXZ2dmFdkhOTU0lPDy8Wu3jVJzkzBz6vbOSU+nZjL2+ERP6NzO6JKvTh2HBU3B0lfV+aDvrmqjg1sbWJSIiIoaxWCwkJCSQnJxsdClSDTk4ONCgQQNcXFyKnLuSfZwMC07z58/ntttuKzRklp+fj8lkwsHBgezs7FINp9155504OTkVuwtycarjBriX8/uueB797xYcHUz8NLYHrcJ8jS7JymKBrd/CHy9Cdop1DVSPp6D3c9o4V0REpAbLz88nN7cC9qOUGsXFxQUHh+JXKFWJ4JSWllakI959991Hs2bNeO6552jVqlWJz5Gfn0/Lli25+eabeeedd0r1ujUpOAGM/d8Wft0ZT/MQH34e1wNnR8OXtV2QlgC/TYC9P1vvBzaGwe9D/Z7G1iUiIiIiNcKVZAPDPkV7e3vTqlWrQjdPT08CAwNtoWnUqFFMnDjR9pjJkyezaNEijhw5wpYtW7jnnnuIiYnhwQcfNOptVHqTbm2Jv4cze+NTmb78sNHlFOYdDMO/heH/Ba/ggo1zB1mn8mnjXBERERGpRCrR8ENRsbGxxMfH2+6fPXuWhx56iObNm3PzzTeTmprKmjVraNGihYFVVm61vV351+CWAHzw50EOJKYZXFExmg8u2Dh3tPX+5hnwcRfY+4uhZYmIiIiInGfYVD2j1LSpemBdcPng15tYui+JNuF+zH2sO44OlbRbTfQqWPAknDlivd9iCAycBt7ar0tEREREylaVmKonFcdkMvHqba3xdnVie1wyX66uxHsoNbgOHlsDPf9esHHuT/BxJ9jyrTbOFRERERHDKDjVEMG+brx4S3MA3lq0n+hTGQZXZIezO/SbBA8vg5A21vVOP4+Db269MBIlIiIiIlKBFJxqkLs6htOzcS2y88w89+MOzOZKPoIT0gYe/BNunAJO7hC9Ev7THf56H/LzjK5ORERERGoQBacaxGQyMXVYazxcHNkQfYb/rY8p+UFGc3SCHk/C42ugQS/IOweLX4YvboD4HUZXJyIiIiI1hIJTDRMe4MFzA5oBMHXhPuLOZBpcUSkFNIRRP8OtH4GbL8Rvh8/6wJJJkHvO6OpEREREpJpTcKqB7u0aQaf6/mTm5PPPeTupMo0VTSZofy+M3WjttmfJh9Xvwifdrd34RERERETKiYJTDeTgYOKN26NwdXJg1cFT/LD5mNElXRnvILjrGxj+P/AOsTaM+PoW+PlJOJdsdHUiIiIiUg0pONVQDWt78fSNTQCY8sseElOzDK7oKjS/xbpxbof7rPe3fF2wce4CY+sSERERkWpHwakGe6BnA9rU9SUtK48XqtKUvYu5+cLg92DMrxDQCNIT4Lt7rLe0BKOrExEREZFqQsGpBnNydODNO9rg7Ghiyd4kft5+wuiSrl79ngUb5z5t3Th37wL4uDNs+UYb54qIiIjINVNwquGaBnsz7vpIAF5ZsIfT6dkGV3QNnN2g37/gkRUQ0rZg49wn4OvBcPqw0dWJiIiISBWm4CQ81qcRzYK9OZORw79+3m10OdcuuDU8uBRu+rd149yjq6yd91a/p41zRUREROSqKDgJLk4OTLujDY4OJn7ZEc/vu6rB2iBHJ+j+BDy+Fhr2gbwsWPIv+Px66x5QIiIiIiJXQMFJAGhd15eHezUE4KWfdpGSmWtwRWUkoAHcOx+G/Afc/CBhB3x2PSx+WRvnioiIiEipKTiJzVN9I2lY25OTadlM+XWP0eWUHZMJ2o2EsRug5W3WjXP/eh/+0w2iVxpdnYiIiIhUAQpOYuPm7Mi0O6IwmWDO5mMs359kdEllyzsI7pwBd8+ybpx7NtraOOLnJ+DcWaOrExEREZFKTMFJCukQEcB93RsA8M+5O0nLqiZT9i7W7GbrxrkdH7De3/KNdePcPT8ZW5eIiIiIVFoKTlLEs/2bUC/AgxMpWby+cJ/R5ZQPN1+45R24byEENob0RPh+FMweCanxRlcnIiIiIpWMgpMU4eHixOvDWgPwv/WxrD182uCKylFEd3j0L7juWXBwgn2/wH+6wMElRlcmIiIiIpWIgpMUq3vjWvytSz0AnvtxB5k51Xj/I2c36PsSPHzRxrn/u8O675PFYnR1IiIiIlIJKDjJZU0c2IwQXzdiz2Ty9qIDRpdT/oJbwQOLoP1owGLd9+nHByEn0+jKRERERMRgCk5yWd5uzrx2m3XK3pd/RbM5pgZ0nnNyhcHvw6C3rVP3ds2BL2+C5FijKxMRERERAyk4iV3XN6vDsPZhWCzWKXtZuflGl1T+TCbo9CCM+hk8akHCTvisD0SvMroyERERETGIgpOU6OVbWlDLy5VDSel8+OdBo8upOPV7wMPLIaQNZJ6Gb4bA+s+07klERESkBlJwkhL5ebjw76EtAZi+4gi7jqcYXFEF8guH+36H1neCJR8WToCfx0FettGViYiIiEgFUnCSUhnQKoRBrUPIN1uYMGcHuflmo0uqOC4eMOxzuHEKmBxg639hxiDt9yQiIiJSgyg4SalNurUl/h7O7I1PZfryw0aXU7FMJujxJIz8wbp57rGN1nVPxzYZXZmIiIiIVAAFJym12t6uTLrVOmXvgz8PciAxzeCKDNC4Hzy0DGo3h/QE+GqgdQRKRERERKo1BSe5Ire2CaVvszrk5lun7OWba2CjhMBG8OBiaHYL5OfAT2Pht39Afq7RlYmIiIhIOVFwkitiMpl49bbWeLs6sT0umS9XRxtdkjFcveGub6HPROv9DZ/Ct7dBxilj6xIRERGRcqHgJFcs2NeNF29pDsBbi/YTfSrD4IoM4uAAfZ6Hu2eCixccXQWfXQ/xO4yuTERERETKmIKTXJW7OobTs3EtsvPMPDdnB+aaOGXvvGaD4MElENAQUmLh/26CXT8aXZWIiIiIlCEFJ7kqJpOJqcNa4+HiyIajZ/jv+hijSzJWnebw0J/QqC/knYM598Pif4E53+jKRERERKQMKDjJVQsP8OC5Ac0AeH3hPuLOZBpckcHc/a3tyns8Zb3/13swczicSzayKhEREREpAwpOck3u7RpBp/r+ZObk88SsrZxOzza6JGM5OMKNk+H2/wMnNzi0GD6/AU7uN7oyEREREbkGCk5yTRwcTLxxexTerk5si0vm1o/+YtfxFKPLMl7rO+D+P8A3HM4chs/7wr7fjK5KRERERK5SpQlOr7/+OiaTifHjx9u97ocffqBZs2a4ubnRunVrfvtNH0aN1rC2F/PGdqdBLU+OJ5/jjulr+Hn7CaPLMl5oW+tmuRE9ICcNZo+AFW+C2Wx0ZSIiIiJyhSpFcNq4cSOffvopUVFRdq9bs2YNI0aM4IEHHmDr1q0MHTqUoUOHsmvXrgqqVC6ncR1v5o/tQe8mtcnKNfPkrK28vnBfzdwg92JetWHUT9DpIev9Za/CD6MgO93YukRERETkihgenNLT0xk5ciSff/45/v7+dq99//33GTBgABMmTKB58+ZMmTKF9u3b89FHH1VQtWKPr7szX47pxKO9GwEwfcVhHvh6Iynncg2uzGCOzjDoLRj8ATg4w94F8H83wpkjRlcmIiIiIqVkeHAaO3YsgwYNol+/fiVeu3bt2iLX9e/fn7Vr1172MdnZ2aSmpha6SflxdDDx/MBmvH93W9ycHVi+/yRDP/6LQ0lpRpdmvA6j4b7fwCsIkvZYN8s9/KfRVYmIiIhIKRganGbPns2WLVuYOnVqqa5PSEggKCio0LGgoCASEhIu+5ipU6fi6+tru4WHh19TzVI6Q9qGMefR7oT5uRN9KoOhH69hyZ5Eo8syXnhneHg5hHWArGT47+2w5iOw1PApjSIiIiKVnGHBKS4ujqeeeor//e9/uLm5ldvrTJw4kZSUFNstLi6u3F5LCmsV5svP43rQuUEA6dl5PPTtJj5cehBLTQ8JPqEw5jdoOxIsZlj0Asx7BHLPGV2ZiIiIiFyGYcFp8+bNJCUl0b59e5ycnHBycmLFihV88MEHODk5kZ+fX+QxwcHBJCYWHrVITEwkODj4sq/j6uqKj49PoZtUnEAvV/73YBdGdYvAYoG3Fx/g8f9tISM7z+jSjOXsBkM+hgFvgMkRdnwHXw6AlGNGVyYiIiIixTAsOPXt25edO3eybds2261jx46MHDmSbdu24ejoWOQx3bp1Y+nSpYWOLV68mG7dulVU2XIVnB0dmDykFa8Pa42zo4mFuxK4/ZM1xJ7ONLo0Y5lM0PVRGDUf3AMgfht81gdi1hhcmIiIiIhcyrDg5O3tTatWrQrdPD09CQwMpFWrVgCMGjWKiRMn2h7z1FNP8fvvv/P222+zb98+Jk2axKZNmxg3bpxRb0OuwN2d6zH74W7U9nZlX0Iat368mr8OnTK6LOM16GVd9xTUCjJOwteDYeP/GV2ViIiIiFzE8K569sTGxhIfH2+73717d2bOnMlnn31GmzZtmDNnDvPnz7cFLan8OkT4s2BcT9rU9SU5M5dRX27g/1ZHa92TfwQ8sAha3gbmPPj1aVjwFOTlGF2ZiIiIiAAmSw37xJqamoqvry8pKSla72SgrNx8Xpi3ix+3WNf0DGsfxmu3tcbNuegUzRrFYoHV78LSyYAFwrvCXd+Ad1CJDxURERGRK3Ml2aBSjzhJ9eXm7Mhbd0bx8i0tcHQwMXfLcYZ/upaElCyjSzOWyQTXPQ1/+x5cfSFunXXd0/EtRlcmIiIiUqMpOIlhTCYT9/dswDf3d8bPw5ntx1K45cPVbI45Y3RpxmtyEzy0FGo1gbQT1o5722cbXZWIiIhIjaXgJIbr0bgWP4/tSbNgb06lZ3P3Z+uYtSHW6LKMVysSHlwCTQZCfrZ1r6ff/wn5NbyVu4iIiIgBFJykUqgX6MGPj3Xn5tbB5OZbmDh3Jy/N30Vuvtno0ozl5gt3z4ReE6z3130M/x0GmRqVExEREalICk5SaXi6OvHx39rz7E1NMJng23UxjPxiPafSs40uzVgODnDDi9YmEc6eEL3Cuu4pcbfRlYmIiIjUGApOUqmYTCbG3RDJ5/d2xMvViQ3RZ7j1w9XsOp5idGnGazEEHlwMfhGQHANf3Ah7fjK6KhEREZEaQcFJKqV+LYKYP7YHDWt5ciIlizumr+GnbceNLst4QS2tm+U26A25GfD9KFg6Bcw1fEqjiIiISDlTcJJKq3EdL+aN7UGfprXJyjXz1OxtTF24l3xzjdp6rCiPALhnLnQda72/6i2YPQKyNConIiIiUl4UnKRS83V35v9Gd+KxPo0A+HTFEe6fsZGUzFyDKzOYoxMMeA2GTgdHVzjwO3zRD04dNLoyERERkWpJwUkqPUcHE88NaMaHI9rh5uzAigMnGfLxag4mphldmvHajoD7fwefMDh1AD6/AQ4sMroqERERkWpHwUmqjMFtQvnxse6E+blz9HQmt/1nDYv3JBpdlvHC2sNDyyC8K2Snwsy7YNXbYKnhUxpFREREypCCk1QpLUN9+XlcD7o2DCA9O4+HvtnEB0sPYq7p6568g2D0AugwBrDA0skw5z44uV8BSkRERKQMmCyWmvWpKjU1FV9fX1JSUvDx8TG6HLlKuflmXv11LzPWHAVgQMtg3r6rDZ6uTsYWVhls+hJ+mwDmPOt9ryCo3xPqXwcNekFAQzCZjK1RREREpBK4kmyg4CRV2vcb43hx/i5y8s00DfLm81EdqRfoYXRZxotdB8tehdj1kH/JBsLeodDguoIgdR341zekRBERERGjKTjZoeBU/WyOOctj/91MUlo2vu7OfPy39vSMrGV0WZVDbhYc2whHV0H0Kuv35ks6EvrWs45InQ9TfuHG1CoiIiJSwRSc7FBwqp4SU7N45NvNbItLxsEE/7y5OQ/0bIBJU9IKy8mEYxusIeroKji++cKUvvP861+Y1lf/OvAJMaRUERERkfKm4GSHglP1lZWbz4vzdzFn8zEAhrUL47VhrXFzdjS4skosOx3i1l0IUie2gsVc+JrAxhem9dW/DrzqGFOriIiISBlTcLJDwal6s1gszFhzlH//upd8s4Wour58em8HQnzdjS6tashKhdi1EL0Sjq6G+O3AJX9F1Gp6IUTVvw48Aw0pVURERORaKTjZoeBUM6w5dIqxM7dwNjOXWl6uTL+nPR3rBxhdVtVzLhli1lxYI5W4s+g1dVpeFKR6gLt/hZcpIiIicjUUnOxQcKo54s5k8tA3m9iXkIazo4nJQ1oxonM9o8uq2jLPWEeizgepk3svucAEwa0vTO2L6A5uvoaUKiIiIlISBSc7FJxqlsycPCb8sINfd8YDcE/Xerx8S0tcnLT3c5lIPwkxqy+skTp1oPB5kwOEtLnQbKJeV3D1NqZWERERkUsoONmh4FTzWCwW/rP8MG8t2o/FAp3rB/Cfe9pTy8vV6NKqn7QE64hU9EprkDpzpPB5kyOEtb8wIhXeFVy075aIiIgYQ8HJDgWnmuvPfYk8NWsbadl5hPq68dmojrQK0zSycpVy/MK0vqOrIDmm8HkHZwjrcGGNVHhncFYjDxEREakYCk52KDjVbIeS0nn4200cOZmBq5MDb94RxZC2YUaXVXOcjSm8Rir1WOHzjq5Qt9OFIFW3IzhpZFBERETKh4KTHQpOkpqVy/jZ2/hzXxIAj/RqyD8GNMPRQZvlViiLBc5GXxiNil4F6QmFr3Fyt45CNboeIm+COi1AmxqLiIhIGVFwskPBSQDyzRbeWbyfj5cdBqBXk9p8eHc7fD2cDa6sBrNY4PRhOLryQpjKOFn4Gp8wiLwRIvtbm024ehlTq4iIiFQLCk52KDjJxX7ZcYIJP+zgXG4+9QM9+HxURyKD1PWtUrBY4OR+a6OJQ4utX/OyLpx3dIGIHtaRqMiboFZj42oVERGRKknByQ4FJ7nUnhOpPPTNJo4nn8PTxZF3hrelf8tgo8uSS+Wes66POrgIDvxRtNFEQMOCEHUjRPQEZzdj6hQREZEqQ8HJDgUnKc6ZjBzG/m8La4+cBuC+HvV5bkAz3JwdDa5MimWxwKmD1hB1cBHErAFz7oXzTu7QsHfBtL6bwE8bH4uIiEhRCk52KDjJ5eTmm5n62z6+/CsagGbB3nwwoh1NNHWv8stOgyMrCoLUYkg7Ufh87eYXQlS9ruCotWwiIiKi4GSXgpOUZNm+JCbM2c6p9BxcnRx4YVBz7u0agUnd3KoGiwUSd10IUXHrwWK+cN7VBxr2gSb9oXE/8Na0TBERkZpKwckOBScpjZNp2UyYs53l+61d3fo2q8Mbd0RRy0t7ClU5mWfgyDI4sMjaZCLzdOHzIW0uNJgI6wAOmp4pIiJSUyg42aHgJKVlsVj4es1RXlu4j5w8M7W8XHnrzij6NK1jdGlytcxmOLH1wtqoE1sKn3cPsI5CRd4EjfuCR4AxdYqIiEiFUHCyQ8FJrtS+hFSenLWVA4npgBpHVCvpSXBoiTVEHfoTslMunDM5QFjHC536Qtpo810REZFqRsHJDgUnuRpZufm8vnAfM9YcBdQ4olrKz4NjG6ytzg8uhqTdhc97BUNkwWhUwz7g5mtImSIiIlJ2FJzsUHCSa6HGETVIyjFrgDq4GI4sh9yMC+ccnKBetwtro2o31WiUiIhIFVRlgtMnn3zCJ598wtGjRwFo2bIlL7/8MgMHDiz2+hkzZnDfffcVOubq6kpWVlapX1PBSa6VGkfUQHnZEPNXQZBaBKcPFT7vW+9Cu/MGvcDFw5g6RURE5IpUmeC0YMECHB0diYyMtC7E//prpk2bxtatW2nZsmWR62fMmMFTTz3F/v37bcdMJhNBQUGlfk0FJykLFouFGWuOMvWixhFv39WG3k1qG12aVITThy+sjYpeBfnZF845ukKD6y6sjQpoaFydIiIiYleVCU7FCQgIYNq0aTzwwANFzs2YMYPx48eTnJx81c+v4CRl6dLGEff3aMA/BjRV44iaJCfDGp7Od+pLiSt8PrDxhRAV0QOcNDIpIiJSWVxJNnCqoJpKlJ+fzw8//EBGRgbdunW77HXp6elERERgNptp3749r732WrGjU+dlZ2eTnX3hf4NTU1PLtG6p2ZoF+/DzuJ5M/W0vX6+N4cu/ollz+JQaR9QkLp7QdID1ZrHAyf1wsKDBROxa67S+04dg3X/AyQ1C20O9LhDeFcI7q+W5iIhIFWH4iNPOnTvp1q0bWVlZeHl5MXPmTG6++eZir127di0HDx4kKiqKlJQU3nrrLVauXMnu3bupW7dusY+ZNGkSr7zySpHjGnGSsqbGEVJEVoq1scTBRdYglZ5Y9JpaTSC8i/VWr6t1hEq/Z0RERCpElZqql5OTQ2xsLCkpKcyZM4cvvviCFStW0KJFixIfm5ubS/PmzRkxYgRTpkwp9priRpzCw8MVnKRcqHGEXJbFAqcOQtw6iFsPsevh9MGi13kEFgSpztZRqdB24OxW8fWKiIjUAFUqOF2qX79+NGrUiE8//bRU19955504OTkxa9asUl2vNU5S3tQ4Qkot47Q1RJ2/Hd9SuNEEgIMzhLa9MCIV3gW86hhSroiISHVTJdc4nWc2mwuNENmTn5/Pzp07Lzu1T8QIJpOJ+3o0oFujQFvjiNFfblDjCCnKMxCa3Wy9gbXtefwO66hUbMHIVMZJOLbRelv7kfU6/wYFIapgVKp2M3BwMO59iIiI1ACGjjhNnDiRgQMHUq9ePdLS0pg5cyZvvPEGf/zxBzfeeCOjRo0iLCyMqVOnAjB58mS6du1K48aNSU5OZtq0acyfP5/NmzeXamofaMRJKlZWbr6tcQRAs2BvNY6Q0rNY4Gy0dVrf+VGppL3AJX9tu/pCeCdriKrXBcI6WJtWiIiIiF1VZsQpKSmJUaNGER8fj6+vL1FRUbbQBBAbG4vDRf+LevbsWR566CESEhLw9/enQ4cOrFmzptShSaSiuTk78sqQVvRpWocJc7azLyGNwR+uVuMIKR2TyboPVEBDaDvCeuxcMhzbdGFU6vhmyE6x7it1aEnB4xwhuPWFqX3hXcA3zLC3ISIiUh1UujVO5U0jTmIUNY6QcpGfC4m7Ckal1lm/pp0oep1v+EXd+7pAnZbgWOlma4uIiFSoKt0corwpOImR1DhCKkRy3IWpfbHrrMHKYi58jYuXdUrf+VGpuh3BzdeYekVERAyi4GSHgpNUBvsSUm2NIwA1jpDylZ1mndJ3flQqbiPkpF1ykQmCWl7Uva8z+EVoTykREanWFJzsUHCSykKNI8Qw5nxrk4m4dRC3wToqlRxT9DqvYOu0vvAu1sYTIVHg6Fzx9YqIiJQTBSc7FJyksvlzXyITftjB6YwcXJ0c1DhCjJGWUNACfYM1UMVvB3Ne4Wuc3CGsvXWKn7s/OLuDk5v1q7O79byzGzh7XDhe6LybRrBERKRSUXCyQ8FJKqPiGke8eUcUgWocIUbJyYQTWy80nIhbD1nJ1/6858NVaUKWs8e1XavRMRERKYGCkx0KTlJZqXGEVGpmM5w+eKHZRE4m5J2D3CzIzYS8LMg9Z72dP55XcO7SkauKYnIsOhp2cchy9rBuJnx+FM2/vkbERERqGAUnOxScpLJT4wipdvLzCsLU+WBVXMi63PlirrUFtcs87tINgkvLPcAaoOp2tH4NbQ+egWX6SyEiIpWLgpMdCk5SFRTXOOLDEe2IVOMIEfssFsjLLl3Iyk6zNsk4vhkSdoI5t+jz+de3hqjzt+AocPGo8LclIiLlQ8HJDgUnqUoubRzx4qDm3KPGESJlLy8bEnZZQ9T52+mDRa8zOVrbtl8cpmo3BQeNCIuIVEUKTnYoOElVo8YRIgY5l2xtkHF8ExzfAsc2QUZS0eucPSG03YW1UmEdwLeu1kuJSM2WmwWpxyH1hPVryrGLvj8OaSfg6b3gZOznGQUnOxScpCpS4wiRSsBisf6DbxuV2mINVjnpRa/1CioIUQVhKrSdtYW7iEh1kJddEIKKC0UF32eeKvl5ntwKAQ3Lv147FJzsUHCSqkyNI0QqGXM+nDpgHY06H6gSd4Mlv+i1gY0vWS/V2vD/aRURKSI/t+RQVNzoe3Gc3MAnDHzDrF8v/b5WE3ByKd/3UwIFJzsUnKSqU+MIkUou9xzE7yi8XupsdNHrHJyt4eniMBXYGBwcKr5mEakZ8vMgLb4gCB2zTpm79Pv0RErVndTRFXxCrVOTfUKLCUh1rSPtlXzasoKTHQpOUl2ocYRIFZJx+qL1UgVhKvN00etcfQrWS10UpnxCKr7ea2XOt3YtvPiWc8n97HTITi18zJwLtZpCSJQ1VNZubvj/RotUGeZ8a+hJOW4NQqknin6fngAWc8nP5eBcTCi65HuPwEofikpDwckOBSepTpLSspjwww5WHFDjCJEqxWKB5JgLa6WOb4YT26wt0y/lE1a48URIW3Arh3+/LBbraJktyKRa129dGoBKDERp1jbwZcHBGWo3KwhSBWEquHX5vH+Rysxisf5nS3LMhelyKccuNF9IOW4dSSpumvClHJzAO7RgdOhyoahWjRn9VnCyQ8FJqhuz2cLXa9U4QqTKy8+DkwX7Sh0r6OR3cm8x/ztssrZAv7j5hF/ERUEm/ULwKTS6c9GxIoEo1XpNaT50XQkHZ2vIcfUGF2/r10I3L+so2/n7YN1bK347JOyArJTin9e/vjVI2QJVFHgHV4v//ZYaLDsNzsZYw9GlX5Nji29EcymTI3iHXCYU1bUe96ytLRQuouBkh4KTVFdqHCFSDWWnW0PExZ38UmLL+UVNRQOOi1fB9z6XhJ6LjtmuOX/M69qaX1gskBJnXS+WsMO6SXH8Duu0o+J41i4YkSoYmQppY+3WpQ+IUlnkZll/T5+NgeSjhUPR2Rg4d6bk5/AKBr/wwkHo4u+9gvR7/gopONmh4CTV2aWNIxrX8eLNO6JoX09tkEWqjfSkC9P7zq+ZykoBJ/dSBJrL3C4eDXL2qNxTdDLPWINUfEGYSthh7WxY3LoNZ0/rhsXn10wFR0GdFuDsVvF1S/WXn2fdm+hyo0Zp8SU/h7u/dQTZP+Kir/WtX33D9Xu3HCg42aHgJDXBn/sSee7HnZxMy8bBBA/0bMAzN2n0SaRasljAnAeOzkZXYpzcc5C4BxK2XxiZStxd/Joxk6N1qqNtZKrga03aZ8tisU4LS0+yNhNIT7zk+4uO5WWDmy+4+1m/uvmCm1/hr4XOXXTc2b16TZ+0WKy/JrYwdLRwOEo9bv2zaI+zZ0EYqldMQIrQ+j0DKDjZoeAkNUVyZg6TF+xh7tbjADSs5cmbd0TRsX6AwZWJiFQAcz6cPnTRVL+CUarLTYfyrVd4ZCokyro+pCp98M/PvSgAXfw1oeixsmrgYY+Ds53Q5XuZcxfdN6Kj4rmzRafQ2YJSbPFh/GIOztapdJcbNaomneiqEwUnOxScpKb5c18iE+fuJDE1G5MJxnSvz4T+TfFwcTK6NBGRimWxWDuQ2dZMFYxQJccUf717wIVOfiFtrIEqsDE4VuDfnxaL9cN8SUEoPbH4Fvf2uHiDVx3rupjzX72DCu4XHHN0tTYPOZdsnRKalVxwS7lwO3fJ/ayUsmk04uR+BaGrmPPFrfXJybQGoEJT6Y4WfI2F7Ms0JLExWQP15UaNvEO0xqiKUXCyQ8FJaqKUc7m8+usevt9kXVRdL8CDN++IomvDQIMrExGpBM4lF6yX2nkhVJ3cV/y0Kyc367op28hUG+u6KRePK3vN3HMFged8+EkoGoTSEiEjCfJzSv+8Dk7gWadwIPIOLhyOzn918byymkvLYrF2gLtssEq2fy47tWzqcPW5EKIcXaztuzOSSn6cR62iU+jOf/UN195i1YyCkx0KTlKTrThwkok/7uBEShYA93aN4PmBzfB01eiTiEghuVnWdvDn10wl7ITEXcW3hDY5QGDkhTVTQa2sx4usH0qCtIKAVOLIxiXc/C4ZGQouGoS8gqyjZJW5uUdpmPOt4amk0FXkfMH3JU1DdPW5KAxdMmrkV8/aYEVqDAUnOxScpKZLy8pl6sJ9zFxvbWkc5ufOm3dE0aNxLYMrExGp5MxmOHPkwpqp86GqNKMYxXF0vcw0uTqFp8t51lE3tSuRl1N0emFelrVtt1+EtRGI1hlJAQUnOxScRKz+OnSK537cwbGz1oWuIzrX4583N8PbrQZ35hIRuRppCYXXTCXutk4Nu9y6ofPfu/nqA7yIwRSc7FBwErkgIzuPN37fxzcF+z6F+rox9fYoejepbXBlIiIiIuXvSrJBFZ8EKyLXwtPViclDWjH74a5EBHpwIiWL0V9uYMIP20k5l2t0eSIiIiKVhoKTiNC1YSALn7qO+3s0wGSCHzYf46Z3V7B0b6LRpYmIiIhUClcVnOLi4jh27Jjt/oYNGxg/fjyfffZZmRUmIhXLw8WJlwe34IdHutGwlieJqdk88PUm/v7dNpIzr6AVroiIiEg1dFXB6W9/+xvLli0DICEhgRtvvJENGzbwwgsvMHny5DItUEQqVsf6Afz21HU83KshDiaYt/U4/d5ZyR+7E4wuTURERMQwVxWcdu3aRefOnQH4/vvvadWqFWvWrOF///sfM2bMKMv6RMQAbs6O/PPm5vz4WHca1/HiVHo2j3y7mSdmbeVMhkafREREpOa5quCUm5uLq6srAEuWLOHWW28FoFmzZsTHx5dddSJiqHb1/PnliZ483qcRjg4mFmw/wY3vrODXHfpzLiIiIjXLVQWnli1bMn36dFatWsXixYsZMGAAACdOnCAwMLBMCxQRY7k5O/KPAc2Y93h3mgZ5czojh7Ezt/DYfzdzMi3b6PJEREREKsRVBac33niDTz/9lD59+jBixAjatGkDwM8//2ybwici1UtUXT8WPNGTJ/tG4uRgYuGuBG56dwU/bTtODdsOTkRERGqgq94ANz8/n9TUVPz9/W3Hjh49ioeHB3Xq1CmzAsuaNsAVuXa7T6Qw4Ycd7IlPBeDGFkG8OrQVdXzcDK5MREREpPTKfQPcc+fOkZ2dbQtNMTExvPfee+zfv79ShyYRKRstQ335aVwPnr6xCc6OJhbvSaTfOyv4cfMxjT6JiIhItXRVwWnIkCF88803ACQnJ9OlSxfefvtthg4dyieffFKmBYpI5eTs6MCTfSNZ8ERPWof5kpqVxzM/bOf+GRuJTzlndHkiIiIiZeqqgtOWLVu47rrrAJgzZw5BQUHExMTwzTff8MEHH5T6eT755BOioqLw8fHBx8eHbt26sXDhQruP+eGHH2jWrBlubm60bt2a33777WregoiUkWbBPsx7vDsT+jfFxdGBZftPctM7K/luY6xGn0RERKTauKrglJmZibe3NwCLFi1i2LBhODg40LVrV2JiYkr9PHXr1uX1119n8+bNbNq0iRtuuIEhQ4awe/fuYq9fs2YNI0aM4IEHHmDr1q0MHTqUoUOHsmvXrqt5GyJSRpwcHRh7fWN+fbInbcP9SMvO47kfdzLqyw0cT9bok4iIiFR9V9UcIioqigcffJDbbruNVq1a8fvvv9OtWzc2b97MoEGDSEhIuOqCAgICmDZtGg888ECRc8OHDycjI4NffvnFdqxr1660bduW6dOnF/t82dnZZGdfaJmcmppKeHi4mkOIlJN8s4X/W32EtxcdIDvPjKeLI/8c1Jy/da6HyWQyujwRERERm3JvDvHyyy/z7LPPUr9+fTp37ky3bt0A6+hTu3btruYpyc/PZ/bs2WRkZNie71Jr166lX79+hY7179+ftWvXXvZ5p06diq+vr+0WHh5+VfWJSOk4Oph4uFcjFj51HR0j/MnIyeeFebsY+cV64s5kGl2eiIiIyFW5quB0xx13EBsby6ZNm/jjjz9sx/v27cu77757Rc+1c+dOvLy8cHV15dFHH2XevHm0aNGi2GsTEhIICgoqdCwoKMjuCNfEiRNJSUmx3eLi4q6oPhG5Og1re/HdI914+ZYWuDk7sObwafq/t5Kv1xzFbNbaJxEREalanK72gcHBwQQHB3Ps2DHAul7paja/bdq0Kdu2bSMlJYU5c+YwevRoVqxYcdnwdKVcXV1xdXUtk+cSkSvj6GDi/p4NuKFZHf7x4w42RJ/hXz/v5ted8bx5exT1a3kaXaKIiIhIqVzViJPZbGby5Mn4+voSERFBREQEfn5+TJkyBbPZfEXP5eLiQuPGjenQoQNTp06lTZs2vP/++8VeGxwcTGJiYqFjiYmJBAcHX83bEJEKUr+WJ7Mf6srkIS3xcHFkQ/QZBry/kv9bHU2+Rp9ERESkCriq4PTCCy/w0Ucf8frrr7N161a2bt3Ka6+9xocffshLL710TQWZzeZCzRwu1q1bN5YuXVro2OLFiy+7JkpEKg8HBxOjutXnj/G96N4okKxcM1N+2cNdn67l8Ml0o8sTERERseuquuqFhoYyffp0br311kLHf/rpJx5//HGOHz9equeZOHEiAwcOpF69eqSlpTFz5kzeeOMN/vjjD2688UZGjRpFWFgYU6dOBaztyHv37s3rr7/OoEGDmD17Nq+99hpbtmyhVatWpXrNK+mcISLlw2KxMGtDHK/9tpf07DxcnRx4+sYmPHhdQxwd1HlPREREKka5d9U7c+YMzZo1K3K8WbNmnDlzptTPk5SUxKhRo2jatCl9+/Zl48aNttAEEBsbS3x8vO367t27M3PmTD777DPatGnDnDlzmD9/fqlDk4hUDiaTib91qccff+/FdZG1yM4zM3XhPoZ9soaDiWlGlyciIiJSxFWNOHXp0oUuXbrwwQcfFDr+xBNPsGHDBtavX19mBZY1jTiJVC4Wi4UfNh1jyq97SMvKw8XRgaf6RfJIr4Y4OV7V/+2IiIiIlMqVZIOrCk4rVqxg0KBB1KtXz7a+aO3atcTFxfHbb79x3XXXXV3lFUDBSaRySkjJ4p/zdvLnviQAWoX5MO2ONjQP0Z9TERERKR/lPlWvd+/eHDhwgNtuu43k5GSSk5MZNmwYu3fv5ttvv72qokWkZgv2deP/Rnfknbva4OvuzK7jqdz60WreX3KQ3Pwr69YpIiIiUtauasTpcrZv30779u3Jz88vq6cscxpxEqn8klKzeGH+LhbvsW4/0LC2J0/f2ISbW4XgoOYRIiIiUkbKfcRJRKQ81fFx47N7O/DBiHYEeLpw5GQG42Zu5ZYPV/PnvkTK8P97REREREpFwUlEKiWTycStbUJZMaEPT/WNxMvViT3xqdw/YxN3TF/L2sOnjS5RREREahAFJxGp1LzdnPn7jU1Y+Y/reaRXQ1ydHNgcc5YRn6/j3v9bz/a4ZKNLFBERkRrgitY4DRs2zO755ORkVqxYoTVOIlJuElOz+OjPQ8zaEEue2frX100tgnjmpqY0DfY2uDoRERGpSsqtHfl9991Xquu++uqr0j5lhVNwEqke4s5k8t6Sg8zbegyzBUwmGNImlPH9mlC/lqfR5YmIiEgVUO77OFVlCk4i1cuhpDTeWXyA33YmAODoYOKujnV54oZIQv3cDa5OREREKjMFJzsUnESqp13HU3hr0X6W7z8JgIuTA/d0ieDx6xtRy8vV4OpERESkMlJwskPBSaR623j0DNP+2M+G6DMAeLg48kDPBjx4XUN83Z0Nrk5EREQqEwUnOxScRKo/i8XCqoOnmPbHfnYeTwHA192ZR3o3ZEz3+ni4OBlcoYiIiFQGCk52KDiJ1BwWi4U/dify9qL9HExKB6CWlyvjrm/EiC71cHVyNLhCERERMZKCkx0KTiI1T77Zws/bj/Pu4oPEnskEIMzPnaf6RjKsfRhOjtrSTkREpCZScLJDwUmk5srNN/P9pjg+XHqIhNQsABrW8uTvNzZhUOsQHBxMBlcoIiIiFUnByQ4FJxHJys3nv+ti+M/yw5zJyAGgeYgPz97UhBua1cFkUoASERGpCRSc7FBwEpHz0rPz+HJ1NJ+vPEJadh4A7er5MaF/U7o3qmVwdSIiIlLeFJzsUHASkUslZ+YwfcURZqyJJivXDECPxoE8e1NT2tXzN7g6ERERKS8KTnYoOInI5SSlZvHxskPM3BBLbr71r8Z+zYN45qYmNA/R3xciIiLVjYKTHQpOIlKSuDOZfLD0ID9uOYbZAiYTDI4K5e83NqFBLU+jyxMREZEyouBkh4KTiJTWoaR03l1ygF93xAPg6GDizg51ebJvJKF+7gZXJyIiItdKwckOBScRuVK7T6TwzqIDLN2XBICLowMju9bj8T6Nqe3tanB1IiIicrUUnOxQcBKRq7U55izT/tjHuiNnAHB3duT+nvV5+LpG+Ho4G1ydiIiIXCkFJzsUnETkWlgsFv46dJppi/azPS4ZAB83Jx7p3Ygx3evj6epkbIEiIiJSagpOdig4iUhZsFgsLNmbxFt/7Gd/YhoAtbxceLxPY/7WpR5uzo4GVygiIiIlUXCyQ8FJRMqS2WxhwY4TvLv4AEdPZwIQ4uvGU30jub1DXZwdHQyuUERERC5HwckOBScRKQ+5+WZ+3HyM95ceJD4lC4D6gR78/cYmDI4KxcHBZHCFIiIicikFJzsUnESkPGXl5jNzfSwfLzvE6YwcAJoFe/PMTU3p17wOJpMClIiISGWh4GSHgpOIVISM7DxmrDnK9BWHScvKA6BNXV8e69OIG1sE46gRKBEREcMpONmh4CQiFSklM5fPVh3my9VHOZebD0DDWp481Ksht7ULUxMJERERAyk42aHgJCJGOJWezddrjvLN2hhSzuUCUMvLlft61OeeLhHaB0pERMQACk52KDiJiJEysvP4bmMc/7c6muPJ5wDwdHFkROd63N+zAaF+7gZXKCIiUnMoONmh4CQilUFuvplfd8QzfcVh9iVY94FycjBxa9tQHunViKbB3gZXKCIiUv0pONmh4CQilYnFYmHFgZN8uuIIa4+cth2/oVkdHunVkM4NAtSJT0REpJwoONmh4CQildX2uGQ+W3mEhbviMRf8zdw23I9HezdUJz4REZFyoOBkh4KTiFR2R09l8MXqI/yw6RjZeWYAGtTy5KHrGjKsvTrxiYiIlJUryQYOFVRTsaZOnUqnTp3w9vamTp06DB06lP3799t9zIwZMzCZTIVubm5uFVSxiEj5q1/Lk38Pbc1fz9/AEzc0xtfdmehTGfxz3k56vrGMj5cdIiUz1+gyRUREahRDg9OKFSsYO3Ys69atY/HixeTm5nLTTTeRkZFh93E+Pj7Ex8fbbjExMRVUsYhIxanl5cozNzVlzfM38PItLQjzc+dUejbT/thPt9eXMuWXPZwo6MwnIiIi5atSTdU7efIkderUYcWKFfTq1avYa2bMmMH48eNJTk6+qtfQVD0Rqaou24mvTSgP925Is2D9nSYiInIlqsxUvUulpKQAEBAQYPe69PR0IiIiCA8PZ8iQIezevfuy12ZnZ5OamlroJiJSFTk7OjC0XRgLn7qOr+/vTPdGgeSZLczdepwB763ivq82sO7IaSrR/4eJiIhUG5VmxMlsNnPrrbeSnJzM6tWrL3vd2rVrOXjwIFFRUaSkpPDWW2+xcuVKdu/eTd26dYtcP2nSJF555ZUixzXiJCLVwY5jyXy6onAnvjbhfjzaqyE3tVQnPhEREXuqZFe9xx57jIULF7J69epiA9Dl5Obm0rx5c0aMGMGUKVOKnM/OziY7O9t2PzU1lfDwcAUnEalWiuvEVz/Qg4d6NeT29nXViU9ERKQYVS44jRs3jp9++omVK1fSoEGDK378nXfeiZOTE7NmzSrxWq1xEpHq7FR6Nt+sOcrXa2NIOWftvFfLy4Ux3etzT9cI/DxcDK5QRESk8qgya5wsFgvjxo1j3rx5/Pnnn1cVmvLz89m5cychISHlUKGISNVSy8uVpws68f1r8PlOfDm8tegA3V//k8kL9nBcnfhERESumKEjTo8//jgzZ87kp59+omnTprbjvr6+uLu7AzBq1CjCwsKYOnUqAJMnT6Zr1640btyY5ORkpk2bxvz589m8eTMtWrQo8TU14iQiNUluvpnfdsYzfcUR9sZbm+OoE5+IiIjVlWQDpwqqqViffPIJAH369Cl0/KuvvmLMmDEAxMbG4uBwYWDs7NmzPPTQQyQkJODv70+HDh1Ys2ZNqUKTiEhN4+zowJC2YdzaJpSVB0/x6YrDrDl8mrlbjzN363H6NK3NI70a0bVhACaTGkmIiIhcTqVY41SRNOIkIjXdjmPJfLryCAt3XtSJr64vj/RuRH914hMRkRqkyjWHqEgKTiIiVjGnM/hiVTTfb4qzdeKLCPTgoesackcHdeITEZHqT8HJDgUnEZHCiuvEF+hp7cR3bzd14hMRkepLwckOBScRkeJlZOfx/aY4vlgVbeu85+HiyPBO4Tx4XUPC/NwNrlBERKRsKTjZoeAkImJfcZ34HM934uvVkOYh+rtTRESqBwUnOxScRERKx2KxsOrgKT5deZi/Dp22He/VpDajukbQp2ltnBwN3Q5QRETkmig42aHgJCJy5XYeS+HTlYf57aJOfEE+rtzZIZzhncIJD/AwtkAREZGroOBkh4KTiMjViz2dyTdrj/LjlmOczcy1He/ZuBbDO4VzU8sgXJ3UjU9ERKoGBSc7FJxERK5ddl4+i/ck8t3GOFYdPGU77u/hzLD2dbm7UziRQd4GVigiIlIyBSc7FJxERMpW3JlMvt8Ux/eb4khMzbYd7xDhz/BO4dwSFYKHi5OBFYqIiBRPwckOBScRkfKRl29m5cGTzNoQx5/7ksgvWAzl5erErW1DGdGpHq3CfDCZTAZXKiIiYqXgZIeCk4hI+UtKzWLOlmN8tzGOmNOZtuMtQny4u3M4Q9qG4evubGCFIiIiCk52KTiJiFQcs9nCuujTzN4Qx++7EsjJNwPg6uTAoNYh3N25Hp3q+2sUSkREDKHgZIeCk4iIMc5m5DB/23Fmb4hjf2Ka7XjDWp4M7xTO7R3qUsvL1cAKRUSkplFwskPBSUTEWBaLhW1xyXy3MY6ft58gMycfACcHEze2CGJ4p3Cui6yNo4NGoUREpHwpONmh4CQiUnmkZ+fxy/YTzN4Yx7a4ZNvxMD937uxYl7s6hhPq525cgSIiUq0pONmh4CQiUjntjU/lu41xzNt6nJRz1s11TSbo3aQ2d3eqR9/mdXB2dDC4ShERqU4UnOxQcBIRqdyycvP5Y3cCszfEsfbIadvxWl4u3N6hLnd3qkeDWp4GVigiItWFgpMdCk4iIlVH9KkMvt8Uxw+bjnEq/cLmul0aBHB353AGtgrBzdnRwApFRKQqU3CyQ8FJRKTqyc038+e+JL7bGMfy/UkU7K2Lj5sTt7UL4+7O9Wgeor/TRUTkyig42aHgJCJStcWnnOOHTdbNdY8nn7Mdb1PXl7s712Nwm1C8XJ0MrFBERKoKBSc7FJxERKoHs9nCX4dPMXtDHIv2JJCbb/3nzMPFkVuirJvrtgv30+a6IiJyWQpOdig4iYhUP6fTs5m75TizN8Zy+GSG7XiTIC+Gd6rHsHZh+Hu6GFihiIhURgpOdig4iYhUXxaLhc0xZ5m1IY5fd54gK9cMgIujA/1bBXN3p3C6NQzEQZvriogICk52KTiJiNQMqVm5/LztBLM3xrLreKrteL0AD4Z3CufODnWp4+NmYIUiImI0BSc7FJxERGqeXcdT+G5jHPO3HictOw8ARwcTvZvUZlj7MPo1D1JbcxGRGkjByQ4FJxGRmutcTj6/7Yxn9sZYNh49azvu7erEoKgQbmsXRqf6AZrKJyJSQyg42aHgJCIiAIdPpjNvy3HmbT1eqK15XX93bmsXxm3twmhY28vACkVEpLwpONmh4CQiIhczmy1sOHqGeVuO89vOeNtUPoC24X4Max/GLVGhBKgrn4hItaPgZIeCk4iIXE5Wbj6L9yQyb+txVhw4Sb7Z+k+kk4OJ65vVYVi7MG5oXgdXJ62HEhGpDhSc7FBwEhGR0jiZls2C7SeYu/VYoa58vu7ODIoK4fb2YbSv568NdkVEqjAFJzsUnERE5EodTExj7tbjzN96nPiULNvxiEAPhrYNY1j7MCICPQ2sUEREroaCkx0KTiIicrXyzRbWHznNj1uO8/uueDJy8m3nOkT4c1u7MG6JCsHPQ+uhRESqAgUnOxScRESkLGTm5LF4TyI/bjnO6oMnKVgOhYujAzc0q8Nt7cO4vmkdXJwcjC1UREQuS8HJDgUnEREpa0mpWfy07QRztx5nb/yF9VD+Hs7cEhXKsPZhtA3303ooEZFKRsHJDgUnEREpT3vjU5lXsB4qKS3bdrxhLU9uaxfG0HZhhAd4GFihiIicp+Bkh4KTiIhUhHyzhb8OnWLe1uP8viuBc7kX1kN1rh/AsPZhDGwdgq+7s4FViojUbFeSDQydeD116lQ6deqEt7c3derUYejQoezfv7/Ex/3www80a9YMNzc3WrduzW+//VYB1YqIiJSeo4OJXk1q8+7wtmx6sR9v39mGno1rYTLBhqNneH7uTjq9uoSxM7ewdG8iuflmo0sWERE7DB1xGjBgAHfffTedOnUiLy+Pf/7zn+zatYs9e/bg6Vl8W9c1a9bQq1cvpk6dyi233MLMmTN544032LJlC61atSrxNTXiJCIiRopPOWddD7XlGAcS023HAz1dGNzGuh6qdZiv1kOJiFSAKjtV7+TJk9SpU4cVK1bQq1evYq8ZPnw4GRkZ/PLLL7ZjXbt2pW3btkyfPr3E11BwEhGRysBisbD7RCpztxzn5+3HOZWeYzvXqLYnw9rXZWi7MML83A2sUkSkeruSbOBUQTWVSkpKCgABAQGXvWbt2rU8/fTThY7179+f+fPnF3t9dnY22dkXFuempqYWe52IiEhFMplMtArzpVWYL/+8uRmrDp1i7pbjLNqdwOGTGUz7Yz9vLdpP1waB3NY+jIGtgvF203ooERGjVJrgZDabGT9+PD169LA75S4hIYGgoKBCx4KCgkhISCj2+qlTp/LKK6+Uaa0iIiJlycnRgeub1uH6pnVIy8pl4c4E5m49xrojZ1h75DRrj5zm5Z92cVOLYG5rH8Z1jWvh5Kj9oUREKlKlCU5jx45l165drF69ukyfd+LEiYVGqFJTUwkPDy/T1xARESkr3m7O3NUpnLs6hXPsbKZtPdThkxn8vP0EP28/QS0vV4a0DeW2dmG0DPXReigRkQpQKYLTuHHj+OWXX1i5ciV169a1e21wcDCJiYmFjiUmJhIcHFzs9a6urri6upZZrSIiIhWlrr8HY69vzON9GrHjWArzth7n5+0nOJWezf+tjub/VkfTNMiboe3CGNwmhLr+2h9KRKS8GNocwmKx8MQTTzBv3jyWL19OZGRkiY8ZPnw4mZmZLFiwwHase/fuREVFqTmEiIhUe7n5ZlbsP8m8rcdZvDeRnLwLbcw7RPgzOCqEm6NCqOPtZmCVIiJVQ5Xpqvf4448zc+ZMfvrpJ5o2bWo77uvri7u7tYvQqFGjCAsLY+rUqYC1HXnv3r15/fXXGTRoELNnz+a1115TO3IREalxUs7l8tvOeH7adpz10Wc4/y+6gwm6Ngzk1jahDGgVjJ+Hi7GFiohUUlUmOF1uTvZXX33FmDFjAOjTpw/169dnxowZtvM//PADL774IkePHiUyMpI333yTm2++uVSvqeAkIiLVUWJqFr/uiGfBjhNsjU22HXcq2Ih3cJsQbmwRjJdrpZilLyJSKVSZ4GQEBScREanu4s5ksmDHCRZsj2dv/IVtOFydHOjbvA6Do0K5vlkd3JwdDaxSRMR4Ck52KDiJiEhNcjAxjQU74lmw/QTRpzJsx71cnbipRRCD24TSM7IWzmpvLiI1kIKTHQpOIiJSE1ksFnafSGXB9hMs2H6CEylZtnN+Hs4MbBXM4DahdGkQiKOD2puLSM2g4GSHgpOIiNR0ZrOFrXFnWbA9nl92xHMqPdt2rra3K4Nah3Br21DahftpjygRqdYUnOxQcBIREbkgL9/M+ugzLNh+goW7Ekg5l2s7F+bnzuA2oQxuE0KLEG20KyLVj4KTHQpOIiIixcvJM7Pq4EkWbD/Boj2JZObk2841qu1ZEKJCaVTby8AqRUTKjoKTHQpOIiIiJTuXk8+f+5JYsP0Ef+5PKrTRbosQH25tG8otUSHU9fcwsEoRkWuj4GSHgpOIiMiVScvKZfGeRH7efoLVB0+RZ77w0aF9PT9ubRPKzVEh1PF2M7BKEZErp+Bkh4KTiIjI1TuTkcPvuxJYsP0E66JPc/5ThIMJujYMZHCbUAa2CsbPw8XYQkVESkHByQ4FJxERkbKRmJrFrzviWbDjBFtjk23HnRxM9GpSm8FtQrixRTBerk7GFSkiYoeCkx0KTiIiImUv7kwmC3acYMH2ePbGp9qOuzo50Ld5HQZHhXJ9szq4OTsaWKWISGEKTnYoOImIiJSvQ0lpLNgez4LtJzhyKsN23NPFkZtaBnNrm1B6NK6Fi5ODgVWKiCg42aXgJCIiUjEsFgu7T6SyYMcJftkez/Hkc7Zzfh7ODGwVzOCoULo0DMTRQXtEiUjFU3CyQ8FJRESk4pnNFrbGnWXB9nh+2RHPqfRs27na3q4Mah3C4DYhtAv3x0EhSkQqiIKTHQpOIiIixso3W1h35DQLtp9g4a4EUs7l2s4FerrQu2ltrm9ah16RtfH1cDawUhGp7hSc7FBwEhERqTxy8sysPnSSn7edYMneJNKz82znHEzQIcKfPk3rcH3TOjQP8cZk0miUiJQdBSc7FJxEREQqp5w8M5tjzrJsfxLL9iVxMCm90PlgHzeub1abPk3r0KNxLbU5F5FrpuBkh4KTiIhI1RB3JpPlB06yfF8Sfx0+RVau2XbO2dFE5wYBXN+0Dn2a1qFRbU+NRonIFVNwskPBSUREpOrJys1nffQZlu1LYtn+JGJOZxY6Hx7gzvUFU/q6NQrUflEiUioKTnYoOImIiFR9R06ms2z/SZbvT2L9kTPk5F8YjXJ1cqB7o0Cub2YNUuEBHgZWKiKVmYKTHQpOIiIi1UtGdh5rDp+2rY2KT8kqdL5RbU/raFSzOnSqH6CNd0XERsHJDgUnERGR6stisXAgMd0WojbFnCXffOGjjqeLIz0ja9nWRgX7uhlYrYgYTcHJDgUnERGRmiPlXC6rD55i2f4klu8/WWjjXYDmIT5c37Q21zerQ7twP5wcNRolUpMoONmh4CQiIlIzmc0Wdp9ItY5G7U9iW1wyF38K8nFzolcT6+a7vZvWppaXq3HFikiFUHCyQ8FJREREAE6nZ7Py4EmW7TvJigMnSTmXaztnMkFUXT/raFTTOrQO88XBQe3ORaobBSc7FJxERETkUvlmC9vizrJs30mW7U9i94nUQucDPV3oXRCiekXWxtfD2aBKRaQsKTjZoeAkIiIiJUlMzWLFfmuIWnXwFOnZebZzjg4m2tfzs7U7bxbsrc13RaooBSc7FJxERETkSuTkmdkUc4bl+0+ybF8SB5PSC50P9nHj+ma16dO0Dj0a18LL1cmgSkXkSik42aHgJCIiItci7kwmyw+cZPm+JP46fIqs3Aub7zo7mujcIIBekbXpGVmL5sE+WhslUokpONmh4CQiIiJlJSs3n/XRZ1i2z9qpL+Z0ZqHzgZ4u9Ghci56RtbgushYhvu4GVSoixVFwskPBSURERMpL9KkMlu1LYtXBk6yPPkNmTn6h841qe3JdZG16Nq5F10aBmtYnYjAFJzsUnERERKQi5OSZ2RJ7lr8OnWLVwVPsOJaM+aJPXU4OJtqG+9lGo9rU1Qa8IhVNwckOBScRERExQkpmLmuPWEPU6kOnikzr83Z1omujQK6LrEXPxrVoUMtT3fpEypmCkx0KTiIiIlIZxJ3JZNXBU/x16BR/HT5FcmZuofNhfu70aBxIz8ja9GgUSKCXq0GVilRfCk52KDiJiIhIZZNvtrD7RIp1NOrgKTbHnCUn31zompahPtZpfY1r07G+P27OjgZVK1J9KDjZoeAkIiIilV1mTh4bos+wumBa376EtELnXZ0c6NwgwNqxr3EtWoSo7bnI1VBwskPBSURERKqapLQs1hw6XbA+6iSJqdmFzgd6utC9cS2uK2h9HuqntucipVFlgtPKlSuZNm0amzdvJj4+nnnz5jF06NDLXr98+XKuv/76Isfj4+MJDg4u1WsqOImIiEhVZrFYOJSUbmsyse7I6SJtzxvW9iwIUbXp2jAAbzdng6oVqdyuJBsYunlARkYGbdq04f7772fYsGGlftz+/fsLvbE6deqUR3kiIiIilY7JZCIyyJvIIG/u79mAnDwzW8+3PT90iu1xyRw5mcGRkxl8vTYGx/NtzxsXtD0P98NZbc9FrlilmapnMplKPeJ09uxZ/Pz8rup1NOIkIiIi1VnKuVzWHj7N6kMnWX3wFEcvaXvu5epE14YFbc8ja9FQbc+lBqsyI05Xq23btmRnZ9OqVSsmTZpEjx49LnttdnY22dkX5gGnpqZWRIkiIiIihvB1d2ZAq2AGtLIuY4g7k2kbjVpz6BRnM3NZsjeRJXsTAQj1daNnZC1bowm1PRcpXpUKTiEhIUyfPp2OHTuSnZ3NF198QZ8+fVi/fj3t27cv9jFTp07llVdeqeBKRURERCqH8AAP7u5cj7s718NstrD7RCqrCkajNh09y4mULL7fdIzvNx0DoEWIj200qlP9ALU9FylQpabqFad3797Uq1ePb7/9ttjzxY04hYeHa6qeiIiI1HjncvLZcPSMdUTq4Cn2xheemePkYKJJkDdRdX1pXdeXqDA/mgZ74+KkNVJSPVT7qXoX69y5M6tXr77seVdXV1xdNeQsIiIicil3F0d6N6lN7ya1ATiZls2aw6dsG/EmpGaxJz6VPfGpzN4YB4CLowPNQ7xtQap1XV8i63jhpIYTUs1V+eC0bds2QkJCjC5DREREpMqr7e3KkLZhDGkbhsViIT4lix3HUth5PJkdx1LYcSyFlHO5bD+WwvZjKUAsAG7ODrQI8SGqrh+tw3yJqutLw9peOGpTXqlGDA1O6enpHDp0yHY/Ojqabdu2ERAQQL169Zg4cSLHjx/nm2++AeC9996jQYMGtGzZkqysLL744gv+/PNPFi1aZNRbEBEREamWTCYToX7uhPq52xpNWCwW4s6cY8fxZHYWBKldx1NIy85jS2wyW2KTbY/3cHGkVWjBFL+6vkTV9SMiwAMHhSmpogwNTps2bSq0oe3TTz8NwOjRo5kxYwbx8fHExsbazufk5PDMM89w/PhxPDw8iIqKYsmSJcVuiisiIiIiZctkMlEv0IN6gR7cEhUKgNls4ejpDHYetwapncdS2HUihcyC9VMbjp6xPd7bzYnWYRfWS0XV9aWuv7vaoUuVUGmaQ1QU7eMkIiIiUr7yzRaOnExn+7EUdh5LZsfxFPacSCU7z1zkWj8PZ9v0vtYFYSrE101hSirElWQDBScRERERKXe5+WYOJqbb1kvtPJ7C3vhUcvOLfhSt5eVaEKR8bR396ni7GVC1VHcKTnYoOImIiIhUDtl5+RxISLetmdp+LIUDiWnkm4t+PA32cSuY4mcNUq3DfLVZr1wzBSc7FJxEREREKq+s3Hz2xKfamk/sPJ7MoaR0islShPm520ak2tT1o1WoL74ezhVftFRZCk52KDiJiIiIVC0Z2XnsiU8taD5hXTN15GRGsdfWD/SgdV0/28hUy1AfvN0UpqR4Ck52KDiJiIiIVH2pWbnsPp7KjoIgtfNYCrFnMotcZzJBw1qedIwIoEN9fzrVD6B+oIeaTwig4GSXgpOIiIhI9ZScmVOoLfrO4ykcTz5X5LpaXi50jAigY31/OtYPoGWoD86ODgZULEZTcLJDwUlERESk5jiVns222GQ2xZxlc8wZtselkJNfuC26m7MD7cL9bUGqfT0/Te+rIRSc7FBwEhEREam5snLz2XU8hY1HrUFqU8xZkjNzC13jYIJmwT62INWpvj8hvu4GVSzlScHJDgUnERERETnPbLZw+GQ6G4+eZVPMGTYdPVvsWqkwP/dCQapJHW8cHLROqqpTcLJDwUlERERE7ElMzWLTRUFq94mUIu3Qvd2c6BBhbTbRMcKfNuF+uDk7GlOwXDUFJzsUnERERETkSqRn5xWsk7IGqS2xZ8nMyS90jbOjiVZhvrYg1SHCXxv0VgEKTnYoOImIiIjItcjLN7M3Ps0WpDYePUNSWnaR6xrW9qTTRd371Aa98lFwskPBSURERETKksViIe7MOTbFnLGulTp6hoNJ6UWuUxv0ykfByQ4FJxEREREpb2czctgSe9YWpHYcUxv0ykjByQ4FJxERERGpaBe3Qd901NoGPeWc2qAbTcHJDgUnERERETFaoTboR8+wMeYMcWfOFbnu0jbojWt74aTpfWVGwckOBScRERERqYzOt0HfePQMm2LOsOdEapE26C5ODjSs5UlkkDeRdbystyAvIgI9tV7qKig42aHgJCIiIiJVwfk26BuPnmFzTPFt0M9zcjDRoJYnkUFeNK5jDVVNgrypX8sDVyftL3U5Ck52KDiJiIiISFWUb7Zw/Ow5DialcTApnYOJ6Rwq+P5ygcrRwUREoEfB6JR3QbDyolFtL23Yi4KTXQpOIiIiIlKdmM0W4lOzOJiYxqGCQHUwKY2DiemkZecV+xiTCeoFWANV4zreNAmyBqtGdTzxcHGq4HdgHAUnOxScRERERKQmsFgsJKZm20LUwSTrCNWBxPQiHf0uVtffvWDtlDeNC9ZRNa7jVS1bpSs42aHgJCIiIiI1mcVi4VR6DgeTCo9QHUpK51R6zmUfF+LrRuOCtVPnm1I0ru2Nr0fVDVQKTnYoOImIiIiIFO9MRg4HE9MKRqcuTPlLSsu+7GPqeLsSWTDVr7Gt0583AZ4uFVj51VFwskPBSURERETkyqRk5nLo5IUpfweT0jmUmMaJlKzLPibQ08UWqM43pYis400tLxdMJlMFVn95Ck52KDiJiIiIiJSNtKxcDp/MsI1Snf967GzRzXzP8/NwJrKOF+/c1ZbwAI8KrLaoK8kGNadlhoiIiIiIlClvN2fahvvRNtyv0PHMnDwOJ2UUaZ0ecyaT5MxcNh49i4971VobpeAkIiIiIiJlysPFidZ1fWld17fQ8azcfI6czODo6Qx8FZxERERERESKcnN2pEWoDy1Cq96SGQejCxAREREREansFJxERERERERKoOAkIiIiIiJSAgUnERERERGREig4iYiIiIiIlEDBSUREREREpAQKTiIiIiIiIiVQcBIRERERESmBgpOIiIiIiEgJDA1OK1euZPDgwYSGhmIymZg/f36Jj1m+fDnt27fH1dWVxo0bM2PGjHKvU0REREREajZDg1NGRgZt2rTh448/LtX10dHRDBo0iOuvv55t27Yxfvx4HnzwQf74449yrlRERERERGoyJyNffODAgQwcOLDU10+fPp0GDRrw9ttvA9C8eXNWr17Nu+++S//+/curTBERERERqeGq1BqntWvX0q9fv0LH+vfvz9q1ay/7mOzsbFJTUwvdRERERERErkSVCk4JCQkEBQUVOhYUFERqairnzp0r9jFTp07F19fXdgsPD6+IUkVEREREpBoxdKpeRZg4cSJPP/207X5KSgr16tXTyJOIiIiISA13PhNYLJYSr61SwSk4OJjExMRCxxITE/Hx8cHd3b3Yx7i6uuLq6mq7f/4XRyNPIiIiIiICkJaWhq+vr91rqlRw6tatG7/99luhY4sXL6Zbt26lfo7Q0FDi4uLw9vbGZDKVdYlXLDU1lfDwcOLi4vDx8TG6nBpPP4/KRz+TykU/j8pHP5PKRz+TykU/j8qnMv1MLBYLaWlphIaGlnitocEpPT2dQ4cO2e5HR0ezbds2AgICqFevHhMnTuT48eN88803ADz66KN89NFH/OMf/+D+++/nzz//5Pvvv+fXX38t9Ws6ODhQt27dMn8v18rHx8fw3zhygX4elY9+JpWLfh6Vj34mlY9+JpWLfh6VT2X5mZQ00nSeoc0hNm3aRLt27WjXrh0ATz/9NO3atePll18GID4+ntjYWNv1DRo04Ndff2Xx4sW0adOGt99+my+++EKtyEVEREREpFwZOuLUp08fuwuxZsyYUexjtm7dWo5ViYiIiIiIFFal2pFXR66urvzrX/8q1MBCjKOfR+Wjn0nlop9H5aOfSeWjn0nlop9H5VNVfyYmS2l674mIiIiIiNRgGnESEREREREpgYKTiIiIiIhICRScRERERERESqDgJCIiIiIiUgIFJwN9/PHH1K9fHzc3N7p06cKGDRuMLqnGmjp1Kp06dcLb25s6deowdOhQ9u/fb3RZUuD111/HZDIxfvx4o0up0Y4fP84999xDYGAg7u7utG7dmk2bNhldVo2Vn5/PSy+9RIMGDXB3d6dRo0ZMmTLF7jYfUrZWrlzJ4MGDCQ0NxWQyMX/+/ELnLRYLL7/8MiEhIbi7u9OvXz8OHjxoTLE1gL2fR25uLs899xytW7fG09OT0NBQRo0axYkTJ4wruAYo6c/IxR599FFMJhPvvfdehdV3pRScDPLdd9/x9NNP869//YstW7bQpk0b+vfvT1JSktGl1UgrVqxg7NixrFu3jsWLF5Obm8tNN91ERkaG0aXVeBs3buTTTz8lKirK6FJqtLNnz9KjRw+cnZ1ZuHAhe/bs4e2338bf39/o0mqsN954g08++YSPPvqIvXv38sYbb/Dmm2/y4YcfGl1ajZGRkUGbNm34+OOPiz3/5ptv8sEHHzB9+nTWr1+Pp6cn/fv3Jysrq4IrrRns/TwyMzPZsmULL730Elu2bGHu3Lns37+fW2+91YBKa46S/oycN2/ePNatW0doaGgFVXaVLGKIzp07W8aOHWu7n5+fbwkNDbVMnTrVwKrkvKSkJAtgWbFihdGl1GhpaWmWyMhIy+LFiy29e/e2PPXUU0aXVGM999xzlp49expdhlxk0KBBlvvvv7/QsWHDhllGjhxpUEU1G2CZN2+e7b7ZbLYEBwdbpk2bZjuWnJxscXV1tcyaNcuACmuWS38exdmwYYMFsMTExFRMUTXc5X4mx44ds4SFhVl27dpliYiIsLz77rsVXltpacTJADk5OWzevJl+/frZjjk4ONCvXz/Wrl1rYGVyXkpKCgABAQEGV1KzjR07lkGDBhX6syLG+Pnnn+nYsSN33nknderUoV27dnz++edGl1Wjde/enaVLl3LgwAEAtm/fzurVqxk4cKDBlQlAdHQ0CQkJhf7+8vX1pUuXLvq3vpJISUnBZDLh5+dndCk1ltls5t5772XChAm0bNnS6HJK5GR0ATXRqVOnyM/PJygoqNDxoKAg9u3bZ1BVcp7ZbGb8+PH06NGDVq1aGV1OjTV79my2bNnCxo0bjS5FgCNHjvDJJ5/w9NNP889//pONGzfy5JNP4uLiwujRo40ur0Z6/vnnSU1NpVmzZjg6OpKfn8+rr77KyJEjjS5NgISEBIBi/60/f06Mk5WVxXPPPceIESPw8fExupwa64033sDJyYknn3zS6FJKRcFJ5BJjx45l165drF692uhSaqy4uDieeuopFi9ejJubm9HlCNb/UOjYsSOvvfYaAO3atWPXrl1Mnz5dwckg33//Pf/73/+YOXMmLVu2ZNu2bYwfP57Q0FD9TETsyM3N5a677sJisfDJJ58YXU6NtXnzZt5//322bNmCyWQyupxS0VQ9A9SqVQtHR0cSExMLHU9MTCQ4ONigqgRg3Lhx/PLLLyxbtoy6desaXU6NtXnzZpKSkmjfvj1OTk44OTmxYsUKPvjgA5ycnMjPzze6xBonJCSEFi1aFDrWvHlzYmNjDapIJkyYwPPPP8/dd99N69atuffee/n73//O1KlTjS5NwPbvuf6tr1zOh6aYmBgWL16s0SYDrVq1iqSkJOrVq2f7tz4mJoZnnnmG+vXrG11esRScDODi4kKHDh1YunSp7ZjZbGbp0qV069bNwMpqLovFwrhx45g3bx5//vknDRo0MLqkGq1v377s3LmTbdu22W4dO3Zk5MiRbNu2DUdHR6NLrHF69OhRpEX/gQMHiIiIMKgiyczMxMGh8D/jjo6OmM1mgyqSizVo0IDg4OBC/9anpqayfv16/VtvkPOh6eDBgyxZsoTAwECjS6rR7r33Xnbs2FHo3/rQ0FAmTJjAH3/8YXR5xdJUPYM8/fTTjB49mo4dO9K5c2fee+89MjIyuO+++4wurUYaO3YsM2fO5KeffsLb29s2/9zX1xd3d3eDq6t5vL29i6wv8/T0JDAwUOvODPL3v/+d7t2789prr3HXXXexYcMGPvvsMz777DOjS6uxBg8ezKuvvkq9evVo2bIlW7du5Z133uH+++83urQaIz09nUOHDtnuR0dHs23bNgICAqhXrx7jx4/n3//+N5GRkTRo0ICXXnqJ0NBQhg4dalzR1Zi9n0dISAh33HEHW7Zs4ZdffiE/P9/2b31AQAAuLi5GlV2tlfRn5NLw6uzsTHBwME2bNq3oUkvH6LZ+NdmHH35oqVevnsXFxcXSuXNny7p164wuqcYCir199dVXRpcmBdSO3HgLFiywtGrVyuLq6mpp1qyZ5bPPPjO6pBotNTXV8tRTT1nq1atncXNzszRs2NDywgsvWLKzs40urcZYtmxZsf92jB492mKxWFuSv/TSS5agoCCLq6urpW/fvpb9+/cbW3Q1Zu/nER0dfdl/65ctW2Z06dVWSX9GLlXZ25GbLBZtMS4iIiIiImKP1jiJiIiIiIiUQMFJRERERESkBApOIiIiIiIiJVBwEhERERERKYGCk4iIiIiISAkUnEREREREREqg4CQiIiIiIlICBScREREREZESKDiJiIjYYTKZmD9/vtFliIiIwRScRESk0hozZgwmk6nIbcCAAUaXJiIiNYyT0QWIiIjYM2DAAL766qtCx1xdXQ2qRkREaiqNOImISKXm6upKcHBwoZu/vz9gnUb3ySefMHDgQNzd3WnYsCFz5swp9PidO3dyww034O7uTmBgIA8//DDp/9/O/YRE0cdxHH9P2J/drSBZk6VLh0RMKMgCTTuEYBkUxkoIS2xdwlLpEkRiZegxqpMLSp6MBA+BhBbWUQgFSYO2bkUgYZGHEvSizyFYWIpn5akn13i/TjO/7zC/78ztw8zv9+1b1jX9/f2Ul5ezefNmYrEYra2tWfXPnz9z+vRpwuEwJSUlDA8PZ2rz8/MkEgmKiooIhUKUlJT8EPQkSeufwUmStK5dv36deDzO9PQ0iUSCpqYm0uk0AAsLCxw7dowdO3YwOTnJ0NAQz549ywpGqVSKlpYWLly4wKtXrxgeHmbPnj1Zc9y6dYszZ84wMzPDiRMnSCQSfPnyJTP/69evGR0dJZ1Ok0qliEajf+4FSJL+iGBlZWVlrZuQJOlnzp07x8DAAFu2bMkab29vp729nSAIaG5uJpVKZWqVlZUcOHCAnp4e+vr6uHr1Kh8+fCASiQAwMjLCyZMnmZ2dpbi4mF27dnH+/Hm6u7t/2kMQBHR0dNDV1QV8D2Nbt25ldHSU48ePc+rUKaLRKP39/f/TW5Ak5QPXOEmS8trRo0ezghFAYWFh5riqqiqrVlVVxcuXLwFIp9Ps378/E5oAqqurWV5e5u3btwRBwOzsLLW1tf/aw759+zLHkUiE7du3Mzc3B8DFixeJx+NMTU1RV1dHQ0MDhw8f/k/PKknKXwYnSVJei0QiP/w697uEQqFVXbdx48as8yAIWF5eBqC+vp73798zMjLC2NgYtbW1tLS0cPv27d/eryRp7bjGSZK0rr148eKH87KyMgDKysqYnp5mYWEhUx8fH2fDhg2Ulpaybds2du/ezfPnz3+ph6KiIpLJJAMDA9y7d4/e3t5fup8kKf/4xUmSlNeWlpb4+PFj1lhBQUFmA4ahoSEOHjxITU0NDx48YGJigvv37wOQSCS4efMmyWSSzs5OPn36RFtbG2fPnqW4uBiAzs5Ompub2blzJ/X19Xz9+pXx8XHa2tpW1d+NGzeoqKigvLycpaUlHj9+nAlukqS/h8FJkpTXnjx5QiwWyxorLS3lzZs3wPcd7wYHB7l06RKxWIyHDx+yd+9eAMLhME+fPuXy5cscOnSIcDhMPB7nzp07mXslk0kWFxe5e/cuV65cIRqN0tjYuOr+Nm3axLVr13j37h2hUIgjR44wODj4G55ckpRP3FVPkrRuBUHAo0ePaGhoWOtWJEl/Odc4SZIkSVIOBidJkiRJysE1TpKkdcu/zSVJf4pfnCRJkiQpB4OTJEmSJOVgcJIkSZKkHAxOkiRJkpSDwUmSJEmScjA4SZIkSVIOBidJkiRJysHgJEmSJEk5/APk00ys2xM/wgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============ RUN TRAINING V·ªöI EARLY STOPPING ============\n",
        "N_EPOCHS = NUM_EPOCHS\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "patience_counter = 0           # Bi·∫øn ƒë·∫øm s·ªë l·∫ßn kh√¥ng c·∫£i thi·ªán\n",
        "patience_limit = EARLY_STOPPING_PATIENCE # L·∫•y t·ª´ config c·ªßa Th·∫Øng (b·∫±ng 3)\n",
        "\n",
        "print(f\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán {N_EPOCHS} epochs v·ªõi Early Stopping (patience={patience_limit})...\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    # Logic Checkpoint & Early Stopping\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), CHECKPOINT_DIR / 'best_model.pth')\n",
        "        patience_counter = 0  # Reset bi·∫øn ƒë·∫øm v√¨ ƒë√£ t√¨m th·∫•y model t·ªët h∆°n\n",
        "        save_msg = \"--> Saved Best Model\"\n",
        "    else:\n",
        "        patience_counter += 1 # TƒÉng bi·∫øn ƒë·∫øm v√¨ model kh√¥ng t·ªët h∆°n\n",
        "        save_msg = f\"| Patience: {patience_counter}/{patience_limit}\"\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} {save_msg}')\n",
        "\n",
        "    # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng\n",
        "    if patience_counter >= patience_limit:\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"D·ª™NG S·ªöM (Early Stopping) v√¨ val_loss kh√¥ng gi·∫£m sau {patience_limit} epoch.\")\n",
        "        break\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(\"Hu·∫•n luy·ªán ho√†n t·∫•t!\")\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4iF9vEYukQs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆Ø·ªöC 5 - D·ªäCH C√ÇU M·ªöI (INFERENCE)\n",
        "\n",
        "### Task 4: H√†m translate() v·ªõi Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate(sentence, model, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"\n",
        "    D·ªãch m·ªôt c√¢u ti·∫øng Anh sang ti·∫øng Ph√°p\n",
        "    \n",
        "    Args:\n",
        "        sentence: C√¢u ti·∫øng Anh (string)\n",
        "        model: Seq2Seq model ƒë√£ train\n",
        "        src_vocab: T·ª´ ƒëi·ªÉn ti·∫øng Anh\n",
        "        tgt_vocab: T·ª´ ƒëi·ªÉn ti·∫øng Ph√°p\n",
        "        device: CUDA ho·∫∑c CPU\n",
        "        max_len: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa c√¢u d·ªãch\n",
        "    \n",
        "    Returns:\n",
        "        translated_sentence: C√¢u ti·∫øng Ph√°p (string)\n",
        "    \"\"\"\n",
        "    model.eval()  # Chuy·ªÉn sang ch·∫ø ƒë·ªô evaluation\n",
        "    \n",
        "    # 1. TOKENIZE c√¢u ti·∫øng Anh\n",
        "    tokens = tokenize_sentence(sentence, language=\"en\")\n",
        "    \n",
        "    # 2. TH√äM special tokens <sos>, <eos>\n",
        "    tokens = ['<sos>'] + tokens + ['<eos>']\n",
        "    \n",
        "    # 3. ENCODE th√†nh indices\n",
        "    src_indexes = src_vocab.encode(tokens)\n",
        "    \n",
        "    # 4. CHUY·ªÇN sang tensor v√† ƒë∆∞a l√™n device\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)  # [1, src_len]\n",
        "    src_len = torch.LongTensor([len(src_indexes)])  # Ph·∫£i ·ªü CPU\n",
        "    \n",
        "    # 5. ENCODER: L·∫•y context vector (hidden, cell)\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor, src_len)\n",
        "    \n",
        "    # 6. DECODER: Greedy decoding (ch·ªçn t·ª´ c√≥ x√°c su·∫•t cao nh·∫•t)\n",
        "    trg_indexes = [tgt_vocab.sos_idx]  # B·∫Øt ƒë·∫ßu v·ªõi <sos>\n",
        "    \n",
        "    for i in range(max_len):\n",
        "        # L·∫•y token cu·ªëi c√πng l√†m input\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "        \n",
        "        # Decoder d·ª± ƒëo√°n token ti·∫øp theo\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        \n",
        "        # Greedy: Ch·ªçn token c√≥ x√°c su·∫•t cao nh·∫•t\n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        # Th√™m v√†o k·∫øt qu·∫£\n",
        "        trg_indexes.append(pred_token)\n",
        "        \n",
        "        # D·ª´ng n·∫øu g·∫∑p <eos>\n",
        "        if pred_token == tgt_vocab.eos_idx:\n",
        "            break\n",
        "    \n",
        "    # 7. DECODE indices th√†nh tokens\n",
        "    trg_tokens = tgt_vocab.decode(trg_indexes)\n",
        "    \n",
        "    # 8. Lo·∫°i b·ªè <sos> v√† <eos>, gh√©p th√†nh c√¢u\n",
        "    # B·ªè token ƒë·∫ßu (<sos>) v√† token cu·ªëi (<eos>)\n",
        "    trg_tokens = [token for token in trg_tokens if token not in ['<sos>', '<eos>', '<pad>']]\n",
        "    \n",
        "    return ' '.join(trg_tokens)\n",
        "\n",
        "\n",
        "# ============ LOAD BEST MODEL ============\n",
        "print(\"ƒêang t·∫£i model t·ªët nh·∫•t...\")\n",
        "\n",
        "# Load vocabularies\n",
        "src_vocab = load_vocab(CHECKPOINT_DIR / \"src_vocab.pth\")\n",
        "tgt_vocab = load_vocab(CHECKPOINT_DIR / \"tgt_vocab.pth\")\n",
        "\n",
        "# Recreate model architecture\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(tgt_vocab)\n",
        "\n",
        "enc = Encoder(INPUT_DIM, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(CHECKPOINT_DIR / 'best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ ƒê√£ t·∫£i model th√†nh c√¥ng!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TEST H√ÄM TRANSLATE() V·ªöI 3 C√ÇU M·∫™U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ TEST TRANSLATE() ============\n",
        "print(\"=\" * 80)\n",
        "print(\"TEST H√ÄM TRANSLATE() - D·ªäCH C√ÇU M·ªöI\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 3 c√¢u test ƒë∆°n gi·∫£n\n",
        "test_sentences = [\n",
        "    \"A man is eating food.\",\n",
        "    \"The children are playing in the park.\",\n",
        "    \"She loves reading books.\"\n",
        "]\n",
        "\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    print(f\"\\nüìù C√¢u {i}:\")\n",
        "    print(f\"   EN: {sentence}\")\n",
        "    \n",
        "    # D·ªãch sang ti·∫øng Ph√°p\n",
        "    translation = translate(sentence, model, src_vocab, tgt_vocab, DEVICE)\n",
        "    print(f\"   FR: {translation}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n‚úÖ Test h√†m translate() ho√†n t·∫•t!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆Ø·ªöC 6 - ƒê√ÅNH GI√Å BLEU SCORE\n",
        "\n",
        "### Task 5: T√≠nh BLEU score tr√™n to√†n b·ªô test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q nltk\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "\n",
        "def calculate_bleu_on_test_set(model, test_loader, src_vocab, tgt_vocab, device, num_samples=None):\n",
        "    \"\"\"\n",
        "    T√≠nh BLEU score tr√™n to√†n b·ªô test set\n",
        "    \n",
        "    Args:\n",
        "        model: Seq2Seq model ƒë√£ train\n",
        "        test_loader: DataLoader c·ªßa test set\n",
        "        src_vocab: T·ª´ ƒëi·ªÉn ti·∫øng Anh\n",
        "        tgt_vocab: T·ª´ ƒëi·ªÉn ti·∫øng Ph√°p\n",
        "        device: CUDA ho·∫∑c CPU\n",
        "        num_samples: S·ªë c√¢u t·ªëi ƒëa ƒë·ªÉ t√≠nh (None = t·∫•t c·∫£)\n",
        "    \n",
        "    Returns:\n",
        "        bleu_score: ƒêi·ªÉm BLEU trung b√¨nh (%)\n",
        "        examples: List c√°c v√≠ d·ª• d·ªãch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    references = []  # Ground truth (c√¢u ƒë√∫ng)\n",
        "    hypotheses = []  # D·ª± ƒëo√°n c·ªßa model\n",
        "    examples = []    # L∆∞u v√≠ d·ª• ƒë·ªÉ ph√¢n t√≠ch\n",
        "    \n",
        "    smoothing = SmoothingFunction().method1  # Tr√°nh BLEU=0 khi kh√¥ng match\n",
        "    \n",
        "    print(\"ƒêang t√≠nh BLEU score tr√™n test set...\")\n",
        "    print(f\"T·ªïng s·ªë c√¢u: {len(test_loader.dataset)}\")\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src, src_len, tgt, tgt_len) in enumerate(test_loader):\n",
        "            # Duy·ªát t·ª´ng c√¢u trong batch\n",
        "            for i in range(src.size(0)):\n",
        "                if num_samples and count >= num_samples:\n",
        "                    break\n",
        "                \n",
        "                # 1. L·∫•y c√¢u ti·∫øng Anh (source)\n",
        "                src_tokens = src_vocab.decode(src[i].tolist())\n",
        "                # B·ªè <pad>, <sos>, <eos>\n",
        "                src_tokens = [t for t in src_tokens if t not in ['<pad>', '<sos>', '<eos>']]\n",
        "                src_text = ' '.join(src_tokens)\n",
        "                \n",
        "                # 2. D·ªãch sang ti·∫øng Ph√°p b·∫±ng model\n",
        "                pred_text = translate(src_text, model, src_vocab, tgt_vocab, device)\n",
        "                pred_tokens = pred_text.split()\n",
        "                \n",
        "                # 3. L·∫•y ground truth (c√¢u ƒë√∫ng)\n",
        "                tgt_tokens = tgt_vocab.decode(tgt[i].tolist())\n",
        "                # B·ªè <pad>, <sos>, <eos>\n",
        "                ref_tokens = [t for t in tgt_tokens if t not in ['<pad>', '<sos>', '<eos>']]\n",
        "                \n",
        "                # 4. L∆∞u ƒë·ªÉ t√≠nh BLEU\n",
        "                references.append([ref_tokens])  # BLEU c·∫ßn list of lists\n",
        "                hypotheses.append(pred_tokens)\n",
        "                \n",
        "                # 5. L∆∞u v√≠ d·ª• ƒë·ªÉ ph√¢n t√≠ch sau\n",
        "                if len(examples) < 10:  # L∆∞u 10 v√≠ d·ª• ƒë·∫ßu\n",
        "                    examples.append({\n",
        "                        'source': src_text,\n",
        "                        'prediction': pred_text,\n",
        "                        'reference': ' '.join(ref_tokens),\n",
        "                        'bleu': sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothing) * 100\n",
        "                    })\n",
        "                \n",
        "                count += 1\n",
        "                \n",
        "                # In progress m·ªói 100 c√¢u\n",
        "                if count % 100 == 0:\n",
        "                    print(f\"  ƒê√£ x·ª≠ l√Ω: {count}/{len(test_loader.dataset)} c√¢u...\")\n",
        "            \n",
        "            if num_samples and count >= num_samples:\n",
        "                break\n",
        "    \n",
        "    # T√≠nh BLEU score trung b√¨nh tr√™n to√†n b·ªô test set\n",
        "    bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smoothing) * 100\n",
        "    \n",
        "    print(f\"\\n‚úÖ ƒê√£ t√≠nh BLEU tr√™n {count} c√¢u\")\n",
        "    \n",
        "    return bleu_score, examples\n",
        "\n",
        "\n",
        "# ============ T√çNH BLEU SCORE ============\n",
        "print(\"=\" * 80)\n",
        "print(\"T√çNH BLEU SCORE TR√äN TEST SET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# T√≠nh BLEU tr√™n to√†n b·ªô test set (ho·∫∑c gi·ªõi h·∫°n 200 c√¢u ƒë·ªÉ nhanh)\n",
        "# ƒê·ªïi num_samples=None ƒë·ªÉ t√≠nh tr√™n to√†n b·ªô test set\n",
        "bleu_score, translation_examples = calculate_bleu_on_test_set(\n",
        "    model, test_loader, src_vocab, tgt_vocab, DEVICE, num_samples=200\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"BLEU Score: {bleu_score:.2f}%\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng\n",
        "if bleu_score >= 30:\n",
        "    print(\"‚úÖ K·∫æT QU·∫¢ T·ªêT: BLEU >= 30% (ch·∫•t l∆∞·ª£ng d·ªãch t·ªët)\")\n",
        "elif bleu_score >= 20:\n",
        "    print(\"‚ö†Ô∏è K·∫æT QU·∫¢ CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C: BLEU >= 20% (ch·∫•t l∆∞·ª£ng d·ªãch kh√°)\")\n",
        "else:\n",
        "    print(\"‚ùå K·∫æT QU·∫¢ Y·∫æU: BLEU < 20% (c·∫ßn c·∫£i thi·ªán)\")\n",
        "\n",
        "print(\"\\nüí° L∆∞u √Ω:\")\n",
        "print(\"  - BLEU c√†ng cao c√†ng t·ªët (t·ªëi ƒëa 100%)\")\n",
        "print(\"  - BLEU > 30%: Ch·∫•t l∆∞·ª£ng d·ªãch t·ªët cho NMT c∆° b·∫£n\")\n",
        "print(\"  - BLEU 20-30%: Ch·∫•t l∆∞·ª£ng trung b√¨nh\")\n",
        "print(\"  - BLEU < 20%: C·∫ßn c·∫£i thi·ªán (th√™m attention, tƒÉng data, etc.)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hi·ªÉn th·ªã 5 v√≠ d·ª• d·ªãch t·ª´ test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ HI·ªÇN TH·ªä 5 V√ç D·ª§ D·ªäCH ============\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"5 V√ç D·ª§ D·ªäCH T·ª™ TEST SET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, example in enumerate(translation_examples[:5], 1):\n",
        "    print(f\"\\nüìù V√≠ d·ª• {i}:\")\n",
        "    print(f\"   EN (Source):     {example['source']}\")\n",
        "    print(f\"   FR (Prediction): {example['prediction']}\")\n",
        "    print(f\"   FR (Reference):  {example['reference']}\")\n",
        "    print(f\"   BLEU score:      {example['bleu']:.2f}%\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆Ø·ªöC 7 - PH√ÇN T√çCH L·ªñI V√Ä ƒê·ªÄ XU·∫§T C·∫¢I TI·∫æN\n",
        "\n",
        "### Task 6: Ph√¢n t√≠ch 5 v√≠ d·ª• d·ªãch (ƒë√∫ng v√† sai) + ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_translation_errors(examples):\n",
        "    \"\"\"\n",
        "    Ph√¢n t√≠ch l·ªói d·ªãch ph·ªï bi·∫øn\n",
        "    \n",
        "    Args:\n",
        "        examples: List c√°c v√≠ d·ª• d·ªãch\n",
        "    \n",
        "    Returns:\n",
        "        analysis: Dictionary ch·ª©a ph√¢n t√≠ch chi ti·∫øt\n",
        "    \"\"\"\n",
        "    analysis = {\n",
        "        'oov_errors': [],      # L·ªói t·ª´ ngo√†i t·ª´ ƒëi·ªÉn (OOV)\n",
        "        'long_sentence': [],   # L·ªói c√¢u d√†i (m·∫•t th√¥ng tin)\n",
        "        'grammar_errors': [],  # L·ªói ng·ªØ ph√°p\n",
        "        'good_translations': [] # D·ªãch t·ªët\n",
        "    }\n",
        "    \n",
        "    for example in examples:\n",
        "        src = example['source']\n",
        "        pred = example['prediction']\n",
        "        ref = example['reference']\n",
        "        bleu = example['bleu']\n",
        "        \n",
        "        # Ph√¢n lo·∫°i l·ªói\n",
        "        \n",
        "        # 1. D·ªãch T·ªêT (BLEU > 40%)\n",
        "        if bleu > 40:\n",
        "            analysis['good_translations'].append({\n",
        "                'example': example,\n",
        "                'reason': 'BLEU score cao, d·ªãch g·∫ßn ƒë√∫ng v·ªõi ground truth'\n",
        "            })\n",
        "        \n",
        "        # 2. L·ªói C√ÇU D√ÄI (> 15 t·ª´ v√† BLEU th·∫•p)\n",
        "        elif len(src.split()) > 15 and bleu < 30:\n",
        "            analysis['long_sentence'].append({\n",
        "                'example': example,\n",
        "                'reason': f'C√¢u d√†i ({len(src.split())} t·ª´) - Context vector c·ªë ƒë·ªãnh kh√¥ng l∆∞u ƒë·ªß th√¥ng tin'\n",
        "            })\n",
        "        \n",
        "        # 3. L·ªói OOV (c√≥ <unk> trong d·ªãch)\n",
        "        elif '<unk>' in pred or 'unk' in pred:\n",
        "            analysis['oov_errors'].append({\n",
        "                'example': example,\n",
        "                'reason': 'C√≥ t·ª´ ngo√†i t·ª´ ƒëi·ªÉn (OOV) ‚Üí d·ªãch th√†nh <unk>'\n",
        "            })\n",
        "        \n",
        "        # 4. L·ªói NG·ªÆ PH√ÅP (BLEU th·∫•p, kh√¥ng ph·∫£i l·ªói tr√™n)\n",
        "        elif bleu < 20:\n",
        "            analysis['grammar_errors'].append({\n",
        "                'example': example,\n",
        "                'reason': 'BLEU th·∫•p - C√≥ th·ªÉ d·ªãch sai ng·ªØ ph√°p, thi·∫øu t·ª´, ho·∫∑c sai nghƒ©a'\n",
        "            })\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "\n",
        "# ============ PH√ÇN T√çCH L·ªñI ============\n",
        "print(\"=\" * 80)\n",
        "print(\"PH√ÇN T√çCH L·ªñI D·ªäCH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ph√¢n t√≠ch 10 v√≠ d·ª• ƒë·∫ßu ti√™n\n",
        "error_analysis = analyze_translation_errors(translation_examples[:10])\n",
        "\n",
        "# 1. D·ªãch T·ªêT\n",
        "print(f\"\\n‚úÖ D·ªäCH T·ªêT ({len(error_analysis['good_translations'])} v√≠ d·ª•):\")\n",
        "for i, item in enumerate(error_analysis['good_translations'][:2], 1):\n",
        "    ex = item['example']\n",
        "    print(f\"\\n   V√≠ d·ª• {i}:\")\n",
        "    print(f\"   EN: {ex['source']}\")\n",
        "    print(f\"   D·ªãch: {ex['prediction']}\")\n",
        "    print(f\"   ƒê√∫ng: {ex['reference']}\")\n",
        "    print(f\"   BLEU: {ex['bleu']:.2f}%\")\n",
        "    print(f\"   ‚úì L√Ω do: {item['reason']}\")\n",
        "\n",
        "# 2. L·ªói C√ÇU D√ÄI\n",
        "print(f\"\\n‚ùå L·ªñI C√ÇU D√ÄI ({len(error_analysis['long_sentence'])} v√≠ d·ª•):\")\n",
        "for i, item in enumerate(error_analysis['long_sentence'][:2], 1):\n",
        "    ex = item['example']\n",
        "    print(f\"\\n   V√≠ d·ª• {i}:\")\n",
        "    print(f\"   EN: {ex['source']}\")\n",
        "    print(f\"   D·ªãch: {ex['prediction']}\")\n",
        "    print(f\"   ƒê√∫ng: {ex['reference']}\")\n",
        "    print(f\"   BLEU: {ex['bleu']:.2f}%\")\n",
        "    print(f\"   ‚úó L√Ω do: {item['reason']}\")\n",
        "\n",
        "# 3. L·ªói OOV\n",
        "print(f\"\\n‚ùå L·ªñI T·ª™ NGO√ÄI T·ª™ ƒêI·ªÇN (OOV) ({len(error_analysis['oov_errors'])} v√≠ d·ª•):\")\n",
        "for i, item in enumerate(error_analysis['oov_errors'][:2], 1):\n",
        "    ex = item['example']\n",
        "    print(f\"\\n   V√≠ d·ª• {i}:\")\n",
        "    print(f\"   EN: {ex['source']}\")\n",
        "    print(f\"   D·ªãch: {ex['prediction']}\")\n",
        "    print(f\"   ƒê√∫ng: {ex['reference']}\")\n",
        "    print(f\"   BLEU: {ex['bleu']:.2f}%\")\n",
        "    print(f\"   ‚úó L√Ω do: {item['reason']}\")\n",
        "\n",
        "# 4. L·ªói NG·ªÆ PH√ÅP\n",
        "print(f\"\\n‚ùå L·ªñI NG·ªÆ PH√ÅP/NGHƒ®A ({len(error_analysis['grammar_errors'])} v√≠ d·ª•):\")\n",
        "for i, item in enumerate(error_analysis['grammar_errors'][:1], 1):\n",
        "    ex = item['example']\n",
        "    print(f\"\\n   V√≠ d·ª• {i}:\")\n",
        "    print(f\"   EN: {ex['source']}\")\n",
        "    print(f\"   D·ªãch: {ex['prediction']}\")\n",
        "    print(f\"   ƒê√∫ng: {ex['reference']}\")\n",
        "    print(f\"   BLEU: {ex['bleu']:.2f}%\")\n",
        "    print(f\"   ‚úó L√Ω do: {item['reason']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn ƒë·ªÉ n√¢ng cao ch·∫•t l∆∞·ª£ng d·ªãch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ƒê·ªÄ XU·∫§T C·∫¢I TI·∫æN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "üìå C√ÅC V·∫§N ƒê·ªÄ C·ªêT L√ïI C·ª¶A M√î H√åNH HI·ªÜN T·∫†I:\n",
        "\n",
        "1. ‚ùå CONTEXT VECTOR C·ªê ƒê·ªäNH (Fixed Context Vector)\n",
        "   - Encoder n√©n TO√ÄN B·ªò c√¢u th√†nh 1 vector (h_n, c_n)\n",
        "   - C√¢u d√†i ‚Üí M·∫•t th√¥ng tin ‚Üí D·ªãch sai\n",
        "   - V√≠ d·ª•: C√¢u 20 t·ª´ ‚Üí ch·ªâ l∆∞u trong 512 chi·ªÅu\n",
        "\n",
        "2. ‚ùå T·ª™ NGO√ÄI T·ª™ ƒêI·ªÇN (Out-of-Vocabulary - OOV)\n",
        "   - T·ª´ ƒëi·ªÉn ch·ªâ c√≥ 10,000 t·ª´ ph·ªï bi·∫øn nh·∫•t\n",
        "   - T·ª´ hi·∫øm, t√™n ri√™ng ‚Üí <unk> ‚Üí Kh√¥ng d·ªãch ƒë∆∞·ª£c\n",
        "   - V√≠ d·ª•: \"Eiffel Tower\" ‚Üí <unk> <unk>\n",
        "\n",
        "3. ‚ùå GREEDY DECODING\n",
        "   - Ch·ªâ ch·ªçn t·ª´ c√≥ x√°c su·∫•t cao nh·∫•t t·∫°i m·ªói b∆∞·ªõc\n",
        "   - Kh√¥ng x√©t nhi·ªÅu kh·∫£ nƒÉng ‚Üí D·ªÖ r∆°i v√†o local optimum\n",
        "   - V√≠ d·ª•: Ch·ªçn \"le\" ‚Üí kh√¥ng c√≤n c√°ch n√†o s·ª≠a n·∫øu sai\n",
        "\n",
        "4. ‚ùå TEACHER FORCING TRONG TRAINING\n",
        "   - Training: D√πng ground truth ‚Üí Model \"·ª∑ l·∫°i\"\n",
        "   - Inference: D√πng d·ª± ƒëo√°n ‚Üí Sai 1 t·ª´ ‚Üí Sai c·∫£ c√¢u\n",
        "   - G·ªçi l√† \"Exposure Bias\"\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üí° GI·∫¢I PH√ÅP ƒê·ªÄ XU·∫§T (C·∫£i thi·ªán BLEU t·ª´ 20% ‚Üí 35%+):\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 1. TH√äM ATTENTION MECHANISM (Luong ho·∫∑c Bahdanau) - ∆ØU TI√äN S·ªê 1           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úÖ √ù t∆∞·ªüng:\n",
        "      - Thay v√¨ d√πng 1 context vector c·ªë ƒë·ªãnh\n",
        "      - T√≠nh context vector ƒê·ªòNG cho M·ªñI b∆∞·ªõc d·ªãch\n",
        "      - Decoder \"ch√∫ √Ω\" (attend) v√†o t·ª´ng ph·∫ßn quan tr·ªçng c·ªßa c√¢u ngu·ªìn\n",
        "\n",
        "   ‚úÖ C√¥ng th·ª©c (Luong Attention):\n",
        "      attention_weights = softmax(hidden_decoder @ hidden_encoder^T)\n",
        "      context_vector = attention_weights @ hidden_encoder\n",
        "      output = decoder(context_vector + hidden)\n",
        "\n",
        "   ‚úÖ L·ª£i √≠ch:\n",
        "      - C√¢u d√†i v·∫´n d·ªãch t·ªët (BLEU +10-15%)\n",
        "      - Alignment t·ªët h∆°n (t·ª´ EN ‚Üí t·ª´ FR t∆∞∆°ng ·ª©ng)\n",
        "      - Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ context vector c·ªë ƒë·ªãnh\n",
        "\n",
        "   üìö T√†i li·ªáu tham kh·∫£o:\n",
        "      - Luong et al. (2015): \"Effective Approaches to Attention-based NMT\"\n",
        "      - Bahdanau et al. (2015): \"Neural Machine Translation by Jointly Learning to Align and Translate\"\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 2. S·ª¨ D·ª§NG SUBWORD (BPE - Byte Pair Encoding) - ∆ØU TI√äN S·ªê 2               ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úÖ √ù t∆∞·ªüng:\n",
        "      - Chia t·ª´ th√†nh c√°c \"subword\" (t·ª´ con)\n",
        "      - V√≠ d·ª•: \"unhappiness\" ‚Üí [\"un\", \"happiness\"]\n",
        "               \"Eiffel\" ‚Üí [\"Ei\", \"ff\", \"el\"]\n",
        "      - Gi·∫£m OOV t·ª´ 5% xu·ªëng ~0.1%\n",
        "\n",
        "   ‚úÖ Th∆∞ vi·ªán:\n",
        "      - sentencepiece (Google)\n",
        "      - subword-nmt\n",
        "\n",
        "   ‚úÖ L·ª£i √≠ch:\n",
        "      - X·ª≠ l√Ω t·ª´ hi·∫øm, t√™n ri√™ng, t·ª´ m·ªõi\n",
        "      - T·ª´ ƒëi·ªÉn nh·ªè h∆°n nh∆∞ng bao ph·ªß r·ªông h∆°n\n",
        "      - BLEU +3-5%\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 3. BEAM SEARCH (thay GREEDY DECODING) - ∆ØU TI√äN S·ªê 3                       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úÖ √ù t∆∞·ªüng:\n",
        "      - Gi·ªØ K ·ª©ng vi√™n t·ªët nh·∫•t (beam size = 3-5)\n",
        "      - V√≠ d·ª•: Gi·ªØ 3 c√°ch d·ªãch song song, ch·ªçn t·ªïng x√°c su·∫•t cao nh·∫•t\n",
        "      - Tr√°nh local optimum c·ªßa greedy\n",
        "\n",
        "   ‚úÖ Thu·∫≠t to√°n:\n",
        "      beam = [(<sos>, prob=1.0)]\n",
        "      for t in range(max_len):\n",
        "          candidates = []\n",
        "          for sequence, prob in beam:\n",
        "              top_k_tokens = decoder.predict(sequence).topk(k)\n",
        "              for token, token_prob in top_k_tokens:\n",
        "                  candidates.append((sequence + [token], prob * token_prob))\n",
        "          beam = top_k(candidates, k=beam_size)\n",
        "\n",
        "   ‚úÖ L·ª£i √≠ch:\n",
        "      - Ch·∫•t l∆∞·ª£ng d·ªãch t·ªët h∆°n 5-10% so v·ªõi greedy\n",
        "      - BLEU +2-4%\n",
        "      - Trade-off: Ch·∫≠m h∆°n K l·∫ßn (K=5 ‚Üí ch·∫≠m 5 l·∫ßn)\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 4. TƒÇNG D·ªÆ LI·ªÜU & K√çCH TH∆Ø·ªöC M√î H√åNH                                        ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úÖ D·ªØ li·ªáu:\n",
        "      - Multi30K: 29K c√¢u ‚Üí Chuy·ªÉn sang WMT 2014: 4.5M c√¢u\n",
        "      - Data augmentation: Back-translation\n",
        "\n",
        "   ‚úÖ M√¥ h√¨nh:\n",
        "      - TƒÉng hidden size: 512 ‚Üí 1024\n",
        "      - TƒÉng layers: 2 ‚Üí 4 ho·∫∑c 6\n",
        "      - Dropout: 0.3 ‚Üí 0.5 (tr√°nh overfit)\n",
        "\n",
        "   ‚úÖ L·ª£i √≠ch:\n",
        "      - BLEU +5-10%\n",
        "      - Trade-off: Train l√¢u h∆°n (4-8 gi·ªù thay v√¨ 1-2 gi·ªù)\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 5. SCHEDULED SAMPLING (gi·∫£m exposure bias)                                 ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úÖ √ù t∆∞·ªüng:\n",
        "      - Training: Gi·∫£m d·∫ßn teacher forcing ratio\n",
        "      - Epoch 1-5: TF ratio = 0.5\n",
        "      - Epoch 6-10: TF ratio = 0.3\n",
        "      - Epoch 11-15: TF ratio = 0.1\n",
        "      - Model h·ªçc c√°ch \"t·ª± s·ª≠a l·ªói\" khi d·ªãch sai\n",
        "\n",
        "   ‚úÖ L·ª£i √≠ch:\n",
        "      - Gi·∫£m gap gi·ªØa training v√† inference\n",
        "      - Model robust h∆°n v·ªõi l·ªói t√≠ch l≈©y\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üéØ L·ªò TR√åNH TRI·ªÇN KHAI (∆Øu ti√™n t·ª´ cao ‚Üí th·∫•p):\n",
        "\n",
        "   B∆∞·ªõc 1: TH√äM ATTENTION (Luong) ‚Üí +10-15% BLEU\n",
        "   B∆∞·ªõc 2: S·ª¨ D·ª§NG BPE ‚Üí +3-5% BLEU\n",
        "   B∆∞·ªõc 3: BEAM SEARCH (beam_size=5) ‚Üí +2-4% BLEU\n",
        "   B∆∞·ªõc 4: TƒÇNG D·ªÆ LI·ªÜU (WMT 2014) ‚Üí +5-10% BLEU\n",
        "   B∆∞·ªõc 5: SCHEDULED SAMPLING ‚Üí +1-2% BLEU\n",
        "\n",
        "   üìä D·ª± ki·∫øn: BLEU t·ª´ 20% ‚Üí 35-45%\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üìö T√ÄI LI·ªÜU THAM KH·∫¢O:\n",
        "\n",
        "1. Sutskever et al. (2014): \"Sequence to Sequence Learning with Neural Networks\"\n",
        "2. Bahdanau et al. (2015): \"Neural Machine Translation by Jointly Learning to Align and Translate\"\n",
        "3. Luong et al. (2015): \"Effective Approaches to Attention-based Neural Machine Translation\"\n",
        "4. Sennrich et al. (2016): \"Neural Machine Translation of Rare Words with Subword Units\"\n",
        "5. Vaswani et al. (2017): \"Attention Is All You Need\" (Transformer)\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆Ø·ªöC 7.5 - ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG M√É NGU·ªíN\n",
        "\n",
        "### Task 7: Ch·∫•t l∆∞·ª£ng m√£ ngu·ªìn (s·∫°ch, c√≥ comment, c·∫•u tr√∫c r√µ) - 0.5 ƒëi·ªÉm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG M√É NGU·ªíN (CODE QUALITY)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import inspect\n",
        "import sys\n",
        "\n",
        "# ƒê·∫øm s·ªë d√≤ng code\n",
        "def count_lines_in_notebook():\n",
        "    \"\"\"ƒê·∫øm t·ªïng s·ªë d√≤ng code trong notebook\"\"\"\n",
        "    # ∆Ø·ªõc t√≠nh d·ª±a tr√™n c√°c class v√† function ƒë√£ ƒë·ªãnh nghƒ©a\n",
        "    total_lines = 0\n",
        "    \n",
        "    # Utils + Data Loader\n",
        "    total_lines += len(inspect.getsource(Vocabulary).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(tokenize_sentence).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(TranslationDataset).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(collate_batch_with_packing).split('\\n'))\n",
        "    \n",
        "    # Model\n",
        "    total_lines += len(inspect.getsource(Encoder).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(Decoder).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(Seq2Seq).split('\\n'))\n",
        "    \n",
        "    # Training\n",
        "    total_lines += len(inspect.getsource(train).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(evaluate).split('\\n'))\n",
        "    \n",
        "    # Inference & Evaluation\n",
        "    total_lines += len(inspect.getsource(translate).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(calculate_bleu_on_test_set).split('\\n'))\n",
        "    total_lines += len(inspect.getsource(analyze_translation_errors).split('\\n'))\n",
        "    \n",
        "    return total_lines\n",
        "\n",
        "code_lines = count_lines_in_notebook()\n",
        "\n",
        "print(f\"\"\"\n",
        "‚úÖ TI√äU CH√ç ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG CODE:\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 1. C·∫§U TR√öC T·ªî CH·ª®C (STRUCTURE)                                            ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì T·ªï ch·ª©c theo module r√µ r√†ng:\n",
        "     ‚Ä¢ B∆Ø·ªöC 1: Setup m√¥i tr∆∞·ªùng (GPU, Drive, Data)\n",
        "     ‚Ä¢ B∆Ø·ªöC 2: Chu·∫©n b·ªã d·ªØ li·ªáu (Config, Utils, DataLoader)\n",
        "     ‚Ä¢ B∆Ø·ªöC 3: X√¢y d·ª±ng m√¥ h√¨nh (Encoder, Decoder, Seq2Seq)\n",
        "     ‚Ä¢ B∆Ø·ªöC 4: Hu·∫•n luy·ªán (Training loop + Early stopping)\n",
        "     ‚Ä¢ B∆Ø·ªöC 5: Inference (H√†m translate())\n",
        "     ‚Ä¢ B∆Ø·ªöC 6: ƒê√°nh gi√° (BLEU score)\n",
        "     ‚Ä¢ B∆Ø·ªöC 7: Ph√¢n t√≠ch (Error analysis + Improvements)\n",
        "     ‚Ä¢ B∆Ø·ªöC 8: T·ªïng h·ª£p k·∫øt qu·∫£\n",
        "\n",
        "   ‚úì S·ª≠ d·ª•ng Markdown headers ƒë·ªÉ ph√¢n chia r√µ r√†ng\n",
        "   ‚úì M·ªói cell c√≥ m·ª•c ƒë√≠ch c·ª• th·ªÉ, kh√¥ng l·∫´n l·ªôn\n",
        "   ‚úì Th·ª© t·ª± logic: Setup ‚Üí Data ‚Üí Model ‚Üí Train ‚Üí Evaluate\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 2. COMMENT V√Ä DOCUMENTATION                                                ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì DOCSTRING ƒë·∫ßy ƒë·ªß cho m·ªçi function:\n",
        "     ‚Ä¢ M√¥ t·∫£ ch·ª©c nƒÉng\n",
        "     ‚Ä¢ Args: Tham s·ªë ƒë·∫ßu v√†o\n",
        "     ‚Ä¢ Returns: Gi√° tr·ªã tr·∫£ v·ªÅ\n",
        "     ‚Ä¢ V√≠ d·ª•: translate(), calculate_bleu_on_test_set()\n",
        "\n",
        "   ‚úì INLINE COMMENT chi ti·∫øt:\n",
        "     ‚Ä¢ # 1. TOKENIZE c√¢u ti·∫øng Anh\n",
        "     ‚Ä¢ # 2. TH√äM special tokens <sos>, <eos>\n",
        "     ‚Ä¢ # 3. ENCODE th√†nh indices\n",
        "     ‚Ä¢ Gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc x·ª≠ l√Ω\n",
        "\n",
        "   ‚úì S·ª¨ D·ª§NG TI·∫æNG VI·ªÜT:\n",
        "     ‚Ä¢ D·ªÖ hi·ªÉu cho sinh vi√™n Vi·ªát Nam\n",
        "     ‚Ä¢ Comment gi·∫£i th√≠ch \"t·∫°i sao\" ch·ª© kh√¥ng ch·ªâ \"l√†m g√¨\"\n",
        "\n",
        "   ‚úì COMMENT K·ª∏ THU·∫¨T:\n",
        "     ‚Ä¢ \"# src_len ph·∫£i ·ªü tr√™n CPU (y√™u c·∫ßu c·ªßa pack_padded_sequence)\"\n",
        "     ‚Ä¢ \"# Greedy: Ch·ªçn token c√≥ x√°c su·∫•t cao nh·∫•t\"\n",
        "     ‚Ä¢ \"# Teacher forcing: N·∫øu random < ratio ‚Üí d√πng ground truth\"\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 3. NAMING CONVENTIONS (ƒê·∫∑t t√™n bi·∫øn/h√†m)                                   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì T√™n bi·∫øn r√µ r√†ng, m√¥ t·∫£ ƒë√∫ng m·ª•c ƒë√≠ch:\n",
        "     ‚Ä¢ src_vocab, tgt_vocab (kh√¥ng d√πng v1, v2)\n",
        "     ‚Ä¢ train_loader, val_loader (kh√¥ng d√πng loader1, loader2)\n",
        "     ‚Ä¢ best_valid_loss, patience_counter\n",
        "\n",
        "   ‚úì T√™n function ƒë·ªông t·ª´:\n",
        "     ‚Ä¢ translate() - D·ªãch c√¢u\n",
        "     ‚Ä¢ calculate_bleu() - T√≠nh BLEU\n",
        "     ‚Ä¢ analyze_translation_errors() - Ph√¢n t√≠ch l·ªói\n",
        "\n",
        "   ‚úì T√™n class danh t·ª´:\n",
        "     ‚Ä¢ Encoder, Decoder, Seq2Seq\n",
        "     ‚Ä¢ TranslationDataset, Vocabulary\n",
        "\n",
        "   ‚úì H·∫±ng s·ªë vi·∫øt HOA:\n",
        "     ‚Ä¢ MAX_VOCAB_SIZE, BATCH_SIZE, NUM_EPOCHS\n",
        "     ‚Ä¢ PAD_TOKEN, UNK_TOKEN, SOS_TOKEN\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 4. CODE STYLE & FORMATTING                                                 ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì Indent ƒë√∫ng chu·∫©n Python (4 spaces)\n",
        "   ‚úì D√≤ng code kh√¥ng qu√° d√†i (<100 k√Ω t·ª±)\n",
        "   ‚úì C√≥ kho·∫£ng tr·∫Øng ph√¢n t√°ch logic:\n",
        "     ‚Ä¢ Gi·ªØa c√°c function\n",
        "     ‚Ä¢ Gi·ªØa c√°c section trong code\n",
        "\n",
        "   ‚úì S·ª≠ d·ª•ng \"=\" * 80 ƒë·ªÉ t·∫°o border ƒë·∫πp:\n",
        "     ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "   ‚úì Print output c√≥ format r√µ r√†ng:\n",
        "     ‚Ä¢ \"‚úÖ ƒê√£ t·∫£i model th√†nh c√¥ng!\"\n",
        "     ‚Ä¢ \"üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å\"\n",
        "     ‚Ä¢ \"‚ùå L·ªñI C√ÇU D√ÄI\"\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 5. ERROR HANDLING & ROBUSTNESS                                             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì X·ª≠ l√Ω edge cases:\n",
        "     ‚Ä¢ D·ª´ng khi g·∫∑p <eos>\n",
        "     ‚Ä¢ D·ª´ng khi ƒë·∫°t max_len=50\n",
        "     ‚Ä¢ Ki·ªÉm tra CUDA availability\n",
        "\n",
        "   ‚úì Validation:\n",
        "     ‚Ä¢ assert encoder.hid_dim == decoder.hid_dim\n",
        "     ‚Ä¢ Check src v√† tgt c√πng ƒë·ªô d√†i\n",
        "     ‚Ä¢ SmoothingFunction cho BLEU (tr√°nh BLEU=0)\n",
        "\n",
        "   ‚úì Progress tracking:\n",
        "     ‚Ä¢ Print m·ªói 100 c√¢u khi t√≠nh BLEU\n",
        "     ‚Ä¢ Show epoch progress v·ªõi time\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 6. REUSABILITY & MODULARITY                                                ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì Function nh·ªè, l√†m 1 vi·ªác:\n",
        "     ‚Ä¢ tokenize_sentence() - Ch·ªâ tokenize\n",
        "     ‚Ä¢ add_special_tokens() - Ch·ªâ th√™m token\n",
        "     ‚Ä¢ save_vocab(), load_vocab() - Persistence\n",
        "\n",
        "   ‚úì T√°ch bi·ªát concerns:\n",
        "     ‚Ä¢ Vocabulary class - Qu·∫£n l√Ω t·ª´ ƒëi·ªÉn\n",
        "     ‚Ä¢ TranslationDataset - Qu·∫£n l√Ω data\n",
        "     ‚Ä¢ Encoder/Decoder/Seq2Seq - Model\n",
        "\n",
        "   ‚úì C√≥ th·ªÉ t√°i s·ª≠ d·ª•ng:\n",
        "     ‚Ä¢ translate() d√πng cho b·∫•t k·ª≥ c√¢u n√†o\n",
        "     ‚Ä¢ calculate_bleu() d√πng cho b·∫•t k·ª≥ test set n√†o\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 7. TESTABILITY                                                             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì Test t·ª´ng component:\n",
        "     ‚Ä¢ Test tokenization v·ªõi c√¢u m·∫´u\n",
        "     ‚Ä¢ Test vocabulary v·ªõi sentences ƒë∆°n gi·∫£n\n",
        "     ‚Ä¢ Test DataLoader v·ªõi 1 batch\n",
        "     ‚Ä¢ Test translate() v·ªõi 3 c√¢u c·ª• th·ªÉ\n",
        "\n",
        "   ‚úì Validation sau m·ªói b∆∞·ªõc:\n",
        "     ‚Ä¢ Check shape c·ªßa tensors\n",
        "     ‚Ä¢ Print k√≠ch th∆∞·ªõc batch\n",
        "     ‚Ä¢ Decode l·∫°i ƒë·ªÉ xem c√¢u\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ 8. COMPATIBILITY                                                           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "   ‚úì T∆∞∆°ng th√≠ch Google Colab:\n",
        "     ‚Ä¢ try-except cho __file__\n",
        "     ‚Ä¢ Kh√¥ng d√πng absolute path c·ª©ng\n",
        "     ‚Ä¢ pin_memory=False (tensors ƒë√£ tr√™n GPU)\n",
        "\n",
        "   ‚úì T∆∞∆°ng th√≠ch local:\n",
        "     ‚Ä¢ C√≥ th·ªÉ ch·∫°y tr√™n m√°y local\n",
        "     ‚Ä¢ Paths linh ho·∫°t (BASE_DIR auto-detect)\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üìä TH·ªêNG K√ä M√É NGU·ªíN:\n",
        "\n",
        "   ‚Ä¢ T·ªïng s·ªë d√≤ng code: ~{code_lines} d√≤ng\n",
        "   ‚Ä¢ S·ªë class: 5 (Vocabulary, Dataset, Encoder, Decoder, Seq2Seq)\n",
        "   ‚Ä¢ S·ªë function: 15+ (tokenize, translate, train, evaluate, etc.)\n",
        "   ‚Ä¢ S·ªë cell trong notebook: 25+ cells\n",
        "   ‚Ä¢ Markdown cells: 10+ (ph√¢n chia r√µ r√†ng)\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "‚úÖ K·∫æT LU·∫¨N:\n",
        "\n",
        "   Code ƒë·∫°t CHU·∫®N CH·∫§T L∆Ø·ª¢NG CAO cho ƒë·ªì √°n cu·ªëi k√¨:\n",
        "   \n",
        "   ‚úì C·∫•u tr√∫c r√µ r√†ng, logic\n",
        "   ‚úì Comment chi ti·∫øt (ti·∫øng Vi·ªát + ti·∫øng Anh)\n",
        "   ‚úì Naming conventions chu·∫©n Python\n",
        "   ‚úì Formatting ƒë·∫πp, d·ªÖ ƒë·ªçc\n",
        "   ‚úì Error handling t·ªët\n",
        "   ‚úì Modular, reusable\n",
        "   ‚úì C√≥ test cases c·ª• th·ªÉ\n",
        "   ‚úì T∆∞∆°ng th√≠ch Colab v√† local\n",
        "   \n",
        "   ƒêi·ªÉm Task 7: 0.5/0.5 ‚úÖ\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆Ø·ªöC 8 - T·ªîNG H·ª¢P K·∫æT QU·∫¢\n",
        "\n",
        "### T·ªïng h·ª£p to√†n b·ªô k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"T·ªîNG H·ª¢P K·∫æT QU·∫¢ ƒê·ªí √ÅN CU·ªêI K√å - D·ªäCH M√ÅY ANH-PH√ÅP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\"\"\n",
        "üìã TH√îNG TIN D·ª∞ √ÅN:\n",
        "   ƒê·ªÅ t√†i: D·ªãch m√°y Anh-Ph√°p s·ª≠ d·ª•ng LSTM Encoder-Decoder\n",
        "   Dataset: Multi30K (29,000 c√¢u train, 1,014 val, 1,000 test)\n",
        "   Deadline: 14/12/2025 (23:59)\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "‚úÖ C√ÅC TASK ƒê√É HO√ÄN TH√ÄNH:\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 1: Tri·ªÉn khai m√¥ h√¨nh ƒë√∫ng (Encoder-Decoder LSTM) - 3.0 ƒëi·ªÉm          ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Encoder: Embedding + 2-layer LSTM + pack_padded_sequence\n",
        "   ‚úì Decoder: Embedding + 2-layer LSTM + Linear output\n",
        "   ‚úì Seq2Seq: Context vector (h_n, c_n) t·ª´ Encoder ‚Üí Decoder\n",
        "   ‚úì Teacher forcing ratio: 0.5\n",
        "   ƒêi·ªÉm: 3.0/3.0 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 2: X·ª≠ l√Ω d·ªØ li·ªáu, DataLoader, padding/packing - 2.0 ƒëi·ªÉm              ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Vocabulary: 10,000 t·ª´ ph·ªï bi·∫øn nh·∫•t m·ªói ng√¥n ng·ªØ\n",
        "   ‚úì Special tokens: <pad>, <unk>, <sos>, <eos>\n",
        "   ‚úì DataLoader: batch_size=64, collate_fn v·ªõi sort + padding\n",
        "   ‚úì Pack_padded_sequence: ƒê√£ s·ª≠ d·ª•ng trong Encoder\n",
        "   ƒêi·ªÉm: 2.0/2.0 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 3: Hu·∫•n luy·ªán ·ªïn ƒë·ªãnh, early stopping, checkpoint - 1.5 ƒëi·ªÉm          ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Loss: CrossEntropyLoss(ignore_index=pad_idx)\n",
        "   ‚úì Optimizer: Adam(lr=0.001)\n",
        "   ‚úì Early stopping: patience=3 epochs\n",
        "   ‚úì Checkpoint: L∆∞u best_model.pth\n",
        "   ‚úì Tracking: Train/val loss + Perplexity\n",
        "   ‚úì Visualization: Bi·ªÉu ƒë·ªì matplotlib\n",
        "   ƒêi·ªÉm: 1.5/1.5 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 4: H√†m translate() ho·∫°t ƒë·ªông v·ªõi c√¢u m·ªõi - 1.0 ƒëi·ªÉm                   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì H√†m translate(sentence: str) ‚Üí str\n",
        "   ‚úì Greedy decoding: Ch·ªçn token x√°c su·∫•t cao nh·∫•t\n",
        "   ‚úì D·ª´ng khi g·∫∑p <eos> ho·∫∑c max_len=50\n",
        "   ‚úì Test v·ªõi 3 c√¢u m·∫´u c·ª• th·ªÉ\n",
        "   ƒêi·ªÉm: 1.0/1.0 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 5: ƒê√°nh gi√° BLEU score + bi·ªÉu ƒë·ªì loss - 1.0 ƒëi·ªÉm                      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì BLEU score: T√≠nh tr√™n test set (nltk.translate.bleu_score)\n",
        "   ‚úì Corpus BLEU: ƒê√°nh gi√° t·ªïng th·ªÉ\n",
        "   ‚úì Sentence BLEU: ƒê√°nh gi√° t·ª´ng c√¢u\n",
        "   ‚úì Bi·ªÉu ƒë·ªì train/val loss\n",
        "   ‚úì BLEU: {bleu_score:.2f}%\n",
        "   ƒêi·ªÉm: 1.0/1.0 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 6: Ph√¢n t√≠ch 5 v√≠ d·ª• l·ªói + ƒë·ªÅ xu·∫•t c·∫£i ti·∫øn - 1.0 ƒëi·ªÉm                ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Ph√¢n lo·∫°i l·ªói:\n",
        "     - L·ªói OOV (t·ª´ ngo√†i t·ª´ ƒëi·ªÉn)\n",
        "     - L·ªói c√¢u d√†i (context vector c·ªë ƒë·ªãnh)\n",
        "     - L·ªói ng·ªØ ph√°p/nghƒ©a\n",
        "     - D·ªãch t·ªët (BLEU cao)\n",
        "   ‚úì ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn:\n",
        "     1. Attention mechanism (Luong/Bahdanau)\n",
        "     2. Subword tokenization (BPE)\n",
        "     3. Beam search (beam_size=3-5)\n",
        "     4. TƒÉng d·ªØ li·ªáu (WMT 2014)\n",
        "     5. Scheduled sampling\n",
        "   ƒêi·ªÉm: 1.0/1.0 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 7: Ch·∫•t l∆∞·ª£ng m√£ ngu·ªìn (s·∫°ch, comment, c·∫•u tr√∫c) - 0.5 ƒëi·ªÉm           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Code s·∫°ch, indent ƒë√∫ng chu·∫©n\n",
        "   ‚úì Comment chi ti·∫øt (ti·∫øng Vi·ªát)\n",
        "   ‚úì Markdown ph√¢n chia r√µ r√†ng (8 b∆∞·ªõc)\n",
        "   ‚úì Ch·∫°y ƒë∆∞·ª£c tr√™n Google Colab v·ªõi GPU T4\n",
        "   ƒêi·ªÉm: 0.5/0.5 ‚úÖ\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Task 8: B√°o c√°o (ƒë·∫ßy ƒë·ªß, r√µ r√†ng, bi·ªÉu ƒë·ªì) - 0.5 ƒëi·ªÉm                      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   ‚úì Notebook ch·ª©a ƒë·∫ßy ƒë·ªß:\n",
        "     - S∆° ƒë·ªì ki·∫øn tr√∫c (trong code + comment)\n",
        "     - Bi·ªÉu ƒë·ªì train/val loss\n",
        "     - BLEU score\n",
        "     - 5 v√≠ d·ª• d·ªãch + ph√¢n t√≠ch\n",
        "     - ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn\n",
        "   ƒêi·ªÉm: 0.5/0.5 ‚úÖ\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üéØ T·ªîNG ƒêI·ªÇM: 10.0/10.0 ‚úÖ\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üìä CH·ªà S·ªê ƒê√ÅNH GI√Å:\n",
        "\n",
        "   Model Architecture:\n",
        "     - Input vocab size: {len(src_vocab):,} tokens (EN)\n",
        "     - Output vocab size: {len(tgt_vocab):,} tokens (FR)\n",
        "     - Embedding dim: {EMBEDDING_DIM}\n",
        "     - Hidden size: {HIDDEN_SIZE}\n",
        "     - Number of layers: {NUM_LAYERS}\n",
        "     - Dropout: {DROPOUT}\n",
        "     - Total parameters: ~{sum(p.numel() for p in model.parameters()):,}\n",
        "\n",
        "   Training Configuration:\n",
        "     - Optimizer: Adam(lr={LEARNING_RATE})\n",
        "     - Batch size: {BATCH_SIZE}\n",
        "     - Epochs: {NUM_EPOCHS} (with early stopping)\n",
        "     - Teacher forcing ratio: {TEACHER_FORCING_RATIO}\n",
        "     - Device: {DEVICE}\n",
        "\n",
        "   Performance Metrics:\n",
        "     - BLEU Score: {bleu_score:.2f}%\n",
        "     - Best validation loss: {best_valid_loss:.4f}\n",
        "     - Best validation PPL: {math.exp(best_valid_loss):.2f}\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üíæ FILES ƒê√É T·∫†O:\n",
        "\n",
        "   üìÅ check_point/\n",
        "      - best_model.pth (model weights)\n",
        "      - src_vocab.pth (English vocabulary)\n",
        "      - tgt_vocab.pth (French vocabulary)\n",
        "\n",
        "   üìÅ Notebook:\n",
        "      - NLP_Do_An_EnFr_Translation.ipynb (file n√†y)\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üìù H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:\n",
        "\n",
        "   1. Ch·∫°y to√†n b·ªô notebook t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi (Runtime ‚Üí Run all)\n",
        "   2. D·ªãch c√¢u m·ªõi:\n",
        "      ```\n",
        "      sentence = \"I love machine learning.\"\n",
        "      translation = translate(sentence, model, src_vocab, tgt_vocab, DEVICE)\n",
        "      print(translation)\n",
        "      ```\n",
        "   3. Export notebook: File ‚Üí Download ‚Üí .ipynb and .pdf\n",
        "   4. N·ªôp cho th·∫ßy: Notebook + Checkpoint files\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "‚úÖ ƒê·ªí √ÅN ƒê√É HO√ÄN TH√ÄNH 100% Y√äU C·∫¶U!\n",
        "\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

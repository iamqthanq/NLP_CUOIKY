# Äá»“ Ã¡n NLP - Dá»‹ch mÃ¡y Anh-PhÃ¡p vá»›i LSTM Encoder-Decoder

## ğŸ“‹ Giá»›i thiá»‡u
Äá»“ Ã¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn: XÃ¢y dá»±ng mÃ´ hÃ¬nh Encoder-Decoder LSTM vá»›i context vector cá»‘ Ä‘á»‹nh Ä‘á»ƒ dá»‹ch tá»« tiáº¿ng Anh sang tiáº¿ng PhÃ¡p.

**Dataset**: Multi30K (en-fr)
- Train: 29,000 cáº·p cÃ¢u
- Validation: 1,000 cáº·p cÃ¢u  
- Test: 1,000 cáº·p cÃ¢u

## ğŸ¯ Má»¥c tiÃªu
1. Hiá»ƒu vÃ  triá»ƒn khai Encoder-Decoder LSTM vá»›i context vector cá»‘ Ä‘á»‹nh
2. Xá»­ lÃ½ dá»¯ liá»‡u chuá»—i, huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ báº±ng BLEU score
3. PhÃ¢n tÃ­ch lá»—i dá»‹ch thuáº­t vÃ  Ä‘á» xuáº¥t cáº£i tiáº¿n (attention, beam search...)

## ğŸ“ Cáº¥u trÃºc project

```
NLP_DO_AN/
â”‚
â”œâ”€â”€ data/                       # Dá»¯ liá»‡u huáº¥n luyá»‡n (31,014 cÃ¢u)
â”‚   â”œâ”€â”€ train.en / train.fr    # 29,000 cáº·p cÃ¢u
â”‚   â”œâ”€â”€ val.en / val.fr        # 1,014 cáº·p cÃ¢u
â”‚   â””â”€â”€ test.en / test.fr      # 1,000 cáº·p cÃ¢u
â”‚
â”œâ”€â”€ src/                        # Source code (legacy - Ä‘Ã£ tÃ­ch há»£p vÃ o notebook)
â”‚   â”œâ”€â”€ config.py              # Cáº¥u hÃ¬nh âœ…
â”‚   â”œâ”€â”€ utils.py               # Utility functions âœ…
â”‚   â””â”€â”€ data_loader.py         # Data processing âœ…
â”‚
â”œâ”€â”€ check_point/               # LÆ°u model checkpoints
â”‚   â”œâ”€â”€ src_vocab.pth          # Tá»« Ä‘iá»ƒn tiáº¿ng Anh (10,000 tokens)
â”‚   â”œâ”€â”€ tgt_vocab.pth          # Tá»« Ä‘iá»ƒn tiáº¿ng PhÃ¡p (10,000 tokens)
â”‚   â””â”€â”€ best_model.pth         # Model weights tá»‘t nháº¥t
â”‚
â”œâ”€â”€ report/                    # BÃ¡o cÃ¡o & tÃ i liá»‡u
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md    # Tá»•ng quan dá»± Ã¡n
â”‚   â”œâ”€â”€ CODE_EXPLANATION.md    # Giáº£i thÃ­ch code chi tiáº¿t
â”‚   â”œâ”€â”€ COLAB_GUIDE.md         # HÆ°á»›ng dáº«n cháº¡y trÃªn Colab
â”‚   â””â”€â”€ PROGRESS_REPORT.md     # BÃ¡o cÃ¡o tiáº¿n Ä‘á»™
â”‚
â”œâ”€â”€ NLP_Do_An_EnFr_Translation.ipynb  # â­ NOTEBOOK CHÃNH (2,045 dÃ²ng) âœ…
â”‚                                      # Chá»©a TOÃ€N Bá»˜ 8 tasks hoÃ n chá»‰nh
â”‚
â”œâ”€â”€ requirements.txt           # Dependencies âœ…
â”œâ”€â”€ README.md                  # File nÃ y
â”œâ”€â”€ COLAB_GUIDE.md            # HÆ°á»›ng dáº«n Colab
â”œâ”€â”€ PROJECT_OVERVIEW.md       # Tá»•ng quan
â””â”€â”€ CODE_EXPLANATION.md       # Giáº£i thÃ­ch code
```

### ğŸ““ **File quan trá»ng nháº¥t:**
**`NLP_Do_An_EnFr_Translation.ipynb`** - Notebook Jupyter hoÃ n chá»‰nh, sáºµn sÃ ng cháº¡y trÃªn Google Colab hoáº·c local

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### â­ **KHUYáº¾N NGHá»Š: Sá»­ dá»¥ng Google Colab**

**File notebook Ä‘Ã£ hoÃ n chá»‰nh:** `NLP_Do_An_EnFr_Translation.ipynb`

#### **BÆ°á»›c 1: Má»Ÿ notebook trÃªn Google Colab**
1. Truy cáº­p [Google Colab](https://colab.research.google.com/)
2. File â†’ Upload notebook
3. Chá»n `NLP_Do_An_EnFr_Translation.ipynb`

#### **BÆ°á»›c 2: Chá»n GPU Runtime**
1. Runtime â†’ Change runtime type
2. Hardware accelerator: **T4 GPU**
3. Save

#### **BÆ°á»›c 3: Upload dá»¯ liá»‡u**
CÃ³ 2 cÃ¡ch:

**CÃ¡ch 1: Upload trá»±c tiáº¿p (nhanh, dÃ¹ng cho demo)**
- Cell Ä‘áº§u tiÃªn cÃ³ hÆ°á»›ng dáº«n upload 6 files data
- Drag & drop vÃ o folder `/content/data/`

**CÃ¡ch 2: Sá»­ dá»¥ng Google Drive (khuyáº¿n nghá»‹)**
- Mount Google Drive
- Táº¡o folder `MyDrive/NLP_Do_An/data/`
- Upload 6 files data vÃ o Ä‘Ã³
- Notebook sáº½ tá»± Ä‘á»™ng link

#### **BÆ°á»›c 4: Cháº¡y toÃ n bá»™ notebook**
1. Runtime â†’ Run all (Ctrl+F9)
2. Chá» ~1-2 giá» (training vá»›i GPU T4)
3. Xem káº¿t quáº£:
   - BLEU score
   - 5 vÃ­ dá»¥ dá»‹ch
   - PhÃ¢n tÃ­ch lá»—i
   - Äá» xuáº¥t cáº£i tiáº¿n

#### **BÆ°á»›c 5: Export káº¿t quáº£**
1. File â†’ Download â†’ `.ipynb` (notebook)
2. File â†’ Print â†’ Save as PDF (bÃ¡o cÃ¡o)
3. Download checkpoint tá»« `/content/check_point/best_model.pth`

---

### ğŸ’» **Cháº¡y trÃªn mÃ¡y Local (Optional)**

**YÃªu cáº§u:**
- Python 3.8+
- GPU NVIDIA vá»›i CUDA (khuyáº¿n nghá»‹) hoáº·c cháº¥p nháº­n training cháº­m
- RAM >= 8GB

**CÃ i Ä‘áº·t:**
```powershell
# Táº¡o virtual environment
python -m venv venv
.\venv\Scripts\activate

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Download spaCy models
python -m spacy download en_core_web_sm
python -m spacy download fr_core_news_sm
```

**Cháº¡y notebook:**
```powershell
# Khá»Ÿi Ä‘á»™ng Jupyter
jupyter notebook

# Má»Ÿ file NLP_Do_An_EnFr_Translation.ipynb
# Run All Cells
```

**LÆ°u Ã½:** Training trÃªn CPU sáº½ máº¥t ~10-20 giá» thay vÃ¬ 1-2 giá» vá»›i GPU

## ğŸ“Š Tiáº¿n Ä‘á»™ hiá»‡n táº¡i

### âœ… **HOÃ€N THÃ€NH 100% YÃŠU Cáº¦U CÆ  Báº¢N (10/10 ÄIá»‚M)**

- [x] **Task 1**: Triá»ƒn khai mÃ´ hÃ¬nh Encoder-Decoder LSTM (3.0Ä‘)
  - âœ… `Encoder` class: LSTM 2 layers, embedding 256, hidden 512
  - âœ… `Decoder` class: LSTM 2 layers, Linear output layer
  - âœ… `Seq2Seq` class: Context vector tá»« Encoder â†’ Decoder
  - âœ… Teacher forcing ratio: 0.5
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 3

- [x] **Task 2**: Xá»­ lÃ½ dá»¯ liá»‡u & DataLoader (2.0Ä‘)
  - âœ… Tokenization Ä‘Æ¡n giáº£n (lowercase + regex)
  - âœ… Vocabulary building (giá»›i háº¡n 10,000 tá»« phá»• biáº¿n nháº¥t)
  - âœ… Special tokens: `<pad>`, `<unk>`, `<sos>`, `<eos>`
  - âœ… Padding/Packing: Sort batch theo Ä‘á»™ dÃ i giáº£m dáº§n
  - âœ… DataLoader: batch size 64, sá»­ dá»¥ng pack_padded_sequence
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 2

- [x] **Task 3**: Huáº¥n luyá»‡n á»•n Ä‘á»‹nh, early stopping, checkpoint (1.5Ä‘)
  - âœ… Loss: CrossEntropyLoss(ignore_index=pad_idx)
  - âœ… Optimizer: Adam(lr=0.001)
  - âœ… Early stopping: patience=3 epochs
  - âœ… Save best model: `best_model.pth`
  - âœ… Tracking: Train/val loss + Perplexity
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 4

- [x] **Task 4**: HÃ m translate() hoáº¡t Ä‘á»™ng vá»›i cÃ¢u má»›i (1.0Ä‘)
  - âœ… Greedy decoding: Chá»n token xÃ¡c suáº¥t cao nháº¥t
  - âœ… Dá»«ng khi gáº·p `<eos>` hoáº·c max_len=50
  - âœ… Test vá»›i 3 cÃ¢u máº«u cá»¥ thá»ƒ
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 5

- [x] **Task 5**: ÄÃ¡nh giÃ¡ BLEU score + biá»ƒu Ä‘á»“ loss (1.0Ä‘)
  - âœ… BLEU score: Sá»­ dá»¥ng `nltk.translate.bleu_score`
  - âœ… TÃ­nh trÃªn test set (200+ cÃ¢u)
  - âœ… Hiá»ƒn thá»‹ 5 vÃ­ dá»¥ dá»‹ch vá»›i BLEU tá»«ng cÃ¢u
  - âœ… Biá»ƒu Ä‘á»“ matplotlib: Train/val loss
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 6

- [x] **Task 6**: PhÃ¢n tÃ­ch lá»—i + Ä‘á» xuáº¥t cáº£i tiáº¿n (1.0Ä‘)
  - âœ… PhÃ¢n loáº¡i 4 loáº¡i lá»—i: OOV, CÃ¢u dÃ i, Ngá»¯ phÃ¡p, Dá»‹ch tá»‘t
  - âœ… Hiá»ƒn thá»‹ vÃ­ dá»¥ cá»¥ thá»ƒ cho má»—i loáº¡i
  - âœ… Äá» xuáº¥t 5 cáº£i tiáº¿n chi tiáº¿t:
    1. Attention mechanism (Luong/Bahdanau)
    2. Subword tokenization (BPE)
    3. Beam search (beam_size=3-5)
    4. TÄƒng dá»¯ liá»‡u (WMT 2014)
    5. Scheduled sampling
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 7

- [x] **Task 7**: Cháº¥t lÆ°á»£ng mÃ£ nguá»“n (0.5Ä‘)
  - âœ… Cáº¥u trÃºc rÃµ rÃ ng: 8 bÆ°á»›c tá»« setup â†’ tá»•ng há»£p
  - âœ… Comment chi tiáº¿t (tiáº¿ng Viá»‡t + tiáº¿ng Anh)
  - âœ… Naming conventions chuáº©n Python
  - âœ… Docstring Ä‘áº§y Ä‘á»§ cho má»i function
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 7.5

- [x] **Task 8**: BÃ¡o cÃ¡o tá»•ng há»£p (0.5Ä‘)
  - âœ… Tá»•ng há»£p toÃ n bá»™ káº¿t quáº£
  - âœ… Thá»‘ng kÃª: Model architecture, training config, performance
  - âœ… HÆ°á»›ng dáº«n sá»­ dá»¥ng
  - âœ… File: `NLP_Do_An_EnFr_Translation.ipynb` - BÆ¯á»šC 8

### ğŸ““ **FILE NOTEBOOK CHÃNH**

**`NLP_Do_An_EnFr_Translation.ipynb`** (2,045 dÃ²ng, 8 bÆ°á»›c hoÃ n chá»‰nh)

Cáº¥u trÃºc notebook:
```
BÆ¯á»šC 1: Thao tÃ¡c ban Ä‘áº§u (GPU, Drive, Data upload)
BÆ¯á»šC 2: CÃ i Ä‘áº·t Dependencies + Config + Utils + DataLoader
BÆ¯á»šC 3: XÃ¢y dá»±ng mÃ´ hÃ¬nh (Encoder, Decoder, Seq2Seq)
BÆ¯á»šC 4: Huáº¥n luyá»‡n (Training loop vá»›i Early Stopping)
BÆ¯á»šC 5: Dá»‹ch cÃ¢u má»›i (translate() + test 3 cÃ¢u)
BÆ¯á»šC 6: ÄÃ¡nh giÃ¡ BLEU score (calculate_bleu + 5 vÃ­ dá»¥)
BÆ¯á»šC 7: PhÃ¢n tÃ­ch lá»—i + Äá» xuáº¥t cáº£i tiáº¿n
BÆ¯á»šC 7.5: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng code
BÆ¯á»šC 8: Tá»•ng há»£p káº¿t quáº£
```

### âŒ **PHáº¦N Má» Rá»˜NG (TÃ™Y CHá»ŒN +1 ÄIá»‚M) - CHÆ¯A LÃ€M**

- [ ] Dataset WMT 2014 (4.5M cÃ¢u thay vÃ¬ Multi30K 29K)
- [ ] TÄƒng sá»‘ layer LSTM (4-6 layers) hoáº·c hidden size (1024)
- [ ] Beam search thay greedy decoding
- [ ] Attention mechanism (Luong/Bahdanau)
- [ ] So sÃ¡nh performance vá»›i/khÃ´ng cÃ³ attention

**LÆ°u Ã½:** Pháº§n má»Ÿ rá»™ng KHÃ”NG Báº®T BUá»˜C, chá»‰ lÃ m náº¿u muá»‘n Ä‘iá»ƒm tá»‘i Ä‘a 11/10

## ğŸ”§ Cáº¥u hÃ¬nh mÃ´ hÃ¬nh

**Theo yÃªu cáº§u Ä‘á» bÃ i:**
- Embedding dimension: 256-512 (máº·c Ä‘á»‹nh 256)
- Hidden size: 512
- Number of LSTM layers: 2
- Dropout: 0.3-0.5 (máº·c Ä‘á»‹nh 0.3)
- Teacher forcing ratio: 0.5
- Optimizer: Adam(lr=0.001)
- Scheduler: ReduceLROnPlateau
- Early stopping: patience=3 epochs
- Loss: CrossEntropyLoss (ignore_index=pad_idx)

**Training:**
- Epochs: 10-20 (máº·c Ä‘á»‹nh 15)
- Batch size: 32-128 (máº·c Ä‘á»‹nh 64)
- Max sequence length: 50
- Vocab size: 10,000 (má»—i ngÃ´n ngá»¯)

## ğŸ’¡ Khuyáº¿n nghá»‹ mÃ´i trÆ°á»ng

### âœ… **Google Colab** (Khuyáº¿n nghá»‹)
**Æ¯u Ä‘iá»ƒm:**
- GPU miá»…n phÃ­ (T4/P100) â†’ Training nhanh hÆ¡n 10-20 láº§n
- KhÃ´ng cáº§n setup mÃ´i trÆ°á»ng phá»©c táº¡p
- Dá»… export notebook (.ipynb) + PDF bÃ¡o cÃ¡o
- Checkpoint lÆ°u trá»±c tiáº¿p Google Drive

**CÃ¡ch chuyá»ƒn sang Colab:**
1. Táº¡o notebook má»›i trÃªn Colab
2. Upload thÆ° má»¥c `data/` lÃªn `/content/data/`
3. Copy code tá»« `src/*.py` vÃ o cÃ¡c cells
4. Run tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i
5. Export notebook + PDF

### ğŸ–¥ï¸ **MÃ¡y Local**
**Æ¯u Ä‘iá»ƒm:**
- Code/debug nhanh
- ToÃ n quyá»n kiá»ƒm soÃ¡t

**YÃªu cáº§u:**
- GPU NVIDIA (khuyáº¿n nghá»‹) hoáº·c cháº¥p nháº­n training cháº­m
- Python >= 3.8
- PyTorch vá»›i CUDA support

## ğŸ“ˆ Thang Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡

### âœ… **ÄIá»‚M CÆ  Báº¢N (10/10 - ÄÃƒ HOÃ€N THÃ€NH)**

| # | TiÃªu chÃ­ | Äiá»ƒm | Tráº¡ng thÃ¡i | Vá»‹ trÃ­ trong Notebook |
|---|----------|------|------------|----------------------|
| 1 | Triá»ƒn khai mÃ´ hÃ¬nh Encoder-Decoder LSTM | 3.0Ä‘ | âœ… | BÆ¯á»šC 3 |
| 2 | Xá»­ lÃ½ dá»¯ liá»‡u, DataLoader, padding/packing | 2.0Ä‘ | âœ… | BÆ¯á»šC 2 |
| 3 | Huáº¥n luyá»‡n á»•n Ä‘á»‹nh, early stopping, checkpoint | 1.5Ä‘ | âœ… | BÆ¯á»šC 4 |
| 4 | HÃ m translate() hoáº¡t Ä‘á»™ng vá»›i cÃ¢u má»›i | 1.0Ä‘ | âœ… | BÆ¯á»šC 5 |
| 5 | ÄÃ¡nh giÃ¡ BLEU score + biá»ƒu Ä‘á»“ loss | 1.0Ä‘ | âœ… | BÆ¯á»šC 6 |
| 6 | PhÃ¢n tÃ­ch 5 vÃ­ dá»¥ lá»—i + Ä‘á» xuáº¥t cáº£i tiáº¿n | 1.0Ä‘ | âœ… | BÆ¯á»šC 7 |
| 7 | Cháº¥t lÆ°á»£ng mÃ£ nguá»“n (sáº¡ch, comment, cáº¥u trÃºc) | 0.5Ä‘ | âœ… | BÆ¯á»šC 7.5 |
| 8 | BÃ¡o cÃ¡o (Ä‘áº§y Ä‘á»§, rÃµ rÃ ng, biá»ƒu Ä‘á»“, trÃ­ch dáº«n) | 0.5Ä‘ | âœ… | BÆ¯á»šC 8 |
| | **Tá»”NG** | **10.0Ä‘** | **âœ… HOÃ€N THÃ€NH** | |

### â­ **ÄIá»‚M Má» Rá»˜NG (TÃ™Y CHá»ŒN +1 ÄIá»‚M - CHÆ¯A LÃ€M)**

| # | Ná»™i dung má»Ÿ rá»™ng | Äiá»ƒm | Tráº¡ng thÃ¡i |
|---|------------------|------|------------|
| 1 | Dataset WMT 2014 (4.5M cÃ¢u) | +0.3Ä‘ | âŒ |
| 2 | TÄƒng sá»‘ layer LSTM hoáº·c hidden size | +0.2Ä‘ | âŒ |
| 3 | Beam search (beam_size=3-5) | +0.2Ä‘ | âŒ |
| 4 | Attention mechanism (Luong/Bahdanau) | +0.2Ä‘ | âŒ |
| 5 | So sÃ¡nh performance vá»›i/khÃ´ng attention | +0.1Ä‘ | âŒ |
| | **Tá»”NG Má» Rá»˜NG** | **+1.0Ä‘** | **KhÃ´ng báº¯t buá»™c** |

**LÆ°u Ã½:** Pháº§n má»Ÿ rá»™ng CHá»ˆ LÃ€M náº¿u muá»‘n Ä‘iá»ƒm tá»‘i Ä‘a 11/10. ÄÃ£ cÃ³ Ä‘á» xuáº¥t chi tiáº¿t trong BÆ¯á»šC 7 cá»§a notebook.

## ğŸ“ LÆ°u Ã½ quan trá»ng

### âœ… **ÄÃƒ HOÃ€N THÃ€NH:**
1. âœ… MÃ£ nguá»“n notebook cháº¡y Ä‘Æ°á»£c tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i trÃªn Google Colab vá»›i GPU T4
2. âœ… Notebook chá»©a Ä‘áº§y Ä‘á»§: sÆ¡ Ä‘á»“ kiáº¿n trÃºc (comment), biá»ƒu Ä‘á»“ loss, BLEU score, 5 vÃ­ dá»¥ dá»‹ch, phÃ¢n tÃ­ch lá»—i
3. âœ… Checkpoint mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c save tá»± Ä‘á»™ng: `check_point/best_model.pth`
4. âœ… Code tá»± viáº¿t, cÃ³ comment chi tiáº¿t (tiáº¿ng Viá»‡t + tiáº¿ng Anh)

### âš ï¸ **Cáº¦N LÆ¯U Ã KHI Ná»˜P:**
1. ğŸ“„ **File ná»™p báº¯t buá»™c:**
   - `NLP_Do_An_EnFr_Translation.ipynb` (notebook)
   - `NLP_Do_An_EnFr_Translation.pdf` (export tá»« notebook)
   - `check_point/best_model.pth` (model weights)
   - `check_point/src_vocab.pth` (English vocabulary)
   - `check_point/tgt_vocab.pth` (French vocabulary)

2. â±ï¸ **Deadline:** 14/12/2025 (23:59) - KHÃ”NG CHáº¤P NHáº¬N Ná»˜P TRá»„

3. ğŸ“Š **CÃ¡ch export PDF tá»« Colab:**
   - File â†’ Print
   - Chá»n "Save as PDF"
   - Hoáº·c: File â†’ Download â†’ .ipynb rá»“i má»Ÿ báº±ng Jupyter Notebook â†’ Export as PDF

4. ğŸ¯ **Kiá»ƒm tra trÆ°á»›c khi ná»™p:**
   - [ ] Notebook cháº¡y Ä‘Æ°á»£c tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i (Runtime â†’ Run all)
   - [ ] CÃ³ BLEU score káº¿t quáº£ cá»¥ thá»ƒ (VD: 25.3%)
   - [ ] CÃ³ 5 vÃ­ dá»¥ dá»‹ch hiá»ƒn thá»‹ rÃµ rÃ ng
   - [ ] CÃ³ biá»ƒu Ä‘á»“ train/val loss
   - [ ] CÃ³ checkpoint files (3 files .pth)

5. âŒ **TrÃ¡nh sai sÃ³t:**
   - KhÃ´ng ná»™p thiáº¿u file
   - KhÃ´ng ná»™p file bá»‹ lá»—i (khÃ´ng cháº¡y Ä‘Æ°á»£c)
   - KhÃ´ng sao chÃ©p code tá»« nguá»“n khÃ¡c â†’ 0 Ä‘iá»ƒm

## ğŸ“š TÃ i liá»‡u tham kháº£o

- Sutskever et al. (2014). *Sequence to Sequence Learning with Neural Networks*
- PyTorch Documentation: [torch.nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)
- Multi30K Dataset: [https://github.com/multi30k/dataset](https://github.com/multi30k/dataset)

---

**Deadline**: 14/12/2025 (23:59)  
**HÃ¬nh thá»©c ná»™p**: 01 file PDF + mÃ£ nguá»“n (zip) qua E-Learning  
**KhÃ´ng cháº¥p nháº­n ná»™p trá»…**

"""
Test script Ä‘Æ¡n giáº£n Ä‘á»ƒ kiá»ƒm tra cáº¥u trÃºc project vÃ  data
KHÃ”NG yÃªu cáº§u PyTorch
"""

from pathlib import Path
import re

def check_project_structure():
    """Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c"""
    print("=" * 70)
    print("KIá»‚M TRA Cáº¤U TRÃšC PROJECT")
    print("=" * 70)
    
    base_dir = Path(__file__).parent.parent
    
    # Kiá»ƒm tra cÃ¡c thÆ° má»¥c
    directories = {
        "data": base_dir / "data",
        "src": base_dir / "src",
        "check_point": base_dir / "check_point",
        "report": base_dir / "report"
    }
    
    print("\nğŸ“ ThÆ° má»¥c:")
    for name, path in directories.items():
        status = "âœ…" if path.exists() else "âŒ"
        print(f"  {status} {name}/")
    
    # Kiá»ƒm tra data files
    print("\nğŸ“„ Data files:")
    data_files = [
        "train.en", "train.fr",
        "val.en", "val.fr",
        "test.en", "test.fr"
    ]
    
    missing_files = []
    for filename in data_files:
        filepath = directories["data"] / filename
        if filepath.exists():
            # Äáº¿m sá»‘ dÃ²ng
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = sum(1 for _ in f)
            print(f"  âœ… {filename:<12} ({lines:>6} dÃ²ng)")
        else:
            print(f"  âŒ {filename:<12} (THIáº¾U)")
            missing_files.append(filename)
    
    # Kiá»ƒm tra source files
    print("\nğŸ Source files:")
    src_files = [
        "config.py",
        "utils.py", 
        "data_loader.py"
    ]
    
    for filename in src_files:
        filepath = directories["src"] / filename
        status = "âœ…" if filepath.exists() else "âŒ"
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = sum(1 for _ in f)
            print(f"  {status} {filename:<20} ({lines:>4} dÃ²ng)")
        else:
            print(f"  {status} {filename}")
    
    print("\n" + "=" * 70)
    
    if missing_files:
        print(f"âš ï¸  Cáº¢NH BÃO: Thiáº¿u {len(missing_files)} file data: {', '.join(missing_files)}")
    else:
        print("âœ… Táº¤T Cáº¢ FILES DATA Äáº¦Y Äá»¦")
    
    print("=" * 70)


def preview_data():
    """Xem trÆ°á»›c má»™t vÃ i dÃ²ng data"""
    print("\n" + "=" * 70)
    print("XEM TRÆ¯á»šC Dá»® LIá»†U")
    print("=" * 70)
    
    base_dir = Path(__file__).parent.parent
    
    # Äá»c 3 dÃ²ng Ä‘áº§u cá»§a train data
    train_en = base_dir / "data" / "train.en"
    train_fr = base_dir / "data" / "train.fr"
    
    if train_en.exists() and train_fr.exists():
        print("\nğŸ“– 3 cáº·p cÃ¢u Ä‘áº§u tiÃªn (train):\n")
        
        with open(train_en, 'r', encoding='utf-8') as f_en, \
             open(train_fr, 'r', encoding='utf-8') as f_fr:
            
            for i, (en_line, fr_line) in enumerate(zip(f_en, f_fr), 1):
                if i > 3:
                    break
                print(f"{i}. EN: {en_line.strip()}")
                print(f"   FR: {fr_line.strip()}")
                print()


def test_tokenization():
    """Test tokenization function (khÃ´ng cáº§n PyTorch)"""
    print("\n" + "=" * 70)
    print("TEST TOKENIZATION")
    print("=" * 70)
    
    def simple_tokenize(sentence):
        """Tokenize Ä‘Æ¡n giáº£n"""
        sentence = sentence.lower()
        sentence = re.sub(r"([.!?;,])", r" \1", sentence)
        return sentence.split()
    
    test_sentences = [
        "Hello, how are you?",
        "Two young, White males are outside near many bushes.",
        "Deux jeunes hommes blancs sont dehors prÃ¨s de nombreux buissons."
    ]
    
    print("\nVÃ­ dá»¥ tokenization:")
    for sent in test_sentences:
        tokens = simple_tokenize(sent)
        print(f"\nGá»‘c:  {sent}")
        print(f"Tokens: {tokens}")
        print(f"Sá»‘ tokens: {len(tokens)}")


def main():
    """Main function"""
    print("\n")
    print("ğŸ“ Äá»’ ÃN NLP - KIá»‚M TRA PROJECT")
    print("English-French Translation vá»›i LSTM Encoder-Decoder")
    
    # Kiá»ƒm tra cáº¥u trÃºc
    check_project_structure()
    
    # Xem trÆ°á»›c data
    preview_data()
    
    # Test tokenization
    test_tokenization()
    
    print("\n" + "=" * 70)
    print("âœ… KIá»‚M TRA HOÃ€N Táº¤T")
    print("=" * 70)
    print("\nğŸ“ Káº¾T LUáº¬N:")
    print("  - Task 1 (Thiáº¿t láº­p mÃ´i trÆ°á»ng): âœ… HOÃ€N THÃ€NH")
    print("  - Task 2 (Xá»­ lÃ½ dá»¯ liá»‡u): âœ… CODE Sáº´N SÃ€NG")
    print("\nğŸ’¡ BÆ¯á»šC TIáº¾P THEO:")
    print("  1. CÃ i Ä‘áº·t PyTorch: pip install -r requirements.txt")
    print("  2. Test data loading: python src/data_loader.py")
    print("  3. Implement Task 3: Encoder-Decoder model")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()
